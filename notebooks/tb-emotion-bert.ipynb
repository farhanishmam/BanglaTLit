{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8419555,"sourceType":"datasetVersion","datasetId":5012232}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":98.203006,"end_time":"2024-04-27T14:12:42.936731","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-27T14:11:04.733725","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"00296b1c34ff4b80b844e229b8ac4c4f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03414352c017411e801b6a954500d227":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ef49ddfe1d1494b8ad81c336f883f96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"104c0ea88b0a49c6a51f47ee0abeebcc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bd28659be43466ebc2cc9e0c1168640","placeholder":"​","style":"IPY_MODEL_85a307a6133e499ebab54662bf5bae69","value":"pytorch_model.bin: 100%"}},"12254cb230a7470cb8af03ccca4e9027":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13e8b655f73949d997a8003c934e5845":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6dd4cd53d55a4b829c6346712c551ac1","placeholder":"​","style":"IPY_MODEL_23d6c2e8259441f6b389d45b2392025e","value":" 119/119 [00:00&lt;00:00, 9.95kB/s]"}},"20402dece1b9460ea476d67c6c349428":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46b90c02cd4b45adb723ae7225de94ed","IPY_MODEL_665a46044d7a4948a3f6c5c40b933768","IPY_MODEL_b831de3747564aed869c0eca4210205d"],"layout":"IPY_MODEL_c688d65e5b4c43bd80b25812902adbb6"}},"20824e914f204c598c2edba20ac25e9c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23c2cb91fcb44332b2172609bafd9f46":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23d6c2e8259441f6b389d45b2392025e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25d36d7c27314cdc80aa1e96f1979aa4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7c2fe324b2d481c99c0872d9751c0c7","placeholder":"​","style":"IPY_MODEL_78d6126c354c455c9676bf39976eccd9","value":"config.json: 100%"}},"2a5585939d094eed98accca4d9dced56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_25d36d7c27314cdc80aa1e96f1979aa4","IPY_MODEL_d4ac1af23a924c9b8633d51ccdf41a75","IPY_MODEL_4aa3e7d9bf8c4bccbaccaec95c48c2e6"],"layout":"IPY_MODEL_00296b1c34ff4b80b844e229b8ac4c4f"}},"2adc59debf0c4eadbb0d4bcc8ab35b91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f7ea5de2e0a4288a909b6efef5202ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"36832c388e96405c80b4fc03145706d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_639d104897114479aee0a81e76e5d1f2","max":528316,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a64deb40760d41f6b64b0ef06f3571d7","value":528316}},"380cc02da3ca4b7a956aaec0b4043c94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b10f2d66eab490abb340d26cfa8b80a","max":442560329,"min":0,"orientation":"horizontal","style":"IPY_MODEL_633698740e4047da8a0bcae6a378a18d","value":442560329}},"3a5632d592cf46ed833ac3a5ed51ddc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b10f2d66eab490abb340d26cfa8b80a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cbbb0369f014cacaa15f38b4d411333":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5af621c5608a4cf4969d16cefaacde04","placeholder":"​","style":"IPY_MODEL_8724f200474d47e5bdbd480e932aa954","value":" 528k/528k [00:00&lt;00:00, 2.78MB/s]"}},"3f6286e4d28146ac8d103b7b2fb27c7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20824e914f204c598c2edba20ac25e9c","placeholder":"​","style":"IPY_MODEL_b34b47da76cf4b538051a836a00295e0","value":"vocab.txt: 100%"}},"41b4a95ce29a4e049c1527fb5650ce68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46b90c02cd4b45adb723ae7225de94ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7912e2fe5658441689f982f655867faf","placeholder":"​","style":"IPY_MODEL_f540915da763489fb74cb685953685f7","value":"100%"}},"49b4fecf969a4ea8a9d724bafa34e923":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8ffd89e5e784862b27dac85a4968db6","placeholder":"​","style":"IPY_MODEL_3a5632d592cf46ed833ac3a5ed51ddc3","value":" 443M/443M [00:01&lt;00:00, 343MB/s]"}},"4aa3e7d9bf8c4bccbaccaec95c48c2e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_edbf6291143049b891cc315d32f6415b","placeholder":"​","style":"IPY_MODEL_8e4c52ed06d446e8b79b1f9f86bdf725","value":" 586/586 [00:00&lt;00:00, 52.7kB/s]"}},"4dde9a3114ed49c68485e5aa59d87c94":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f4d5f1de6034e6fb78144eb22c682ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f6286e4d28146ac8d103b7b2fb27c7e","IPY_MODEL_36832c388e96405c80b4fc03145706d0","IPY_MODEL_3cbbb0369f014cacaa15f38b4d411333"],"layout":"IPY_MODEL_8ccea1201d9348dfb8ddfd38b68fae03"}},"53df00d836d94319a2c3dd1261e78d29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_788ea8b16d9c4ab5a62bc0cb0bbc3121","IPY_MODEL_a9a612ca6399450fa3d7362a401c02cd","IPY_MODEL_5564cb63d5334578a4783a26b657de2a"],"layout":"IPY_MODEL_99f76a6c22dc4f5d9878577cfd5f1ce4"}},"5564cb63d5334578a4783a26b657de2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8eb56802e564365bae1869d4e28655c","placeholder":"​","style":"IPY_MODEL_c428eb428e2f4d47be7179f11e6006f5","value":" 112/112 [00:00&lt;00:00, 9.81kB/s]"}},"57300c05be684f4581c56721c2ebba8d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5931330606d3407abcae4e6a6de92c9a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f226779052714111b34c5fec7ea2ebb1","placeholder":"​","style":"IPY_MODEL_23c2cb91fcb44332b2172609bafd9f46","value":"tokenizer_config.json: 100%"}},"5af621c5608a4cf4969d16cefaacde04":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d2ad126d5b64ec78fe6750c3e6eba3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5931330606d3407abcae4e6a6de92c9a","IPY_MODEL_86cf55e7219343b5904de9d20ef87440","IPY_MODEL_13e8b655f73949d997a8003c934e5845"],"layout":"IPY_MODEL_d9278eadf845407c939ab44891d4b175"}},"60f6d636c19c494eaab4fd8b71d3452a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af2e66fbfb264f44b66337be13bf688d","placeholder":"​","style":"IPY_MODEL_12254cb230a7470cb8af03ccca4e9027","value":"100%"}},"633698740e4047da8a0bcae6a378a18d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"639d104897114479aee0a81e76e5d1f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"665a46044d7a4948a3f6c5c40b933768":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e935fbb0caba4138ad8467680150105c","max":2857,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eec59ae1a8ff404f8ac16e017dff91f1","value":2857}},"6bd28659be43466ebc2cc9e0c1168640":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dd4cd53d55a4b829c6346712c551ac1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"788ea8b16d9c4ab5a62bc0cb0bbc3121":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e168d843812b40ba981774e725a2aa26","placeholder":"​","style":"IPY_MODEL_0ef49ddfe1d1494b8ad81c336f883f96","value":"special_tokens_map.json: 100%"}},"78d6126c354c455c9676bf39976eccd9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7912e2fe5658441689f982f655867faf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b89c8cd21b8434dac8638083b409fdd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85a307a6133e499ebab54662bf5bae69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86cf55e7219343b5904de9d20ef87440":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_abdd78df376e4dbf8cb3ad62ed8fa7af","max":119,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec6ba65f8809413683e99d393dd6ef59","value":119}},"8724f200474d47e5bdbd480e932aa954":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ccea1201d9348dfb8ddfd38b68fae03":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e4c52ed06d446e8b79b1f9f86bdf725":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"924ec67482704413bbe7ecbac762dbb1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9299625368434ba7abb4d07a29778b78","placeholder":"​","style":"IPY_MODEL_2adc59debf0c4eadbb0d4bcc8ab35b91","value":" 6/6 [00:00&lt;00:00,  9.28it/s]"}},"9299625368434ba7abb4d07a29778b78":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93877449d2e1499bacabdae89aaf6597":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_104c0ea88b0a49c6a51f47ee0abeebcc","IPY_MODEL_380cc02da3ca4b7a956aaec0b4043c94","IPY_MODEL_49b4fecf969a4ea8a9d724bafa34e923"],"layout":"IPY_MODEL_99f4c994469e48cdb505b901d170adce"}},"99f4c994469e48cdb505b901d170adce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99f76a6c22dc4f5d9878577cfd5f1ce4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a64deb40760d41f6b64b0ef06f3571d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7c2fe324b2d481c99c0872d9751c0c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9a612ca6399450fa3d7362a401c02cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b034516492364112ab590d2648c4976d","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f7ea5de2e0a4288a909b6efef5202ab","value":112}},"abdd78df376e4dbf8cb3ad62ed8fa7af":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af2e66fbfb264f44b66337be13bf688d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b034516492364112ab590d2648c4976d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b34b47da76cf4b538051a836a00295e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b831de3747564aed869c0eca4210205d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f745fcb6209d40c6a2241f615dd7d592","placeholder":"​","style":"IPY_MODEL_41b4a95ce29a4e049c1527fb5650ce68","value":" 2857/2857 [00:00&lt;00:00, 9537.94it/s]"}},"b8e728b41e254779a4c9e47c057213ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_03414352c017411e801b6a954500d227","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dcfdf578afb448d99a86d5bf17fa942c","value":6}},"c428eb428e2f4d47be7179f11e6006f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c688d65e5b4c43bd80b25812902adbb6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4ac1af23a924c9b8633d51ccdf41a75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_57300c05be684f4581c56721c2ebba8d","max":586,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b89c8cd21b8434dac8638083b409fdd","value":586}},"d8eb56802e564365bae1869d4e28655c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8ffd89e5e784862b27dac85a4968db6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9278eadf845407c939ab44891d4b175":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcfdf578afb448d99a86d5bf17fa942c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e168d843812b40ba981774e725a2aa26":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e935fbb0caba4138ad8467680150105c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb50b7c8ffd34b56b467d1d9307a2561":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_60f6d636c19c494eaab4fd8b71d3452a","IPY_MODEL_b8e728b41e254779a4c9e47c057213ac","IPY_MODEL_924ec67482704413bbe7ecbac762dbb1"],"layout":"IPY_MODEL_4dde9a3114ed49c68485e5aa59d87c94"}},"ec6ba65f8809413683e99d393dd6ef59":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"edbf6291143049b891cc315d32f6415b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eec59ae1a8ff404f8ac16e017dff91f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f226779052714111b34c5fec7ea2ebb1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f540915da763489fb74cb685953685f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f745fcb6209d40c6a2241f615dd7d592":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#C01F4D; border-radius: 100px 100px; text-align:center\"> Install Required Libraries & Utils Function </h1></span>","metadata":{"papermill":{"duration":0.024973,"end_time":"2024-04-27T14:11:07.476924","exception":false,"start_time":"2024-04-27T14:11:07.451951","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Required Libraries\n# ====================================================\n\nimport os\nimport gc\nimport re\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nimport json\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForCausalLM, AutoModelForSequenceClassification\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"papermill":{"duration":6.47607,"end_time":"2024-04-27T14:11:13.977316","exception":false,"start_time":"2024-04-27T14:11:07.501246","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:52:37.673541Z","iopub.execute_input":"2024-05-20T04:52:37.673929Z","iopub.status.idle":"2024-05-20T04:52:44.756499Z","shell.execute_reply.started":"2024-05-20T04:52:37.673898Z","shell.execute_reply":"2024-05-20T04:52:44.755437Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"tokenizers.__version__: 0.15.2\ntransformers.__version__: 4.39.3\nenv: TOKENIZERS_PARALLELISM=true\ncuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# ====================================================\n# Configuration (Hyper Parameters Value)\n# ====================================================\n\nclass CFG:\n    debug=False # want to debug or not \n    apex=True # for faster training\n    print_freq= 300\n    num_workers=4 \n    model= \"microsoft/mdeberta-v3-base\" \n    #\"csebuetnlp/banglabert_large\", \"sagorsarker/bangla-bert-base\",\"csebuetnlp/banglabert\" \n    # \"xlm-roberta-base\"     \n    epochs=10\n    learning_rate=2e-5 \n    eps=1e-6\n    betas=(0.9, 0.999) # for adam optimizer\n    batch_size= 32 #32  # batch size\n    max_len=512\n    weight_decay=0.01 # for adam optimizer regulaization parameter\n    gradient_accumulation_steps=1\n    max_grad_norm=1000\n    target_cols=['Label'] #target columns\n    seed=42 # seed no. for random initialization \n    train=True\n    num_class = None # Number of class in your dataset\n    mode = \"cls_based\" #\"cls_based\", \"attention_based\", \"lstm_based\"\n","metadata":{"papermill":{"duration":0.033332,"end_time":"2024-04-27T14:11:14.036322","exception":false,"start_time":"2024-04-27T14:11:14.002990","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:52:44.758267Z","iopub.execute_input":"2024-05-20T04:52:44.758700Z","iopub.status.idle":"2024-05-20T04:52:44.765115Z","shell.execute_reply.started":"2024-05-20T04:52:44.758674Z","shell.execute_reply":"2024-05-20T04:52:44.764097Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/tb-sentiment-sample-2000/train.csv')\ndf_test = pd.read_csv('/kaggle/input/tb-sentiment-sample-2000/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-20T04:52:44.766440Z","iopub.execute_input":"2024-05-20T04:52:44.766734Z","iopub.status.idle":"2024-05-20T04:52:44.845281Z","shell.execute_reply.started":"2024-05-20T04:52:44.766705Z","shell.execute_reply":"2024-05-20T04:52:44.844445Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"CFG.num_class = df_train['Label'].nunique()\nprint(CFG.num_class)","metadata":{"papermill":{"duration":0.041702,"end_time":"2024-04-27T14:11:14.754989","exception":false,"start_time":"2024-04-27T14:11:14.713287","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:52:44.847329Z","iopub.execute_input":"2024-05-20T04:52:44.847638Z","iopub.status.idle":"2024-05-20T04:52:44.860400Z","shell.execute_reply.started":"2024-05-20T04:52:44.847612Z","shell.execute_reply":"2024-05-20T04:52:44.859482Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"6\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train.head()","metadata":{"papermill":{"duration":0.03722,"end_time":"2024-04-27T14:11:16.157562","exception":false,"start_time":"2024-04-27T14:11:16.120342","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:52:44.861513Z","iopub.execute_input":"2024-05-20T04:52:44.861820Z","iopub.status.idle":"2024-05-20T04:52:44.883630Z","shell.execute_reply.started":"2024-05-20T04:52:44.861794Z","shell.execute_reply":"2024-05-20T04:52:44.882877Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                            Bengali  \\\n0       73680  শালা কাট মোল্লার গুষ্টি অন্ধর বাচ্চারা দাড়ি থা...   \n1       46824  ভাই শুনেন 20 ঘণ্টা বিচার হইছে আর ৬,৫ লক্ষ কম, ...   \n2       17755  না অনুভূতি সবার থাকতে নেই । অনুভূতি শুধু বিশেষ...   \n3        2996                    বিজ্ঞান হোক শিক্ষার মূল ভিত্তি!   \n4        1772  লোকটা পুরো সত্য বলছে। কারন ছাত্র থাকা অবস্থায় ...   \n\n                                            Banglish  Label  \n0  shala kat mollar gushti ondhor baccara dari th...      2  \n1  bhai  shunen 20 ghonta Bichar hoiche ar 6,5 lk...      1  \n2  na onuvuti sobar thakte nei . onuvuti shudhu b...      3  \n3                     biggan hok shikkhar mul vitti!      0  \n4  lokta puro sotjo bolche. karon chatro thaka ob...      3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Bengali</th>\n      <th>Banglish</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>73680</td>\n      <td>শালা কাট মোল্লার গুষ্টি অন্ধর বাচ্চারা দাড়ি থা...</td>\n      <td>shala kat mollar gushti ondhor baccara dari th...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>46824</td>\n      <td>ভাই শুনেন 20 ঘণ্টা বিচার হইছে আর ৬,৫ লক্ষ কম, ...</td>\n      <td>bhai  shunen 20 ghonta Bichar hoiche ar 6,5 lk...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17755</td>\n      <td>না অনুভূতি সবার থাকতে নেই । অনুভূতি শুধু বিশেষ...</td>\n      <td>na onuvuti sobar thakte nei . onuvuti shudhu b...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2996</td>\n      <td>বিজ্ঞান হোক শিক্ষার মূল ভিত্তি!</td>\n      <td>biggan hok shikkhar mul vitti!</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1772</td>\n      <td>লোকটা পুরো সত্য বলছে। কারন ছাত্র থাকা অবস্থায় ...</td>\n      <td>lokta puro sotjo bolche. karon chatro thaka ob...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# If Debugging is True then we will consider a small set of training data\n\nif CFG.debug:\n    CFG.epochs = 2\n    train = train.sample(frac =.1) ","metadata":{"papermill":{"duration":0.032059,"end_time":"2024-04-27T14:11:16.216366","exception":false,"start_time":"2024-04-27T14:11:16.184307","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:52:44.884796Z","iopub.execute_input":"2024-05-20T04:52:44.885192Z","iopub.status.idle":"2024-05-20T04:52:44.890684Z","shell.execute_reply.started":"2024-05-20T04:52:44.885158Z","shell.execute_reply":"2024-05-20T04:52:44.889652Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"papermill":{"duration":0.032462,"end_time":"2024-04-27T14:11:16.275552","exception":false,"start_time":"2024-04-27T14:11:16.243090","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:52:44.891904Z","iopub.execute_input":"2024-05-20T04:52:44.892202Z","iopub.status.idle":"2024-05-20T04:52:44.900643Z","shell.execute_reply.started":"2024-05-20T04:52:44.892169Z","shell.execute_reply":"2024-05-20T04:52:44.899762Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Logger File\n# ====================================================\n\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n\n\ndef get_logger(filename=OUTPUT_DIR+'train'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(CFG.seed)","metadata":{"papermill":{"duration":0.038673,"end_time":"2024-04-27T14:11:16.339457","exception":false,"start_time":"2024-04-27T14:11:16.300784","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:52:44.901960Z","iopub.execute_input":"2024-05-20T04:52:44.902295Z","iopub.status.idle":"2024-05-20T04:52:45.969795Z","shell.execute_reply.started":"2024-05-20T04:52:44.902266Z","shell.execute_reply":"2024-05-20T04:52:45.969016Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#C01F4D; border-radius: 100px 100px; text-align:center\"> Tokenizer, Dataset & Collate Function</h1></span>\n","metadata":{"papermill":{"duration":0.024977,"end_time":"2024-04-27T14:11:16.389810","exception":false,"start_time":"2024-04-27T14:11:16.364833","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\n\nPAD_TOKEN = \"<pad>\"\ntokenizer = AutoTokenizer.from_pretrained(CFG.model)\ntokenizer.add_special_tokens({\"pad_token\":PAD_TOKEN})\n#tokenizer.padding_side = \"right\"\ntokenizer.max_seq_length = 310\ntokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\nCFG.tokenizer = tokenizer","metadata":{"papermill":{"duration":1.296216,"end_time":"2024-04-27T14:11:17.711070","exception":false,"start_time":"2024-04-27T14:11:16.414854","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:52:45.971020Z","iopub.execute_input":"2024-05-20T04:52:45.971370Z","iopub.status.idle":"2024-05-20T04:52:49.916788Z","shell.execute_reply.started":"2024-05-20T04:52:45.971336Z","shell.execute_reply":"2024-05-20T04:52:49.915927Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34030746ff9e4ca6a5a3e60360735009"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47b6fabd2c1f4997b1539b518209cb58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d13c153779ae4118bf5deab5c32ece7d"}},"metadata":{}}]},{"cell_type":"code","source":"# ====================================================\n# Define max_len\n# ====================================================\nlengths = []\ntk0 = tqdm(df_train['Banglish'].fillna(\"\").values, total=len(df_train))\nfor text in tk0:\n    length = len(tokenizer(text, truncation=True, add_special_tokens=False)['input_ids'])\n    lengths.append(length)\n    \nif max(lengths) + 2 > 512:\n    CFG.max_len = 512\nelse:\n    CFG.max_len = max(lengths) + 2 # cls & sep \nLOGGER.info(f\"max_len: {CFG.max_len}\")","metadata":{"papermill":{"duration":0.346075,"end_time":"2024-04-27T14:11:18.083299","exception":false,"start_time":"2024-04-27T14:11:17.737224","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:52:49.920788Z","iopub.execute_input":"2024-05-20T04:52:49.921225Z","iopub.status.idle":"2024-05-20T04:52:50.179417Z","shell.execute_reply.started":"2024-05-20T04:52:49.921201Z","shell.execute_reply":"2024-05-20T04:52:50.178558Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1600 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cfc79cbae12487abad5899043bb8bf7"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\nmax_len: 113\n","output_type":"stream"}]},{"cell_type":"code","source":"# ====================================================\n# Dataset Preparation\n# ====================================================\n\ndef prepare_input(cfg, text):\n    inputs = cfg.tokenizer.encode_plus(\n        text, \n        return_tensors=None, \n        add_special_tokens=True, \n        max_length=CFG.max_len,\n        pad_to_max_length=True,\n        truncation=True\n    )\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\nclass TrainDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['Banglish'].values\n#         self.langs = df['lang'].values\n        self.labels = df[cfg.target_cols].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        text = self.texts[item]\n#         text = f'Lang {self.langs[item]} ' + text\n#         self.texts[item] = text\n        inputs = prepare_input(self.cfg, self.texts[item])\n        label = torch.tensor(self.labels[item], dtype=torch.long)\n        return inputs, label\n    \n\n# the colllate function to increase training speed\n\ndef collate(inputs): \n    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n    for k, v in inputs.items():\n        inputs[k] = inputs[k][:,:mask_len]\n    return inputs","metadata":{"papermill":{"duration":0.038244,"end_time":"2024-04-27T14:11:18.148053","exception":false,"start_time":"2024-04-27T14:11:18.109809","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:52:50.180757Z","iopub.execute_input":"2024-05-20T04:52:50.181137Z","iopub.status.idle":"2024-05-20T04:52:50.193099Z","shell.execute_reply.started":"2024-05-20T04:52:50.181106Z","shell.execute_reply":"2024-05-20T04:52:50.192106Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"\n# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#C01F4D; border-radius: 100px 100px; text-align:center\"> Model Architecture </h1></span>\n","metadata":{"papermill":{"duration":0.025563,"end_time":"2024-04-27T14:11:18.199614","exception":false,"start_time":"2024-04-27T14:11:18.174051","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n            self.config.hidden_dropout = 0.\n            self.config.hidden_dropout_prob = 0.\n            self.config.attention_dropout = 0.\n            self.config.attention_probs_dropout_prob = 0.\n            LOGGER.info(self.config)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n#             self.model = AutoModelForCausalLM.from_pretrained(\n#                 self.cfg.model,\n#                 device_map=\"auto\",\n#                 trust_remote_code = True,\n#                 config=self.config\n#             )\n#             self.model.resize_token_embeddings(len(tokenizer),pad_to_multiple_of=8)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        \n        # defining attention network for attention scores \n        self.attention = nn.Sequential(\n            nn.Linear(self.config.hidden_size, 512),\n            nn.Tanh(),\n            nn.Linear(512, 1),\n            nn.Softmax(dim=1))\n        \n        self.linear = nn.Linear(768, 768*2)\n        self.lstm = nn.LSTM(768*2, self.config.hidden_size)\n        \n        self._init_weights(self.attention)\n        self.concat_pool = nn.Linear(self.config.hidden_size*2, self.config.hidden_size)\n        self.fc = nn.Linear(self.config.hidden_size, self.cfg.num_class)\n        self._init_weights(self.fc)\n\n\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n#         last_hidden_states = outputs.last_hidden_state # word level representation of last hiddent state\n        \n        if self.cfg.mode == \"attention_based\":\n            # attention based sentence representation\n            last_hidden_states = outputs.last_hidden_state\n            weights = self.attention(last_hidden_states)\n            feature = torch.sum(weights * last_hidden_states, dim=1)\n            \n            cls_token_feature = last_hidden_states[:, 0, :]\n#             print(feature.shape, cls_token_feature.shape)\n#             combine_feature = torch.cat([feature, cls_token_feature], dim = -1)\n#             feature = self.concat_pool(combine_feature)\n            feature += cls_token_feature\n            \n        if self.cfg.mode == \"cls_based\":\n#             print(f\"Available attributes in outputs: {outputs.__dict__.keys()}\")\n            # [CLS] Token Repr\n            last_hidden_states = outputs.last_hidden_state\n            feature = last_hidden_states[:, 0, :]\n            weights= None\n            \n        if self.cfg.mode == 'tiny_based':\n#             print(outputs.logits)\n#             print(f\"Available attributes in outputs: {outputs.__dict__.keys()}\")\n            last_hidden_states = outputs.hidden_states[-1]\n            feature = last_hidden_states[:, 0, :]\n            weights= None\n            \n        if self.cfg.mode == \"lstm_based\":\n            last_hidden_states = outputs.last_hidden_state\n            x = last_hidden_states[:, 0, :]\n            x = self.linear(x)\n            feature, _ = self.lstm(x)\n            weights= None\n\n        return feature, weights\n\n    def forward(self, inputs):\n        feature, weights = self.feature(inputs)\n        output = self.fc(feature)\n        return output, weights","metadata":{"papermill":{"duration":0.044167,"end_time":"2024-04-27T14:11:18.269589","exception":false,"start_time":"2024-04-27T14:11:18.225422","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:52:50.194221Z","iopub.execute_input":"2024-05-20T04:52:50.194512Z","iopub.status.idle":"2024-05-20T04:52:50.212974Z","shell.execute_reply.started":"2024-05-20T04:52:50.194488Z","shell.execute_reply":"2024-05-20T04:52:50.212097Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"\n# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#C01F4D; border-radius: 100px 100px; text-align:center\"> Helpler functions for Training  </h1></span>\n\n<font size=\"3\">Few important function are created here.</font>\n\n1. <i>AverageMeter</i> - To compute & store the average\n2. <i>asMinutes</i> - To calculate the time\n3. <i>timeSince</i> - To compute training & validation time\n4. <i>train_fn</i> - Calculation of forward & backward pass for a single epoch in training data\n5. <i>valid_fn</i> - Calculation of forward & backward pass for a single epoch in validation data\n","metadata":{"papermill":{"duration":0.025783,"end_time":"2024-04-27T14:11:18.321599","exception":false,"start_time":"2024-04-27T14:11:18.295816","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Helper functions\n# ====================================================\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef train_fn(train_loader, model, criterion, optimizer, epoch, device):\n\n    \n    # Enabling Model Training Mode\n    model.train()\n     \n    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex) # using Automatic Mixed Precision (AMP) for speed up\n    losses = AverageMeter()\n    start = end = time.time()\n    global_step = 0\n    \n    for step, (inputs, labels) in enumerate(train_loader): # iterate over the training data \n        inputs = collate(inputs) # the collate function I discussed for speeding up training\n        \n        for k, v in inputs.items():\n            inputs[k] = v.to(device)  # formatting the input to feed into the transformer model \n        labels = labels.to(device) \n        batch_size = labels.size(0)\n        \n        with torch.cuda.amp.autocast(enabled=CFG.apex):\n            y_preds, _ = model(inputs) \n            loss = criterion(y_preds.view(-1, CFG.num_class), labels.view(-1))\n\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n        \n        scaler.scale(loss).backward() # backpropagation\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm) # clipping the gradient\n        \n        losses.update(loss.item(), batch_size)\n        \n        # Updating weights via optimizer & scaler\n        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n            global_step += 1\n        end = time.time()\n        \n        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n            print('Epoch: [{0}][{1}/{2}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  'Grad: {grad_norm:.4f}  '\n                  .format(epoch+1, step, len(train_loader), \n                          remain=timeSince(start, float(step+1)/len(train_loader)),\n                          loss=losses,\n                          grad_norm=grad_norm))\n\n    return losses.avg\n\n\ndef valid_fn(valid_loader, model, criterion, device):\n    losses = AverageMeter()\n    model.eval()\n    preds = []\n    start = end = time.time()\n    \n    for step, (inputs, labels) in enumerate(valid_loader): # iterate over the validation data \n        inputs = collate(inputs)\n        \n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        \n        with torch.no_grad(): # we don't need to store the gradients w.r.t validation data\n            y_preds, _ = model(inputs)\n            loss = criterion(y_preds.view(-1, CFG.num_class), labels.view(-1))\n            \n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n        \n        losses.update(loss.item(), batch_size)\n        preds.append(y_preds.to('cpu').numpy())\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n            print('EVAL: [{0}/{1}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  .format(step, len(valid_loader),\n                          loss=losses,\n                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n    predictions = np.concatenate(preds)\n    return losses.avg, predictions","metadata":{"papermill":{"duration":0.05031,"end_time":"2024-04-27T14:11:18.398160","exception":false,"start_time":"2024-04-27T14:11:18.347850","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:52:50.214472Z","iopub.execute_input":"2024-05-20T04:52:50.214825Z","iopub.status.idle":"2024-05-20T04:52:50.238096Z","shell.execute_reply.started":"2024-05-20T04:52:50.214800Z","shell.execute_reply":"2024-05-20T04:52:50.236931Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#C01F4D; border-radius: 100px 100px; text-align:center\"> Training Loop </h1></span>","metadata":{"papermill":{"duration":0.068843,"end_time":"2024-04-27T14:11:18.492970","exception":false,"start_time":"2024-04-27T14:11:18.424127","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.metrics import f1_score, classification_report\n\ndef get_score(y_trues, y_preds):\n    y_predicted = y_preds.argmax(axis=1)  # Convert probabilities to class predictions\n    macro_f1 = f1_score(y_trues, y_predicted, average='macro')\n#     print(classification_report(y_trues, y_predicted, digits=4))\n    return macro_f1","metadata":{"papermill":{"duration":0.044676,"end_time":"2024-04-27T14:11:18.568717","exception":false,"start_time":"2024-04-27T14:11:18.524041","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:52:50.239309Z","iopub.execute_input":"2024-05-20T04:52:50.239662Z","iopub.status.idle":"2024-05-20T04:52:50.251830Z","shell.execute_reply.started":"2024-05-20T04:52:50.239632Z","shell.execute_reply":"2024-05-20T04:52:50.251023Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# train loop\n# ====================================================\ndef train_loop():\n\n    # ====================================================\n    # loader\n    # ====================================================\n    \n    train_dataset = TrainDataset(CFG, df_train) # training dataset formatting \n    valid_dataset = TrainDataset(CFG, df_test) # validation dataset formatting\n\n    train_loader = DataLoader(train_dataset,\n                              batch_size=CFG.batch_size,\n                              shuffle=True,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True) # train dataloader\n    valid_loader = DataLoader(valid_dataset,\n                              batch_size=CFG.batch_size * 2,\n                              shuffle=False,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False) # validation dataloader\n\n    valid_labels = df_test[CFG.target_cols].values\n    \n    # ====================================================\n    # model & optimizer\n    # ====================================================\n    model = CustomModel(CFG, config_path=None, pretrained=True)  # initializing the model\n    torch.save(model.config, OUTPUT_DIR+'config.pth') # saving the model configuration \n    model.to(device) # GPU Config\n    \n    optimizer = AdamW(model.parameters(), lr=CFG.learning_rate, eps=CFG.eps, betas=CFG.betas) # declaring the optimizer\n    \n    criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n    best_score = 0\n\n\n    for epoch in range(CFG.epochs):\n\n        start_time = time.time()\n\n        # train function \n        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, device)\n\n        # eval function \n        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n        \n        # scoring\n        score = get_score(valid_labels, predictions)\n\n        elapsed = time.time() - start_time\n\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n        \n        if best_score < score: # Saving the best model w.r.t the score \n            best_score = score\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save({'model': model.state_dict(),\n                        'predictions': predictions},\n                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_score{best_score:.4f}_best.pth\")\n\n#     predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_score{best_score:.4f}_best.pth\", \n#                              map_location=torch.device('cpu'))['predictions']\n#     final_pred = predictions.argmax(axis=1)\n#     final_pred = final_pred.tolist()\n#     df_dev[f\"pred_label\"] = final_pred\n\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    return best_score","metadata":{"papermill":{"duration":0.048232,"end_time":"2024-04-27T14:11:18.646033","exception":false,"start_time":"2024-04-27T14:11:18.597801","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:52:50.253062Z","iopub.execute_input":"2024-05-20T04:52:50.253415Z","iopub.status.idle":"2024-05-20T04:52:50.265681Z","shell.execute_reply.started":"2024-05-20T04:52:50.253385Z","shell.execute_reply":"2024-05-20T04:52:50.264925Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# the training\n# ====================================================\n    \nif __name__ == '__main__':\n    \n    if CFG.train:\n        best_score = train_loop()","metadata":{"papermill":{"duration":67.545398,"end_time":"2024-04-27T14:12:26.218159","exception":false,"start_time":"2024-04-27T14:11:18.672761","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:52:50.266838Z","iopub.execute_input":"2024-05-20T04:52:50.267189Z","iopub.status.idle":"2024-05-20T04:56:38.931702Z","shell.execute_reply.started":"2024-05-20T04:52:50.267166Z","shell.execute_reply":"2024-05-20T04:56:38.930779Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"DebertaV2Config {\n  \"_name_or_path\": \"microsoft/mdeberta-v3-base\",\n  \"attention_dropout\": 0.0,\n  \"attention_probs_dropout_prob\": 0.0,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout\": 0.0,\n  \"hidden_dropout_prob\": 0.0,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta-v2\",\n  \"norm_rel_ebd\": \"layer_norm\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_hidden_states\": true,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 768,\n  \"pos_att_type\": [\n    \"p2c\",\n    \"c2p\"\n  ],\n  \"position_biased_input\": false,\n  \"position_buckets\": 256,\n  \"relative_attention\": true,\n  \"share_att_key\": true,\n  \"transformers_version\": \"4.39.3\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 251000\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6cb6e62be474761a4efdf433963abfb"}},"metadata":{}},{"name":"stdout","text":"Epoch: [1][0/50] Elapsed 0m 1s (remain 1m 7s) Loss: 1.8782(1.8782) Grad: inf  \nEpoch: [1][49/50] Elapsed 0m 20s (remain 0m 0s) Loss: 1.7305(1.7342) Grad: 236917.6562  \nEVAL: [0/7] Elapsed 0m 0s (remain 0m 2s) Loss: 1.6565(1.6565) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 1 - avg_train_loss: 1.7342  avg_val_loss: 1.6879  time: 22s\nEpoch 1 - Score: 0.1709\nEpoch 1 - Save Best Score: 0.1709 Model\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [6/7] Elapsed 0m 1s (remain 0m 0s) Loss: 1.5229(1.6879) \nEpoch: [2][0/50] Elapsed 0m 0s (remain 0m 23s) Loss: 1.7138(1.7138) Grad: 401330.9375  \nEpoch: [2][49/50] Elapsed 0m 18s (remain 0m 0s) Loss: 1.8759(1.6005) Grad: 214614.7344  \nEVAL: [0/7] Elapsed 0m 0s (remain 0m 2s) Loss: 1.5780(1.5780) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 - avg_train_loss: 1.6005  avg_val_loss: 1.6642  time: 21s\nEpoch 2 - Score: 0.1935\nEpoch 2 - Save Best Score: 0.1935 Model\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [6/7] Elapsed 0m 1s (remain 0m 0s) Loss: 1.4267(1.6642) \nEpoch: [3][0/50] Elapsed 0m 0s (remain 0m 21s) Loss: 1.6232(1.6232) Grad: 796980.8125  \nEpoch: [3][49/50] Elapsed 0m 19s (remain 0m 0s) Loss: 1.1805(1.4157) Grad: 549265.3750  \nEVAL: [0/7] Elapsed 0m 0s (remain 0m 2s) Loss: 1.5591(1.5591) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 - avg_train_loss: 1.4157  avg_val_loss: 1.6404  time: 21s\nEpoch 3 - Score: 0.2944\nEpoch 3 - Save Best Score: 0.2944 Model\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [6/7] Elapsed 0m 1s (remain 0m 0s) Loss: 1.5088(1.6404) \nEpoch: [4][0/50] Elapsed 0m 0s (remain 0m 24s) Loss: 1.2716(1.2716) Grad: 553721.7500  \nEpoch: [4][49/50] Elapsed 0m 19s (remain 0m 0s) Loss: 0.9481(1.1502) Grad: 200094.1719  \nEVAL: [0/7] Elapsed 0m 0s (remain 0m 2s) Loss: 1.5622(1.5622) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 - avg_train_loss: 1.1502  avg_val_loss: 1.6996  time: 21s\nEpoch 4 - Score: 0.3195\nEpoch 4 - Save Best Score: 0.3195 Model\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [6/7] Elapsed 0m 1s (remain 0m 0s) Loss: 1.5474(1.6996) \nEpoch: [5][0/50] Elapsed 0m 0s (remain 0m 22s) Loss: 0.9039(0.9039) Grad: inf  \nEpoch: [5][49/50] Elapsed 0m 19s (remain 0m 0s) Loss: 1.6157(0.9891) Grad: 269230.7812  \nEVAL: [0/7] Elapsed 0m 0s (remain 0m 2s) Loss: 1.7828(1.7828) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 - avg_train_loss: 0.9891  avg_val_loss: 1.9583  time: 21s\nEpoch 5 - Score: 0.2921\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [6/7] Elapsed 0m 1s (remain 0m 0s) Loss: 1.8443(1.9583) \nEpoch: [6][0/50] Elapsed 0m 0s (remain 0m 21s) Loss: 0.9027(0.9027) Grad: inf  \nEpoch: [6][49/50] Elapsed 0m 19s (remain 0m 0s) Loss: 0.6903(0.7757) Grad: 393828.2188  \nEVAL: [0/7] Elapsed 0m 0s (remain 0m 2s) Loss: 1.8394(1.8394) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 - avg_train_loss: 0.7757  avg_val_loss: 2.0111  time: 21s\nEpoch 6 - Score: 0.3134\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [6/7] Elapsed 0m 1s (remain 0m 0s) Loss: 2.0273(2.0111) \nEpoch: [7][0/50] Elapsed 0m 0s (remain 0m 19s) Loss: 0.6833(0.6833) Grad: inf  \nEpoch: [7][49/50] Elapsed 0m 19s (remain 0m 0s) Loss: 0.4680(0.4145) Grad: 267045.5625  \nEVAL: [0/7] Elapsed 0m 0s (remain 0m 2s) Loss: 2.0902(2.0902) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 7 - avg_train_loss: 0.4145  avg_val_loss: 2.1871  time: 21s\nEpoch 7 - Score: 0.2906\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [6/7] Elapsed 0m 1s (remain 0m 0s) Loss: 2.6107(2.1871) \nEpoch: [8][0/50] Elapsed 0m 0s (remain 0m 24s) Loss: 0.4964(0.4964) Grad: inf  \nEpoch: [8][49/50] Elapsed 0m 18s (remain 0m 0s) Loss: 0.2152(0.2994) Grad: 134356.7500  \nEVAL: [0/7] Elapsed 0m 0s (remain 0m 2s) Loss: 2.2325(2.2325) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 8 - avg_train_loss: 0.2994  avg_val_loss: 2.3584  time: 21s\nEpoch 8 - Score: 0.3294\nEpoch 8 - Save Best Score: 0.3294 Model\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [6/7] Elapsed 0m 1s (remain 0m 0s) Loss: 2.2613(2.3584) \nEpoch: [9][0/50] Elapsed 0m 0s (remain 0m 22s) Loss: 0.1014(0.1014) Grad: 441983.7500  \nEpoch: [9][49/50] Elapsed 0m 19s (remain 0m 0s) Loss: 0.1245(0.2347) Grad: 154181.7656  \nEVAL: [0/7] Elapsed 0m 0s (remain 0m 2s) Loss: 2.7143(2.7143) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 9 - avg_train_loss: 0.2347  avg_val_loss: 2.5949  time: 21s\nEpoch 9 - Score: 0.3265\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [6/7] Elapsed 0m 1s (remain 0m 0s) Loss: 2.6259(2.5949) \nEpoch: [10][0/50] Elapsed 0m 0s (remain 0m 24s) Loss: 0.1493(0.1493) Grad: 918585.1250  \nEpoch: [10][49/50] Elapsed 0m 19s (remain 0m 0s) Loss: 0.1169(0.1159) Grad: 210797.8750  \nEVAL: [0/7] Elapsed 0m 0s (remain 0m 2s) Loss: 2.6708(2.6708) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 10 - avg_train_loss: 0.1159  avg_val_loss: 2.7824  time: 21s\nEpoch 10 - Score: 0.3039\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [6/7] Elapsed 0m 1s (remain 0m 0s) Loss: 2.7559(2.7824) \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#C01F4D; border-radius: 100px 100px; text-align:center\">  Inference </h1></span>\n\n\n<font color='#3498DB'> <h3> <a id =\"section11a\"> <b> Configuration for Inference</b> </a> </h3> </font>\n\n<font size=\"3\"> The basic and important configuration for infernce is described here along with some function & other stuff.</font>\n","metadata":{"papermill":{"duration":0.029669,"end_time":"2024-04-27T14:12:26.344390","exception":false,"start_time":"2024-04-27T14:12:26.314721","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# CFG for testing\n# ====================================================\n\nclass CFG_Test:\n    num_workers=4\n    path=\"./\"\n    config_path=path+'config.pth'\n    model=CFG.model\n    batch_size=CFG.batch_size\n    target_cols=CFG.target_cols\n    seed=CFG.seed\n    num_class = CFG.num_class\n    mode = CFG.mode\n    \nCFG_Test.tokenizer = AutoTokenizer.from_pretrained(CFG_Test.path+'tokenizer/') # load the saved pretrained tokenizer","metadata":{"papermill":{"duration":0.059656,"end_time":"2024-04-27T14:12:26.433725","exception":false,"start_time":"2024-04-27T14:12:26.374069","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:56:38.933407Z","iopub.execute_input":"2024-05-20T04:56:38.933901Z","iopub.status.idle":"2024-05-20T04:56:39.518960Z","shell.execute_reply.started":"2024-05-20T04:56:38.933863Z","shell.execute_reply":"2024-05-20T04:56:39.518045Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_logger(filename='inference'): # infernece logger file\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()","metadata":{"papermill":{"duration":0.040023,"end_time":"2024-04-27T14:12:26.503839","exception":false,"start_time":"2024-04-27T14:12:26.463816","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:56:39.520237Z","iopub.execute_input":"2024-05-20T04:56:39.520608Z","iopub.status.idle":"2024-05-20T04:56:39.528182Z","shell.execute_reply.started":"2024-05-20T04:56:39.520558Z","shell.execute_reply":"2024-05-20T04:56:39.527170Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"<font color='#3498DB'> <h3> <b> Model Loading for Inference</b> </h3> </font>\n\n<font size=\"3\"> Dataset for predicting on the test data and Model Loading for inference are done in this section </font>","metadata":{"papermill":{"duration":0.028478,"end_time":"2024-04-27T14:12:26.561597","exception":false,"start_time":"2024-04-27T14:12:26.533119","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\ndef prepare_input(cfg, text):\n    inputs = cfg.tokenizer.encode_plus(\n        text, \n        return_tensors=None, \n        add_special_tokens=True)\n    \n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['Banglish'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.texts[item])\n        return inputs","metadata":{"papermill":{"duration":0.039138,"end_time":"2024-04-27T14:12:26.629875","exception":false,"start_time":"2024-04-27T14:12:26.590737","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:56:39.529244Z","iopub.execute_input":"2024-05-20T04:56:39.529542Z","iopub.status.idle":"2024-05-20T04:56:39.540388Z","shell.execute_reply.started":"2024-05-20T04:56:39.529517Z","shell.execute_reply":"2024-05-20T04:56:39.539495Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"<font color='#3498DB'> <h3> <b> Prediction on Test Data</b></h3> </font>\n\n<font size=\"3\"> An inference function is made for predicting on the test data. Then finally, loading the previously saved model for each fold and taking prediction on test dataset for each fold. Then, take the average of the each of prediction is considered as model final prediction, </font>","metadata":{"papermill":{"duration":0.028593,"end_time":"2024-04-27T14:12:26.687041","exception":false,"start_time":"2024-04-27T14:12:26.658448","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in tk0: # iterate over the test data\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds, _ = model(inputs) # considering the logits only\n        preds.append(y_preds.to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions","metadata":{"papermill":{"duration":0.037788,"end_time":"2024-04-27T14:12:26.753384","exception":false,"start_time":"2024-04-27T14:12:26.715596","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:56:39.541492Z","iopub.execute_input":"2024-05-20T04:56:39.541765Z","iopub.status.idle":"2024-05-20T04:56:39.551823Z","shell.execute_reply.started":"2024-05-20T04:56:39.541742Z","shell.execute_reply":"2024-05-20T04:56:39.550945Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nfrom transformers import DataCollatorWithPadding\ntest_dataset = TestDataset(CFG_Test, df_test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG_Test.batch_size,\n                         shuffle=False,\n                         collate_fn=DataCollatorWithPadding(tokenizer=CFG_Test.tokenizer, padding='longest'))\n                         \n\nmodel = CustomModel(CFG_Test, config_path=CFG_Test.config_path, pretrained=True)\nstate = torch.load(CFG_Test.path+f\"{CFG_Test.model.replace('/', '-')}_score{best_score:.4f}_best.pth\",\n                   map_location=torch.device('cpu')) # loading the saved model\n\nmodel.load_state_dict(state['model'])\nprediction = inference_fn(test_loader, model, device)\ndel model, state; gc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-05-20T04:56:39.552755Z","iopub.execute_input":"2024-05-20T04:56:39.553166Z","iopub.status.idle":"2024-05-20T04:56:54.006186Z","shell.execute_reply.started":"2024-05-20T04:56:39.553142Z","shell.execute_reply":"2024-05-20T04:56:54.005297Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"2024-05-20 04:56:41.574543: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-20 04:56:41.574681: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-20 04:56:41.724651: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2d961b284eb48088df072336113409b"}},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, classification_report\n\nprint('\\nThe Classification Report is as follows\\n')\nfinal_prediction = prediction.argmax(axis = 1)\nprint(classification_report(df_test['Label'].tolist(), final_prediction, digits = 4))","metadata":{"execution":{"iopub.status.busy":"2024-05-20T04:56:54.007613Z","iopub.execute_input":"2024-05-20T04:56:54.008005Z","iopub.status.idle":"2024-05-20T04:56:54.022997Z","shell.execute_reply.started":"2024-05-20T04:56:54.007972Z","shell.execute_reply":"2024-05-20T04:56:54.022063Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"\nThe Classification Report is as follows\n\n              precision    recall  f1-score   support\n\n           0     0.6032    0.3878    0.4720        98\n           1     0.3039    0.4247    0.3543        73\n           2     0.2824    0.3117    0.2963        77\n           3     0.2717    0.4098    0.3268        61\n           4     0.2368    0.1875    0.2093        48\n           5     0.5000    0.2326    0.3175        43\n\n    accuracy                         0.3425       400\n   macro avg     0.3663    0.3257    0.3294       400\nweighted avg     0.3812    0.3425    0.3464       400\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# from transformers import DataCollatorWithPadding\n# test_dataset = TestDataset(CFG_Test, df_test)\n# test_loader = DataLoader(test_dataset,\n#                          batch_size=CFG_Test.batch_size,\n#                          shuffle=False,\n#                          collate_fn=DataCollatorWithPadding(tokenizer=CFG_Test.tokenizer, padding='longest'))\n                         \n\n# model = CustomModel(CFG_Test, config_path=CFG_Test.config_path, pretrained=True)\n# state = torch.load(CFG_Test.path+f\"{CFG_Test.model.replace('/', '-')}_score{best_score:.4f}_best.pth\",\n#                    map_location=torch.device('cpu')) # loading the saved model\n\n# model.load_state_dict(state['model'])\n# prediction = inference_fn(test_loader, model, device)\n# del model, state; gc.collect()\n# torch.cuda.empty_cache()\n    \n","metadata":{"papermill":{"duration":12.643409,"end_time":"2024-04-27T14:12:39.425549","exception":false,"start_time":"2024-04-27T14:12:26.782140","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-20T04:56:54.024168Z","iopub.execute_input":"2024-05-20T04:56:54.024454Z","iopub.status.idle":"2024-05-20T04:56:54.029581Z","shell.execute_reply.started":"2024-05-20T04:56:54.024431Z","shell.execute_reply":"2024-05-20T04:56:54.028413Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#C01F4D; border-radius: 100px 100px; text-align:center\"> Evaluation on Test Dataset </h1></span>\n","metadata":{"papermill":{"duration":0.028873,"end_time":"2024-04-27T14:12:39.484225","exception":false,"start_time":"2024-04-27T14:12:39.455352","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#C01F4D; border-radius: 100px 100px; text-align:center\"> Thanks for Reading </h1></span>","metadata":{"papermill":{"duration":0.029191,"end_time":"2024-04-27T14:12:39.693730","exception":false,"start_time":"2024-04-27T14:12:39.664539","status":"completed"},"tags":[]}},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.029286,"end_time":"2024-04-27T14:12:39.752188","exception":false,"start_time":"2024-04-27T14:12:39.722902","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}