{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8409654,"sourceType":"datasetVersion","datasetId":5004931}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":98.203006,"end_time":"2024-04-27T14:12:42.936731","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-27T14:11:04.733725","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"00296b1c34ff4b80b844e229b8ac4c4f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03414352c017411e801b6a954500d227":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ef49ddfe1d1494b8ad81c336f883f96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"104c0ea88b0a49c6a51f47ee0abeebcc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bd28659be43466ebc2cc9e0c1168640","placeholder":"​","style":"IPY_MODEL_85a307a6133e499ebab54662bf5bae69","value":"pytorch_model.bin: 100%"}},"12254cb230a7470cb8af03ccca4e9027":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13e8b655f73949d997a8003c934e5845":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6dd4cd53d55a4b829c6346712c551ac1","placeholder":"​","style":"IPY_MODEL_23d6c2e8259441f6b389d45b2392025e","value":" 119/119 [00:00&lt;00:00, 9.95kB/s]"}},"20402dece1b9460ea476d67c6c349428":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46b90c02cd4b45adb723ae7225de94ed","IPY_MODEL_665a46044d7a4948a3f6c5c40b933768","IPY_MODEL_b831de3747564aed869c0eca4210205d"],"layout":"IPY_MODEL_c688d65e5b4c43bd80b25812902adbb6"}},"20824e914f204c598c2edba20ac25e9c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23c2cb91fcb44332b2172609bafd9f46":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23d6c2e8259441f6b389d45b2392025e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25d36d7c27314cdc80aa1e96f1979aa4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7c2fe324b2d481c99c0872d9751c0c7","placeholder":"​","style":"IPY_MODEL_78d6126c354c455c9676bf39976eccd9","value":"config.json: 100%"}},"2a5585939d094eed98accca4d9dced56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_25d36d7c27314cdc80aa1e96f1979aa4","IPY_MODEL_d4ac1af23a924c9b8633d51ccdf41a75","IPY_MODEL_4aa3e7d9bf8c4bccbaccaec95c48c2e6"],"layout":"IPY_MODEL_00296b1c34ff4b80b844e229b8ac4c4f"}},"2adc59debf0c4eadbb0d4bcc8ab35b91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f7ea5de2e0a4288a909b6efef5202ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"36832c388e96405c80b4fc03145706d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_639d104897114479aee0a81e76e5d1f2","max":528316,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a64deb40760d41f6b64b0ef06f3571d7","value":528316}},"380cc02da3ca4b7a956aaec0b4043c94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b10f2d66eab490abb340d26cfa8b80a","max":442560329,"min":0,"orientation":"horizontal","style":"IPY_MODEL_633698740e4047da8a0bcae6a378a18d","value":442560329}},"3a5632d592cf46ed833ac3a5ed51ddc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b10f2d66eab490abb340d26cfa8b80a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cbbb0369f014cacaa15f38b4d411333":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5af621c5608a4cf4969d16cefaacde04","placeholder":"​","style":"IPY_MODEL_8724f200474d47e5bdbd480e932aa954","value":" 528k/528k [00:00&lt;00:00, 2.78MB/s]"}},"3f6286e4d28146ac8d103b7b2fb27c7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20824e914f204c598c2edba20ac25e9c","placeholder":"​","style":"IPY_MODEL_b34b47da76cf4b538051a836a00295e0","value":"vocab.txt: 100%"}},"41b4a95ce29a4e049c1527fb5650ce68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46b90c02cd4b45adb723ae7225de94ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7912e2fe5658441689f982f655867faf","placeholder":"​","style":"IPY_MODEL_f540915da763489fb74cb685953685f7","value":"100%"}},"49b4fecf969a4ea8a9d724bafa34e923":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8ffd89e5e784862b27dac85a4968db6","placeholder":"​","style":"IPY_MODEL_3a5632d592cf46ed833ac3a5ed51ddc3","value":" 443M/443M [00:01&lt;00:00, 343MB/s]"}},"4aa3e7d9bf8c4bccbaccaec95c48c2e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_edbf6291143049b891cc315d32f6415b","placeholder":"​","style":"IPY_MODEL_8e4c52ed06d446e8b79b1f9f86bdf725","value":" 586/586 [00:00&lt;00:00, 52.7kB/s]"}},"4dde9a3114ed49c68485e5aa59d87c94":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f4d5f1de6034e6fb78144eb22c682ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f6286e4d28146ac8d103b7b2fb27c7e","IPY_MODEL_36832c388e96405c80b4fc03145706d0","IPY_MODEL_3cbbb0369f014cacaa15f38b4d411333"],"layout":"IPY_MODEL_8ccea1201d9348dfb8ddfd38b68fae03"}},"53df00d836d94319a2c3dd1261e78d29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_788ea8b16d9c4ab5a62bc0cb0bbc3121","IPY_MODEL_a9a612ca6399450fa3d7362a401c02cd","IPY_MODEL_5564cb63d5334578a4783a26b657de2a"],"layout":"IPY_MODEL_99f76a6c22dc4f5d9878577cfd5f1ce4"}},"5564cb63d5334578a4783a26b657de2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8eb56802e564365bae1869d4e28655c","placeholder":"​","style":"IPY_MODEL_c428eb428e2f4d47be7179f11e6006f5","value":" 112/112 [00:00&lt;00:00, 9.81kB/s]"}},"57300c05be684f4581c56721c2ebba8d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5931330606d3407abcae4e6a6de92c9a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f226779052714111b34c5fec7ea2ebb1","placeholder":"​","style":"IPY_MODEL_23c2cb91fcb44332b2172609bafd9f46","value":"tokenizer_config.json: 100%"}},"5af621c5608a4cf4969d16cefaacde04":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d2ad126d5b64ec78fe6750c3e6eba3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5931330606d3407abcae4e6a6de92c9a","IPY_MODEL_86cf55e7219343b5904de9d20ef87440","IPY_MODEL_13e8b655f73949d997a8003c934e5845"],"layout":"IPY_MODEL_d9278eadf845407c939ab44891d4b175"}},"60f6d636c19c494eaab4fd8b71d3452a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af2e66fbfb264f44b66337be13bf688d","placeholder":"​","style":"IPY_MODEL_12254cb230a7470cb8af03ccca4e9027","value":"100%"}},"633698740e4047da8a0bcae6a378a18d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"639d104897114479aee0a81e76e5d1f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"665a46044d7a4948a3f6c5c40b933768":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e935fbb0caba4138ad8467680150105c","max":2857,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eec59ae1a8ff404f8ac16e017dff91f1","value":2857}},"6bd28659be43466ebc2cc9e0c1168640":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dd4cd53d55a4b829c6346712c551ac1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"788ea8b16d9c4ab5a62bc0cb0bbc3121":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e168d843812b40ba981774e725a2aa26","placeholder":"​","style":"IPY_MODEL_0ef49ddfe1d1494b8ad81c336f883f96","value":"special_tokens_map.json: 100%"}},"78d6126c354c455c9676bf39976eccd9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7912e2fe5658441689f982f655867faf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b89c8cd21b8434dac8638083b409fdd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85a307a6133e499ebab54662bf5bae69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86cf55e7219343b5904de9d20ef87440":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_abdd78df376e4dbf8cb3ad62ed8fa7af","max":119,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec6ba65f8809413683e99d393dd6ef59","value":119}},"8724f200474d47e5bdbd480e932aa954":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ccea1201d9348dfb8ddfd38b68fae03":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e4c52ed06d446e8b79b1f9f86bdf725":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"924ec67482704413bbe7ecbac762dbb1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9299625368434ba7abb4d07a29778b78","placeholder":"​","style":"IPY_MODEL_2adc59debf0c4eadbb0d4bcc8ab35b91","value":" 6/6 [00:00&lt;00:00,  9.28it/s]"}},"9299625368434ba7abb4d07a29778b78":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93877449d2e1499bacabdae89aaf6597":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_104c0ea88b0a49c6a51f47ee0abeebcc","IPY_MODEL_380cc02da3ca4b7a956aaec0b4043c94","IPY_MODEL_49b4fecf969a4ea8a9d724bafa34e923"],"layout":"IPY_MODEL_99f4c994469e48cdb505b901d170adce"}},"99f4c994469e48cdb505b901d170adce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99f76a6c22dc4f5d9878577cfd5f1ce4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a64deb40760d41f6b64b0ef06f3571d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7c2fe324b2d481c99c0872d9751c0c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9a612ca6399450fa3d7362a401c02cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b034516492364112ab590d2648c4976d","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f7ea5de2e0a4288a909b6efef5202ab","value":112}},"abdd78df376e4dbf8cb3ad62ed8fa7af":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af2e66fbfb264f44b66337be13bf688d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b034516492364112ab590d2648c4976d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b34b47da76cf4b538051a836a00295e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b831de3747564aed869c0eca4210205d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f745fcb6209d40c6a2241f615dd7d592","placeholder":"​","style":"IPY_MODEL_41b4a95ce29a4e049c1527fb5650ce68","value":" 2857/2857 [00:00&lt;00:00, 9537.94it/s]"}},"b8e728b41e254779a4c9e47c057213ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_03414352c017411e801b6a954500d227","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dcfdf578afb448d99a86d5bf17fa942c","value":6}},"c428eb428e2f4d47be7179f11e6006f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c688d65e5b4c43bd80b25812902adbb6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4ac1af23a924c9b8633d51ccdf41a75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_57300c05be684f4581c56721c2ebba8d","max":586,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b89c8cd21b8434dac8638083b409fdd","value":586}},"d8eb56802e564365bae1869d4e28655c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8ffd89e5e784862b27dac85a4968db6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9278eadf845407c939ab44891d4b175":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcfdf578afb448d99a86d5bf17fa942c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e168d843812b40ba981774e725a2aa26":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e935fbb0caba4138ad8467680150105c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb50b7c8ffd34b56b467d1d9307a2561":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_60f6d636c19c494eaab4fd8b71d3452a","IPY_MODEL_b8e728b41e254779a4c9e47c057213ac","IPY_MODEL_924ec67482704413bbe7ecbac762dbb1"],"layout":"IPY_MODEL_4dde9a3114ed49c68485e5aa59d87c94"}},"ec6ba65f8809413683e99d393dd6ef59":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"edbf6291143049b891cc315d32f6415b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eec59ae1a8ff404f8ac16e017dff91f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f226779052714111b34c5fec7ea2ebb1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f540915da763489fb74cb685953685f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f745fcb6209d40c6a2241f615dd7d592":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#C01F4D; border-radius: 100px 100px; text-align:center\"> Install Required Libraries & Utils Function </h1></span>","metadata":{"papermill":{"duration":0.024973,"end_time":"2024-04-27T14:11:07.476924","exception":false,"start_time":"2024-04-27T14:11:07.451951","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Required Libraries\n# ====================================================\n\nimport os\nimport gc\nimport re\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nimport json\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"papermill":{"duration":6.47607,"end_time":"2024-04-27T14:11:13.977316","exception":false,"start_time":"2024-04-27T14:11:07.501246","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T08:56:04.305509Z","iopub.execute_input":"2024-06-03T08:56:04.305845Z","iopub.status.idle":"2024-06-03T08:56:11.418302Z","shell.execute_reply.started":"2024-06-03T08:56:04.305817Z","shell.execute_reply":"2024-06-03T08:56:11.417343Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"tokenizers.__version__: 0.15.2\ntransformers.__version__: 4.39.3\nenv: TOKENIZERS_PARALLELISM=true\ncuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# ====================================================\n# Configuration (Hyper Parameters Value)\n# ====================================================\n\nclass CFG:\n    debug=False # want to debug or not \n    apex=True # for faster training\n    print_freq= 300\n    num_workers=4 \n    model= \"aplycaebous/tb-XLM-R-fpt\"      \n    epochs=10\n    learning_rate=2e-5 \n    eps=1e-6\n    betas=(0.9, 0.999) # for adam optimizer\n    batch_size= 8 #32  # batch size\n    max_len=512\n    weight_decay=0.01 # for adam optimizer regulaization parameter\n    gradient_accumulation_steps=1\n    max_grad_norm=1000\n    target_cols=['offensive_gold'] #target columns\n    seed=42 # seed no. for random initialization \n    train=True\n    num_class = None # Number of class in your dataset\n    mode = \"cls_based\" #\"cls_based\", \"attention_based\", \"lstm_based\"\n","metadata":{"papermill":{"duration":0.033332,"end_time":"2024-04-27T14:11:14.036322","exception":false,"start_time":"2024-04-27T14:11:14.00299","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T08:56:11.420380Z","iopub.execute_input":"2024-06-03T08:56:11.421220Z","iopub.status.idle":"2024-06-03T08:56:11.427437Z","shell.execute_reply.started":"2024-06-03T08:56:11.421183Z","shell.execute_reply":"2024-06-03T08:56:11.426523Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def clean_dataframe(path):\n    with open(path, 'r') as file:\n        data = json.load(file)\n    \n    df = pd.DataFrame(data)\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-06-03T08:56:11.428633Z","iopub.execute_input":"2024-06-03T08:56:11.428913Z","iopub.status.idle":"2024-06-03T08:56:11.440978Z","shell.execute_reply.started":"2024-06-03T08:56:11.428890Z","shell.execute_reply":"2024-06-03T08:56:11.440164Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df_train = clean_dataframe('/kaggle/input/tb-olid/train.json')\n# df_train = df_train[df_train['code_mixed_gold']=='T']\ndf_train.drop(columns=['code_mixed_gold', 'target_gold'], inplace=True)\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T08:56:11.443453Z","iopub.execute_input":"2024-06-03T08:56:11.444117Z","iopub.status.idle":"2024-06-03T08:56:11.504938Z","shell.execute_reply.started":"2024-06-03T08:56:11.444090Z","shell.execute_reply":"2024-06-03T08:56:11.503862Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                text offensive_gold\n0                                eta ki kuno date??               N\n1   @Mehedi Hasan .  Notun SIM e prothom 54 taka ...              N\n2   @Sayed Islam .  Amader ei offer ti maximum 5 ...              N\n3   @Sumon .  amader shathe shorashori kotha bola...              N\n4   #Ajk Jdoi kono Hindo . Vuddo . Gristan ar upo...              N","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>offensive_gold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>eta ki kuno date??</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@Mehedi Hasan .  Notun SIM e prothom 54 taka ...</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@Sayed Islam .  Amader ei offer ti maximum 5 ...</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@Sumon .  amader shathe shorashori kotha bola...</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#Ajk Jdoi kono Hindo . Vuddo . Gristan ar upo...</td>\n      <td>N</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test = clean_dataframe('/kaggle/input/tb-olid/test.json')\n# df_test = df_test[df_test['code_mixed_gold']=='T']\ndf_test.drop(columns=['code_mixed_gold', 'target_gold'], inplace=True)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T08:56:11.506173Z","iopub.execute_input":"2024-06-03T08:56:11.506495Z","iopub.status.idle":"2024-06-03T08:56:11.530299Z","shell.execute_reply.started":"2024-06-03T08:56:11.506468Z","shell.execute_reply":"2024-06-03T08:56:11.529416Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                text offensive_gold\n0  \" ??? ???? ??? ??? Apni amake abal bolar ekbar...              N\n1  \" ??? ???? 0run out hoileu tore ami kisu bolta...              N\n2  \" ????? ??? ekjon valo manush keno tar sathe e...              N\n3  \" ?????? tmr babasakib ar kas thake sikhow ......              O\n4        \" ?????????? amar sim are network asea nah\"              N","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>offensive_gold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\" ??? ???? ??? ??? Apni amake abal bolar ekbar...</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\" ??? ???? 0run out hoileu tore ami kisu bolta...</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\" ????? ??? ekjon valo manush keno tar sathe e...</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\" ?????? tmr babasakib ar kas thake sikhow ......</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\" ?????????? amar sim are network asea nah\"</td>\n      <td>N</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"CFG.num_class = df_train[\"offensive_gold\"].nunique()\nprint(CFG.num_class)","metadata":{"papermill":{"duration":0.041702,"end_time":"2024-04-27T14:11:14.754989","exception":false,"start_time":"2024-04-27T14:11:14.713287","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T08:56:11.531406Z","iopub.execute_input":"2024-06-03T08:56:11.531744Z","iopub.status.idle":"2024-06-03T08:56:11.539584Z","shell.execute_reply.started":"2024-06-03T08:56:11.531714Z","shell.execute_reply":"2024-06-03T08:56:11.538771Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"2\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train['offensive_gold'] = df_train['offensive_gold'].map({'N':0, 'O':1})\ndf_test['offensive_gold'] = df_test['offensive_gold'].map({'N':0, 'O':1})","metadata":{"papermill":{"duration":1.161465,"end_time":"2024-04-27T14:11:15.94399","exception":false,"start_time":"2024-04-27T14:11:14.782525","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T08:56:11.541132Z","iopub.execute_input":"2024-06-03T08:56:11.541454Z","iopub.status.idle":"2024-06-03T08:56:11.551429Z","shell.execute_reply.started":"2024-06-03T08:56:11.541426Z","shell.execute_reply":"2024-06-03T08:56:11.550609Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"papermill":{"duration":0.03722,"end_time":"2024-04-27T14:11:16.157562","exception":false,"start_time":"2024-04-27T14:11:16.120342","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T08:56:11.552550Z","iopub.execute_input":"2024-06-03T08:56:11.552869Z","iopub.status.idle":"2024-06-03T08:56:11.565997Z","shell.execute_reply.started":"2024-06-03T08:56:11.552839Z","shell.execute_reply":"2024-06-03T08:56:11.564986Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                text  offensive_gold\n0                                eta ki kuno date??                0\n1   @Mehedi Hasan .  Notun SIM e prothom 54 taka ...               0\n2   @Sayed Islam .  Amader ei offer ti maximum 5 ...               0\n3   @Sumon .  amader shathe shorashori kotha bola...               0\n4   #Ajk Jdoi kono Hindo . Vuddo . Gristan ar upo...               0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>offensive_gold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>eta ki kuno date??</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@Mehedi Hasan .  Notun SIM e prothom 54 taka ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@Sayed Islam .  Amader ei offer ti maximum 5 ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@Sumon .  amader shathe shorashori kotha bola...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#Ajk Jdoi kono Hindo . Vuddo . Gristan ar upo...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# If Debugging is True then we will consider a small set of training data\n\nif CFG.debug:\n    CFG.epochs = 2\n    train = train.sample(frac =.1) ","metadata":{"papermill":{"duration":0.032059,"end_time":"2024-04-27T14:11:16.216366","exception":false,"start_time":"2024-04-27T14:11:16.184307","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T08:56:11.567174Z","iopub.execute_input":"2024-06-03T08:56:11.567535Z","iopub.status.idle":"2024-06-03T08:56:11.575863Z","shell.execute_reply.started":"2024-06-03T08:56:11.567503Z","shell.execute_reply":"2024-06-03T08:56:11.575070Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"papermill":{"duration":0.032462,"end_time":"2024-04-27T14:11:16.275552","exception":false,"start_time":"2024-04-27T14:11:16.24309","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T08:56:11.578989Z","iopub.execute_input":"2024-06-03T08:56:11.579260Z","iopub.status.idle":"2024-06-03T08:56:11.586851Z","shell.execute_reply.started":"2024-06-03T08:56:11.579230Z","shell.execute_reply":"2024-06-03T08:56:11.586003Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Logger File\n# ====================================================\n\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n\n\ndef get_logger(filename=OUTPUT_DIR+'train'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(CFG.seed)","metadata":{"papermill":{"duration":0.038673,"end_time":"2024-04-27T14:11:16.339457","exception":false,"start_time":"2024-04-27T14:11:16.300784","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T08:56:11.587746Z","iopub.execute_input":"2024-06-03T08:56:11.587973Z","iopub.status.idle":"2024-06-03T08:56:12.113782Z","shell.execute_reply.started":"2024-06-03T08:56:11.587953Z","shell.execute_reply":"2024-06-03T08:56:12.113019Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#C01F4D; border-radius: 100px 100px; text-align:center\"> Tokenizer, Dataset & Collate Function</h1></span>\n","metadata":{"papermill":{"duration":0.024977,"end_time":"2024-04-27T14:11:16.38981","exception":false,"start_time":"2024-04-27T14:11:16.364833","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\n\ntokenizer = AutoTokenizer.from_pretrained(CFG.model)\ntokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\nCFG.tokenizer = tokenizer","metadata":{"papermill":{"duration":1.296216,"end_time":"2024-04-27T14:11:17.71107","exception":false,"start_time":"2024-04-27T14:11:16.414854","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T08:56:12.114922Z","iopub.execute_input":"2024-06-03T08:56:12.115304Z","iopub.status.idle":"2024-06-03T08:56:16.171810Z","shell.execute_reply.started":"2024-06-03T08:56:12.115262Z","shell.execute_reply":"2024-06-03T08:56:16.171017Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d76447c3afa747dfa1c064bac8a9f562"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/693 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"582272b86f2843cabf5a5e0244f8ec09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30230d3ee37540b59ad6b88e92a44e33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"962d4a1c0292429ca0338cec1e4f5096"}},"metadata":{}}]},{"cell_type":"code","source":"# ====================================================\n# Define max_len\n# ====================================================\nlengths = []\ntk0 = tqdm(df_train['text'].fillna(\"\").values, total=len(df_train))\nfor text in tk0:\n    length = len(tokenizer(text, truncation=True, add_special_tokens=False)['input_ids'])\n    lengths.append(length)\n    \nif max(lengths) + 2 > 512:\n    CFG.max_len = 512\nelse:\n    CFG.max_len = max(lengths) + 2 # cls & sep \nLOGGER.info(f\"max_len: {CFG.max_len}\")","metadata":{"papermill":{"duration":0.346075,"end_time":"2024-04-27T14:11:18.083299","exception":false,"start_time":"2024-04-27T14:11:17.737224","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T08:56:16.172943Z","iopub.execute_input":"2024-06-03T08:56:16.173401Z","iopub.status.idle":"2024-06-03T08:56:16.692944Z","shell.execute_reply.started":"2024-06-03T08:56:16.173375Z","shell.execute_reply":"2024-06-03T08:56:16.692090Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b744eb3b4102487285d9d81bf527f7fa"}},"metadata":{}},{"name":"stderr","text":"max_len: 177\n","output_type":"stream"}]},{"cell_type":"code","source":"# ====================================================\n# Dataset Preparation\n# ====================================================\n\ndef prepare_input(cfg, text):\n    inputs = cfg.tokenizer.encode_plus(\n        text, \n        return_tensors=None, \n        add_special_tokens=True, \n        max_length=CFG.max_len,\n        pad_to_max_length=True,\n        truncation=True\n    )\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\nclass TrainDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['text'].values\n#         self.langs = df['lang'].values\n        self.labels = df[cfg.target_cols].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        text = self.texts[item]\n#         text = f'Lang {self.langs[item]} ' + text\n#         self.texts[item] = text\n        inputs = prepare_input(self.cfg, self.texts[item])\n        label = torch.tensor(self.labels[item], dtype=torch.long)\n        return inputs, label\n    \n\n# the colllate function to increase training speed\n\ndef collate(inputs): \n    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n    for k, v in inputs.items():\n        inputs[k] = inputs[k][:,:mask_len]\n    return inputs","metadata":{"papermill":{"duration":0.038244,"end_time":"2024-04-27T14:11:18.148053","exception":false,"start_time":"2024-04-27T14:11:18.109809","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T08:56:16.694194Z","iopub.execute_input":"2024-06-03T08:56:16.694543Z","iopub.status.idle":"2024-06-03T08:56:16.705292Z","shell.execute_reply.started":"2024-06-03T08:56:16.694512Z","shell.execute_reply":"2024-06-03T08:56:16.704468Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"\n# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#C01F4D; border-radius: 100px 100px; text-align:center\"> Model Architecture </h1></span>\n","metadata":{"papermill":{"duration":0.025563,"end_time":"2024-04-27T14:11:18.199614","exception":false,"start_time":"2024-04-27T14:11:18.174051","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n            self.config.hidden_dropout = 0.\n            self.config.hidden_dropout_prob = 0.\n            self.config.attention_dropout = 0.\n            self.config.attention_probs_dropout_prob = 0.\n            LOGGER.info(self.config)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        \n        # defining attention network for attention scores \n        self.attention = nn.Sequential(\n            nn.Linear(self.config.hidden_size, 512),\n            nn.Tanh(),\n            nn.Linear(512, 1),\n            nn.Softmax(dim=1))\n        \n        self.linear = nn.Linear(768, 768*2)\n        self.lstm = nn.LSTM(768*2, self.config.hidden_size)\n        \n        self._init_weights(self.attention)\n        self.concat_pool = nn.Linear(self.config.hidden_size*2, self.config.hidden_size)\n        self.fc = nn.Linear(self.config.hidden_size, self.cfg.num_class)\n        self._init_weights(self.fc)\n\n\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs.last_hidden_state # word level representation of last hiddent state\n        \n        if self.cfg.mode == \"attention_based\":\n            # attention based sentence representation\n            weights = self.attention(last_hidden_states)\n            feature = torch.sum(weights * last_hidden_states, dim=1)\n            \n            cls_token_feature = last_hidden_states[:, 0, :]\n#             print(feature.shape, cls_token_feature.shape)\n#             combine_feature = torch.cat([feature, cls_token_feature], dim = -1)\n#             feature = self.concat_pool(combine_feature)\n            feature += cls_token_feature\n            \n        if self.cfg.mode == \"cls_based\":\n            # [CLS] Token Repr\n            feature = last_hidden_states[:, 0, :]\n            weights= None\n            \n        if self.cfg.mode == \"lstm_based\":\n            x = last_hidden_states[:, 0, :]\n            x = self.linear(x)\n            feature, _ = self.lstm(x)\n            weights= None\n\n        return feature, weights\n\n    def forward(self, inputs):\n        feature, weights = self.feature(inputs)\n        output = self.fc(feature)\n        return output, weights","metadata":{"papermill":{"duration":0.044167,"end_time":"2024-04-27T14:11:18.269589","exception":false,"start_time":"2024-04-27T14:11:18.225422","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T08:56:16.706621Z","iopub.execute_input":"2024-06-03T08:56:16.706907Z","iopub.status.idle":"2024-06-03T08:56:16.724521Z","shell.execute_reply.started":"2024-06-03T08:56:16.706883Z","shell.execute_reply":"2024-06-03T08:56:16.723596Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"\n# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#C01F4D; border-radius: 100px 100px; text-align:center\"> Helpler functions for Training  </h1></span>\n\n<font size=\"3\">Few important function are created here.</font>\n\n1. <i>AverageMeter</i> - To compute & store the average\n2. <i>asMinutes</i> - To calculate the time\n3. <i>timeSince</i> - To compute training & validation time\n4. <i>train_fn</i> - Calculation of forward & backward pass for a single epoch in training data\n5. <i>valid_fn</i> - Calculation of forward & backward pass for a single epoch in validation data\n","metadata":{"papermill":{"duration":0.025783,"end_time":"2024-04-27T14:11:18.321599","exception":false,"start_time":"2024-04-27T14:11:18.295816","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Helper functions\n# ====================================================\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef train_fn(train_loader, model, criterion, optimizer, epoch, device):\n\n    \n    # Enabling Model Training Mode\n    model.train()\n     \n    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex) # using Automatic Mixed Precision (AMP) for speed up\n    losses = AverageMeter()\n    start = end = time.time()\n    global_step = 0\n    \n    for step, (inputs, labels) in enumerate(train_loader): # iterate over the training data \n        inputs = collate(inputs) # the collate function I discussed for speeding up training\n        \n        for k, v in inputs.items():\n            inputs[k] = v.to(device)  # formatting the input to feed into the transformer model \n        labels = labels.to(device) \n        batch_size = labels.size(0)\n        \n        with torch.cuda.amp.autocast(enabled=CFG.apex):\n            y_preds, _ = model(inputs) \n            loss = criterion(y_preds.view(-1, CFG.num_class), labels.view(-1))\n\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n        \n        scaler.scale(loss).backward() # backpropagation\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm) # clipping the gradient\n        \n        losses.update(loss.item(), batch_size)\n        \n        # Updating weights via optimizer & scaler\n        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n            global_step += 1\n        end = time.time()\n        \n        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n            print('Epoch: [{0}][{1}/{2}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  'Grad: {grad_norm:.4f}  '\n                  .format(epoch+1, step, len(train_loader), \n                          remain=timeSince(start, float(step+1)/len(train_loader)),\n                          loss=losses,\n                          grad_norm=grad_norm))\n\n    return losses.avg\n\n\ndef valid_fn(valid_loader, model, criterion, device):\n    losses = AverageMeter()\n    model.eval()\n    preds = []\n    start = end = time.time()\n    \n    for step, (inputs, labels) in enumerate(valid_loader): # iterate over the validation data \n        inputs = collate(inputs)\n        \n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        \n        with torch.no_grad(): # we don't need to store the gradients w.r.t validation data\n            y_preds, _ = model(inputs)\n            loss = criterion(y_preds.view(-1, CFG.num_class), labels.view(-1))\n            \n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n        \n        losses.update(loss.item(), batch_size)\n        preds.append(y_preds.to('cpu').numpy())\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n            print('EVAL: [{0}/{1}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  .format(step, len(valid_loader),\n                          loss=losses,\n                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n    predictions = np.concatenate(preds)\n    return losses.avg, predictions","metadata":{"papermill":{"duration":0.05031,"end_time":"2024-04-27T14:11:18.39816","exception":false,"start_time":"2024-04-27T14:11:18.34785","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T08:56:16.726006Z","iopub.execute_input":"2024-06-03T08:56:16.726465Z","iopub.status.idle":"2024-06-03T08:56:16.748947Z","shell.execute_reply.started":"2024-06-03T08:56:16.726433Z","shell.execute_reply":"2024-06-03T08:56:16.748082Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#C01F4D; border-radius: 100px 100px; text-align:center\"> Training Loop </h1></span>","metadata":{"papermill":{"duration":0.068843,"end_time":"2024-04-27T14:11:18.49297","exception":false,"start_time":"2024-04-27T14:11:18.424127","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.metrics import f1_score, classification_report\n\ndef get_score(y_trues, y_preds):\n    y_predicted = y_preds.argmax(axis=1)  # Convert probabilities to class predictions\n    macro_f1 = f1_score(y_trues, y_predicted, average='macro')\n#     print(classification_report(y_trues, y_predicted, digits=4))\n    return macro_f1","metadata":{"papermill":{"duration":0.044676,"end_time":"2024-04-27T14:11:18.568717","exception":false,"start_time":"2024-04-27T14:11:18.524041","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T08:56:16.750046Z","iopub.execute_input":"2024-06-03T08:56:16.750374Z","iopub.status.idle":"2024-06-03T08:56:16.763580Z","shell.execute_reply.started":"2024-06-03T08:56:16.750340Z","shell.execute_reply":"2024-06-03T08:56:16.762724Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# train loop\n# ====================================================\ndef train_loop():\n\n    # ====================================================\n    # loader\n    # ====================================================\n    \n    train_dataset = TrainDataset(CFG, df_train) # training dataset formatting \n    valid_dataset = TrainDataset(CFG, df_test) # validation dataset formatting\n\n    train_loader = DataLoader(train_dataset,\n                              batch_size=CFG.batch_size,\n                              shuffle=True,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True) # train dataloader\n    valid_loader = DataLoader(valid_dataset,\n                              batch_size=CFG.batch_size * 2,\n                              shuffle=False,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False) # validation dataloader\n\n    valid_labels = df_test[CFG.target_cols].values\n    \n    # ====================================================\n    # model & optimizer\n    # ====================================================\n    model = CustomModel(CFG, config_path=None, pretrained=True)  # initializing the model\n    torch.save(model.config, OUTPUT_DIR+'config.pth') # saving the model configuration \n    model.to(device) # GPU Config\n    \n    optimizer = AdamW(model.parameters(), lr=CFG.learning_rate, eps=CFG.eps, betas=CFG.betas) # declaring the optimizer\n    \n    criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n    best_score = 0\n\n\n    for epoch in range(CFG.epochs):\n\n        start_time = time.time()\n\n        # train function \n        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, device)\n\n        # eval function \n        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n        \n        # scoring\n        score = get_score(valid_labels, predictions)\n\n        elapsed = time.time() - start_time\n\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n        \n        if best_score < score: # Saving the best model w.r.t the score \n            best_score = score\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save({'model': model.state_dict(),\n                        'predictions': predictions},\n                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_score{best_score:.4f}_best.pth\")\n\n#     predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_score{best_score:.4f}_best.pth\", \n#                              map_location=torch.device('cpu'))['predictions']\n#     final_pred = predictions.argmax(axis=1)\n#     final_pred = final_pred.tolist()\n#     df_dev[f\"pred_label\"] = final_pred\n\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    return best_score","metadata":{"papermill":{"duration":0.048232,"end_time":"2024-04-27T14:11:18.646033","exception":false,"start_time":"2024-04-27T14:11:18.597801","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T08:56:16.765048Z","iopub.execute_input":"2024-06-03T08:56:16.765426Z","iopub.status.idle":"2024-06-03T08:56:16.777929Z","shell.execute_reply.started":"2024-06-03T08:56:16.765394Z","shell.execute_reply":"2024-06-03T08:56:16.777073Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# the training\n# ====================================================\n    \nif __name__ == '__main__':\n    \n    if CFG.train:\n        best_score = train_loop()","metadata":{"papermill":{"duration":67.545398,"end_time":"2024-04-27T14:12:26.218159","exception":false,"start_time":"2024-04-27T14:11:18.672761","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2024-06-03T08:56:16.779068Z","iopub.execute_input":"2024-06-03T08:56:16.779349Z","iopub.status.idle":"2024-06-03T09:06:04.360449Z","shell.execute_reply.started":"2024-06-03T08:56:16.779319Z","shell.execute_reply":"2024-06-03T09:06:04.359454Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"XLMRobertaConfig {\n  \"_name_or_path\": \"aplycaebous/tb-XLM-R-fpt\",\n  \"architectures\": [\n    \"XLMRobertaForMaskedLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"attention_probs_dropout_prob\": 0.0,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout\": 0.0,\n  \"hidden_dropout_prob\": 0.0,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"xlm-roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_hidden_states\": true,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.39.3\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 250002\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"012f0f4900594ebc92965cb2324329f1"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaModel were not initialized from the model checkpoint at aplycaebous/tb-XLM-R-fpt and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch: [1][0/500] Elapsed 0m 1s (remain 9m 19s) Loss: 0.6519(0.6519) Grad: 145296.7812  \nEpoch: [1][300/500] Elapsed 0m 34s (remain 0m 22s) Loss: 0.5638(0.5629) Grad: 110998.6875  \nEpoch: [1][499/500] Elapsed 0m 56s (remain 0m 0s) Loss: 0.3828(0.5314) Grad: 72772.8125  \nEVAL: [0/63] Elapsed 0m 0s (remain 0m 10s) Loss: 0.2116(0.2116) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 1 - avg_train_loss: 0.5314  avg_val_loss: 0.5243  time: 59s\nEpoch 1 - Score: 0.7447\nEpoch 1 - Save Best Score: 0.7447 Model\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [62/63] Elapsed 0m 2s (remain 0m 0s) Loss: 1.3471(0.5243) \nEpoch: [2][0/500] Elapsed 0m 0s (remain 1m 34s) Loss: 0.1851(0.1851) Grad: 391320.9375  \nEpoch: [2][300/500] Elapsed 0m 33s (remain 0m 22s) Loss: 0.0189(0.2823) Grad: 22313.9297  \nEpoch: [2][499/500] Elapsed 0m 55s (remain 0m 0s) Loss: 0.3431(0.2877) Grad: 206403.6562  \nEVAL: [0/63] Elapsed 0m 0s (remain 0m 9s) Loss: 0.3352(0.3352) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 - avg_train_loss: 0.2877  avg_val_loss: 1.0946  time: 58s\nEpoch 2 - Score: 0.6671\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [62/63] Elapsed 0m 2s (remain 0m 0s) Loss: 1.7838(1.0946) \nEpoch: [3][0/500] Elapsed 0m 0s (remain 1m 41s) Loss: 0.0097(0.0097) Grad: 42046.2383  \nEpoch: [3][300/500] Elapsed 0m 32s (remain 0m 21s) Loss: 0.0409(0.1757) Grad: 171095.7812  \nEpoch: [3][499/500] Elapsed 0m 55s (remain 0m 0s) Loss: 0.0023(0.2108) Grad: 700.3515  \nEVAL: [0/63] Elapsed 0m 0s (remain 0m 9s) Loss: 0.5313(0.5313) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 - avg_train_loss: 0.2108  avg_val_loss: 1.4773  time: 57s\nEpoch 3 - Score: 0.7341\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [62/63] Elapsed 0m 2s (remain 0m 0s) Loss: 2.8148(1.4773) \nEpoch: [4][0/500] Elapsed 0m 0s (remain 1m 40s) Loss: 0.8827(0.8827) Grad: nan  \nEpoch: [4][300/500] Elapsed 0m 33s (remain 0m 22s) Loss: 0.0002(0.1351) Grad: 30.1498  \nEpoch: [4][499/500] Elapsed 0m 55s (remain 0m 0s) Loss: 0.0003(0.1252) Grad: 628.2808  \nEVAL: [0/63] Elapsed 0m 0s (remain 0m 9s) Loss: 0.2139(0.2139) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 - avg_train_loss: 0.1252  avg_val_loss: 1.7273  time: 57s\nEpoch 4 - Score: 0.7489\nEpoch 4 - Save Best Score: 0.7489 Model\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [62/63] Elapsed 0m 2s (remain 0m 0s) Loss: 3.2580(1.7273) \nEpoch: [5][0/500] Elapsed 0m 0s (remain 1m 32s) Loss: 0.0001(0.0001) Grad: 414.1991  \nEpoch: [5][300/500] Elapsed 0m 32s (remain 0m 21s) Loss: 0.0001(0.0192) Grad: 269.5600  \nEpoch: [5][499/500] Elapsed 0m 55s (remain 0m 0s) Loss: 0.0001(0.0265) Grad: 3.8018  \nEVAL: [0/63] Elapsed 0m 0s (remain 0m 10s) Loss: 0.5127(0.5127) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 - avg_train_loss: 0.0265  avg_val_loss: 2.0881  time: 57s\nEpoch 5 - Score: 0.7404\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [62/63] Elapsed 0m 2s (remain 0m 0s) Loss: 2.9025(2.0881) \nEpoch: [6][0/500] Elapsed 0m 0s (remain 1m 23s) Loss: 0.0000(0.0000) Grad: 83.4777  \nEpoch: [6][300/500] Elapsed 0m 32s (remain 0m 21s) Loss: 0.7257(0.0259) Grad: 563068.8125  \nEpoch: [6][499/500] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0000(0.0205) Grad: 2.5324  \nEVAL: [0/63] Elapsed 0m 0s (remain 0m 9s) Loss: 0.4083(0.4083) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 - avg_train_loss: 0.0205  avg_val_loss: 2.0188  time: 57s\nEpoch 6 - Score: 0.7776\nEpoch 6 - Save Best Score: 0.7776 Model\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [62/63] Elapsed 0m 2s (remain 0m 0s) Loss: 3.6328(2.0188) \nEpoch: [7][0/500] Elapsed 0m 0s (remain 1m 27s) Loss: 0.0000(0.0000) Grad: 170.5397  \nEpoch: [7][300/500] Elapsed 0m 33s (remain 0m 21s) Loss: 0.0000(0.0062) Grad: 6.7469  \nEpoch: [7][499/500] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0000(0.0038) Grad: 3.5364  \nEVAL: [0/63] Elapsed 0m 0s (remain 0m 9s) Loss: 0.3003(0.3003) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 7 - avg_train_loss: 0.0038  avg_val_loss: 2.2470  time: 57s\nEpoch 7 - Score: 0.7509\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [62/63] Elapsed 0m 2s (remain 0m 0s) Loss: 4.2072(2.2470) \nEpoch: [8][0/500] Elapsed 0m 0s (remain 1m 38s) Loss: 0.0000(0.0000) Grad: 35.9993  \nEpoch: [8][300/500] Elapsed 0m 33s (remain 0m 21s) Loss: 0.0000(0.0000) Grad: 9.6554  \nEpoch: [8][499/500] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0000(0.0010) Grad: 4.3611  \nEVAL: [0/63] Elapsed 0m 0s (remain 0m 9s) Loss: 0.3819(0.3819) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 8 - avg_train_loss: 0.0010  avg_val_loss: 2.3283  time: 57s\nEpoch 8 - Score: 0.7498\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [62/63] Elapsed 0m 2s (remain 0m 0s) Loss: 4.3581(2.3283) \nEpoch: [9][0/500] Elapsed 0m 0s (remain 1m 30s) Loss: 0.0000(0.0000) Grad: 8.2441  \nEpoch: [9][300/500] Elapsed 0m 33s (remain 0m 21s) Loss: 0.0000(0.0017) Grad: 3.5807  \nEpoch: [9][499/500] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0000(0.0010) Grad: 3.4702  \nEVAL: [0/63] Elapsed 0m 0s (remain 0m 9s) Loss: 0.3955(0.3955) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 9 - avg_train_loss: 0.0010  avg_val_loss: 2.4021  time: 57s\nEpoch 9 - Score: 0.7486\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [62/63] Elapsed 0m 2s (remain 0m 0s) Loss: 4.4968(2.4021) \nEpoch: [10][0/500] Elapsed 0m 0s (remain 1m 26s) Loss: 0.0000(0.0000) Grad: 5.0668  \nEpoch: [10][300/500] Elapsed 0m 32s (remain 0m 21s) Loss: 0.0000(0.0017) Grad: 3.0523  \nEpoch: [10][499/500] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0000(0.0010) Grad: 2.0117  \nEVAL: [0/63] Elapsed 0m 0s (remain 0m 8s) Loss: 0.4051(0.4051) \n","output_type":"stream"},{"name":"stderr","text":"Epoch 10 - avg_train_loss: 0.0010  avg_val_loss: 2.4635  time: 57s\nEpoch 10 - Score: 0.7508\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [62/63] Elapsed 0m 2s (remain 0m 0s) Loss: 4.6124(2.4635) \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#C01F4D; border-radius: 100px 100px; text-align:center\">  Inference </h1></span>\n\n\n<font color='#3498DB'> <h3> <a id =\"section11a\"> <b> Configuration for Inference</b> </a> </h3> </font>\n\n<font size=\"3\"> The basic and important configuration for infernce is described here along with some function & other stuff.</font>\n","metadata":{"papermill":{"duration":0.029669,"end_time":"2024-04-27T14:12:26.34439","exception":false,"start_time":"2024-04-27T14:12:26.314721","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# CFG for testing\n# ====================================================\n\nclass CFG_Test:\n    num_workers=4\n    path=\"./\"\n    config_path=path+'config.pth'\n    model=CFG.model\n    batch_size=CFG.batch_size\n    target_cols=CFG.target_cols\n    seed=CFG.seed\n    num_class = CFG.num_class\n    mode = CFG.mode\n    \nCFG_Test.tokenizer = AutoTokenizer.from_pretrained(CFG_Test.path+'tokenizer/') # load the saved pretrained tokenizer","metadata":{"papermill":{"duration":0.059656,"end_time":"2024-04-27T14:12:26.433725","exception":false,"start_time":"2024-04-27T14:12:26.374069","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T09:06:04.361968Z","iopub.execute_input":"2024-06-03T09:06:04.362451Z","iopub.status.idle":"2024-06-03T09:06:05.029299Z","shell.execute_reply.started":"2024-06-03T09:06:04.362423Z","shell.execute_reply":"2024-06-03T09:06:05.028377Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def get_logger(filename='inference'): # infernece logger file\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()","metadata":{"papermill":{"duration":0.040023,"end_time":"2024-04-27T14:12:26.503839","exception":false,"start_time":"2024-04-27T14:12:26.463816","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T09:06:05.030648Z","iopub.execute_input":"2024-06-03T09:06:05.031295Z","iopub.status.idle":"2024-06-03T09:06:05.038272Z","shell.execute_reply.started":"2024-06-03T09:06:05.031250Z","shell.execute_reply":"2024-06-03T09:06:05.037397Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"<font color='#3498DB'> <h3> <b> Model Loading for Inference</b> </h3> </font>\n\n<font size=\"3\"> Dataset for predicting on the test data and Model Loading for inference are done in this section </font>","metadata":{"papermill":{"duration":0.028478,"end_time":"2024-04-27T14:12:26.561597","exception":false,"start_time":"2024-04-27T14:12:26.533119","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\ndef prepare_input(cfg, text):\n    inputs = cfg.tokenizer.encode_plus(\n        text, \n        return_tensors=None, \n        add_special_tokens=True)\n    \n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['text'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.texts[item])\n        return inputs","metadata":{"papermill":{"duration":0.039138,"end_time":"2024-04-27T14:12:26.629875","exception":false,"start_time":"2024-04-27T14:12:26.590737","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T09:06:05.039280Z","iopub.execute_input":"2024-06-03T09:06:05.039540Z","iopub.status.idle":"2024-06-03T09:06:05.053175Z","shell.execute_reply.started":"2024-06-03T09:06:05.039518Z","shell.execute_reply":"2024-06-03T09:06:05.052320Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"<font color='#3498DB'> <h3> <b> Prediction on Test Data</b></h3> </font>\n\n<font size=\"3\"> An inference function is made for predicting on the test data. Then finally, loading the previously saved model for each fold and taking prediction on test dataset for each fold. Then, take the average of the each of prediction is considered as model final prediction, </font>","metadata":{"papermill":{"duration":0.028593,"end_time":"2024-04-27T14:12:26.687041","exception":false,"start_time":"2024-04-27T14:12:26.658448","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in tk0: # iterate over the test data\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds, _ = model(inputs) # considering the logits only\n        preds.append(y_preds.to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions","metadata":{"papermill":{"duration":0.037788,"end_time":"2024-04-27T14:12:26.753384","exception":false,"start_time":"2024-04-27T14:12:26.715596","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T09:06:05.054199Z","iopub.execute_input":"2024-06-03T09:06:05.054459Z","iopub.status.idle":"2024-06-03T09:06:05.064835Z","shell.execute_reply.started":"2024-06-03T09:06:05.054437Z","shell.execute_reply":"2024-06-03T09:06:05.064087Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nfrom transformers import DataCollatorWithPadding\ntest_dataset = TestDataset(CFG_Test, df_test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG_Test.batch_size,\n                         shuffle=False,\n                         collate_fn=DataCollatorWithPadding(tokenizer=CFG_Test.tokenizer, padding='longest'))\n                         \n\nmodel = CustomModel(CFG_Test, config_path=CFG_Test.config_path, pretrained=True)\nstate = torch.load(CFG_Test.path+f\"{CFG_Test.model.replace('/', '-')}_score{best_score:.4f}_best.pth\",\n                   map_location=torch.device('cpu')) # loading the saved model\n\nmodel.load_state_dict(state['model'])\nprediction = inference_fn(test_loader, model, device)\ndel model, state; gc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:06:05.066023Z","iopub.execute_input":"2024-06-03T09:06:05.066365Z","iopub.status.idle":"2024-06-03T09:06:18.992131Z","shell.execute_reply.started":"2024-06-03T09:06:05.066336Z","shell.execute_reply":"2024-06-03T09:06:18.991080Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"2024-06-03 09:06:06.607506: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-03 09:06:06.607617: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-03 09:06:06.717286: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nSome weights of XLMRobertaModel were not initialized from the model checkpoint at aplycaebous/tb-XLM-R-fpt and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/125 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d01ddc300f464b8b99ab2113aad01c9b"}},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, classification_report\n\nprint('\\nThe Classification Report is as follows\\n')\nfinal_prediction = prediction.argmax(axis = 1)\nprint(classification_report(df_test['offensive_gold'].tolist(), final_prediction, digits = 4))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:06:18.993511Z","iopub.execute_input":"2024-06-03T09:06:18.993833Z","iopub.status.idle":"2024-06-03T09:06:19.009348Z","shell.execute_reply.started":"2024-06-03T09:06:18.993808Z","shell.execute_reply":"2024-06-03T09:06:19.008350Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"\nThe Classification Report is as follows\n\n              precision    recall  f1-score   support\n\n           0     0.7934    0.8447    0.8183       573\n           1     0.7718    0.7049    0.7368       427\n\n    accuracy                         0.7850      1000\n   macro avg     0.7826    0.7748    0.7776      1000\nweighted avg     0.7842    0.7850    0.7835      1000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# from transformers import DataCollatorWithPadding\n# test_dataset = TestDataset(CFG_Test, df_test)\n# test_loader = DataLoader(test_dataset,\n#                          batch_size=CFG_Test.batch_size,\n#                          shuffle=False,\n#                          collate_fn=DataCollatorWithPadding(tokenizer=CFG_Test.tokenizer, padding='longest'))\n                         \n\n# model = CustomModel(CFG_Test, config_path=CFG_Test.config_path, pretrained=True)\n# state = torch.load(CFG_Test.path+f\"{CFG_Test.model.replace('/', '-')}_score{best_score:.4f}_best.pth\",\n#                    map_location=torch.device('cpu')) # loading the saved model\n\n# model.load_state_dict(state['model'])\n# prediction = inference_fn(test_loader, model, device)\n# del model, state; gc.collect()\n# torch.cuda.empty_cache()\n    \n","metadata":{"papermill":{"duration":12.643409,"end_time":"2024-04-27T14:12:39.425549","exception":false,"start_time":"2024-04-27T14:12:26.78214","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-03T09:06:19.010592Z","iopub.execute_input":"2024-06-03T09:06:19.010870Z","iopub.status.idle":"2024-06-03T09:06:19.015475Z","shell.execute_reply.started":"2024-06-03T09:06:19.010848Z","shell.execute_reply":"2024-06-03T09:06:19.014575Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#C01F4D; border-radius: 100px 100px; text-align:center\"> Evaluation on Test Dataset </h1></span>\n","metadata":{"papermill":{"duration":0.028873,"end_time":"2024-04-27T14:12:39.484225","exception":false,"start_time":"2024-04-27T14:12:39.455352","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#C01F4D; border-radius: 100px 100px; text-align:center\"> Thanks for Reading </h1></span>","metadata":{"papermill":{"duration":0.029191,"end_time":"2024-04-27T14:12:39.69373","exception":false,"start_time":"2024-04-27T14:12:39.664539","status":"completed"},"tags":[]}},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.029286,"end_time":"2024-04-27T14:12:39.752188","exception":false,"start_time":"2024-04-27T14:12:39.722902","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}