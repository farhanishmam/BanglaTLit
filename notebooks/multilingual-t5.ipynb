{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8450937,"sourceType":"datasetVersion","datasetId":5036289},{"sourceId":8556524,"sourceType":"datasetVersion","datasetId":5113293}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-01T08:04:22.069253Z","iopub.status.busy":"2024-06-01T08:04:22.068569Z","iopub.status.idle":"2024-06-01T08:04:22.953091Z","shell.execute_reply":"2024-06-01T08:04:22.952191Z","shell.execute_reply.started":"2024-06-01T08:04:22.069221Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:04:22.955756Z","iopub.status.busy":"2024-06-01T08:04:22.954958Z","iopub.status.idle":"2024-06-01T08:04:36.184255Z","shell.execute_reply":"2024-06-01T08:04:36.183282Z","shell.execute_reply.started":"2024-06-01T08:04:22.955719Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: transformers in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (4.41.0)\n\nRequirement already satisfied: filelock in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (3.14.0)\n\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (0.23.0)\n\nRequirement already satisfied: numpy>=1.17 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (1.26.4)\n\nRequirement already satisfied: packaging>=20.0 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (24.0)\n\nRequirement already satisfied: pyyaml>=5.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (6.0.1)\n\nRequirement already satisfied: regex!=2019.12.17 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (2024.5.15)\n\nRequirement already satisfied: requests in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (2.32.1)\n\nRequirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (0.19.1)\n\nRequirement already satisfied: safetensors>=0.4.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (0.4.3)\n\nRequirement already satisfied: tqdm>=4.27 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (4.66.4)\n\nRequirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\n\nRequirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n\nRequirement already satisfied: colorama in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n\nRequirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from requests->transformers) (3.3.2)\n\nRequirement already satisfied: idna<4,>=2.5 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from requests->transformers) (3.7)\n\nRequirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from requests->transformers) (2.2.1)\n\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from requests->transformers) (2024.2.2)\n"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom transformers import AutoTokenizer, MT5Model, TrainingArguments, Trainer, MT5ForConditionalGeneration, AutoModelForSeq2SeqLM\nimport torch\nimport wandb\n\n# tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")\nmodel_name = \"google/mt5-base\" #\"google/mt5\"  # \"csebuetnlp/banglat5_nmt_en_bn\"Adjust if using a pre-trained model\n# model_name = \"csebuetnlp/banglat5\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\ntorch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel = MT5ForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n# model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(torch_device)","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:04:36.185953Z","iopub.status.busy":"2024-06-01T08:04:36.185643Z","iopub.status.idle":"2024-06-01T08:05:00.976410Z","shell.execute_reply":"2024-06-01T08:05:00.975593Z","shell.execute_reply.started":"2024-06-01T08:04:36.185918Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","output_type":"stream","text":"c:\\Users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n\n  from .autonotebook import tqdm as notebook_tqdm\n\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n\nYou are using a model of type t5 to instantiate a model of type mt5. This is not supported for all configurations of models and can yield errors.\n\nSome weights of MT5ForConditionalGeneration were not initialized from the model checkpoint at weights/checkpoint-8095 and are newly initialized: ['lm_head.weight']\n\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"}]},{"cell_type":"markdown","source":"### Dataset","metadata":{}},{"cell_type":"code","source":"! pip install git+https://github.com/csebuetnlp/normalizer\nfrom normalizer import normalize","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:00.979512Z","iopub.status.busy":"2024-06-01T08:05:00.978984Z","iopub.status.idle":"2024-06-01T08:05:25.284818Z","shell.execute_reply":"2024-06-01T08:05:25.283907Z","shell.execute_reply.started":"2024-06-01T08:05:00.979486Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","output_type":"stream","text":"Collecting git+https://github.com/csebuetnlp/normalizer\n\n  Cloning https://github.com/csebuetnlp/normalizer to c:\\users\\ooga\\appdata\\local\\temp\\pip-req-build-kgv40fsy\n\n  Resolved https://github.com/csebuetnlp/normalizer to commit d405944dde5ceeacb7c2fd3245ae2a9dea5f35c9\n\n  Preparing metadata (setup.py): started\n\n  Preparing metadata (setup.py): finished with status 'done'\n\nRequirement already satisfied: regex in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from normalizer==0.0.1) (2024.5.15)\n\nRequirement already satisfied: emoji==1.4.2 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from normalizer==0.0.1) (1.4.2)\n\nRequirement already satisfied: ftfy==6.0.3 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from normalizer==0.0.1) (6.0.3)\n\nRequirement already satisfied: wcwidth in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from ftfy==6.0.3->normalizer==0.0.1) (0.2.13)\n"},{"name":"stderr","output_type":"stream","text":"  Running command git clone --filter=blob:none --quiet https://github.com/csebuetnlp/normalizer 'C:\\Users\\ooga\\AppData\\Local\\Temp\\pip-req-build-kgv40fsy'\n"}]},{"cell_type":"code","source":"df_train = pd.read_csv(\"data/train.csv\")\ndf_test = pd.read_csv(\"data/test.csv\")\ndf_val =  pd.read_csv(\"data/val.csv\")","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:25.286386Z","iopub.status.busy":"2024-06-01T08:05:25.286080Z","iopub.status.idle":"2024-06-01T08:05:25.678216Z","shell.execute_reply":"2024-06-01T08:05:25.677407Z","shell.execute_reply.started":"2024-06-01T08:05:25.286356Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df_train = df_train[:100]\ndf_val = df_val[:20]","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:25.679596Z","iopub.status.busy":"2024-06-01T08:05:25.679304Z","iopub.status.idle":"2024-06-01T08:05:25.702902Z","shell.execute_reply":"2024-06-01T08:05:25.701885Z","shell.execute_reply.started":"2024-06-01T08:05:25.679571Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(df_train.isna().sum())\nprint(df_test.isna().sum())\nprint(df_val.isna().sum())\n\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:25.704263Z","iopub.status.busy":"2024-06-01T08:05:25.703976Z","iopub.status.idle":"2024-06-01T08:05:25.730186Z","shell.execute_reply":"2024-06-01T08:05:25.729142Z","shell.execute_reply.started":"2024-06-01T08:05:25.704239Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","output_type":"stream","text":"id                     0\n\ndataset                0\n\ntext_transliterated    0\n\ntext_bengali           0\n\ndtype: int64\n\nid                     0\n\ndataset                0\n\ntext_transliterated    0\n\ntext_bengali           0\n\ndtype: int64\n\nid                     0\n\ndataset                0\n\ntext_transliterated    0\n\ntext_bengali           0\n\ndtype: int64\n"}]},{"cell_type":"markdown","source":"## Dataset Preprocessing\n### Normalize","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\n# Download necessary NLTK resources (may need internet connection)\nnltk.download('punkt')\nnltk.download('stopwords')\n\ndef clean_text(text, language='english'):\n    text = ''.join([char for char in text if char.isalnum() or char.isspace()])\n\n    # Convert to lowercase\n    text = text.lower()\n\n    # Remove stopwords (optional, adjust stopword list based on language)\n    stop_words = stopwords.words(language)\n    text = ' '.join([word for word in text.split() if word not in stop_words])\n\n    return text\n\n# Clean Banglish and Bengali text\n# df['Banglish_Clean'] = df['Banglish'].apply(clean_text)\n# df['Bengali_Clean'] = df['Bengali'].apply(clean_text, language='bengali')  # Specify Bengali for stopword removal\n\n# Normalization for Bengali text (replace with your desired normalization function)\ndef normalize_bengali(text):\n    normalized_text = normalize(text)\n    return normalized_text\n\ndf_train['normalized_bengali'] = df_train['text_bengali'].apply(normalize_bengali)\ndf_test['normalized_bengali'] = df_test['text_bengali'].apply(normalize_bengali)\ndf_val['normalized_bengali'] = df_val['text_bengali'].apply(normalize_bengali)\n","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:25.731654Z","iopub.status.busy":"2024-06-01T08:05:25.731390Z","iopub.status.idle":"2024-06-01T08:05:33.429144Z","shell.execute_reply":"2024-06-01T08:05:33.428372Z","shell.execute_reply.started":"2024-06-01T08:05:25.731629Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","output_type":"stream","text":"[nltk_data] Downloading package punkt to\n\n[nltk_data]     C:\\Users\\ooga\\AppData\\Roaming\\nltk_data...\n\n[nltk_data]   Package punkt is already up-to-date!\n\n[nltk_data] Downloading package stopwords to\n\n[nltk_data]     C:\\Users\\ooga\\AppData\\Roaming\\nltk_data...\n\n[nltk_data]   Package stopwords is already up-to-date!\n"}]},{"cell_type":"code","source":"df_train[\"normalized_bengali\"][0]","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:33.430542Z","iopub.status.busy":"2024-06-01T08:05:33.430242Z","iopub.status.idle":"2024-06-01T08:05:33.436711Z","shell.execute_reply":"2024-06-01T08:05:33.435785Z","shell.execute_reply.started":"2024-06-01T08:05:33.430517Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":["'à¦«à§‹à¦¨ à¦°à§‡à¦œà§à¦²à§‡à¦¶à¦¨ à§ªà§®à§¦à¦ªà¦¿, à¦­à¦¿à¦¡à¦¿à¦“ à¦°à§‡à¦•à¦°à§à¦¡à¦¿à¦‚ à§§à§¦à§®à§¦à¦ªà¦¿! à¦¹à¦¾à¦“?'"]},"metadata":{}}]},{"cell_type":"markdown","source":"### pad and truncate all the dfs","metadata":{}},{"cell_type":"code","source":"def find_max_length(df, column_name):\n    # Find the index of the text with the maximum length\n    max_length_index = df[column_name].str.len().idxmax()\n\n    # Get the text with the maximum length\n    max_length_text = df.loc[max_length_index, column_name]\n\n    # Print the maximum length and the corresponding text\n#     print(f\"Index of the text with maximum length: {max_length_index}\")\n#     print(f\"Maximum length: {len(max_length_text)}\")\n#     print(f\"Text with maximum length:\\n{max_length_text}\")\n    return len(max_length_text)\n\n# find_max_length(df_train, 'text_bengali')\n# print(df_train['text_bengali'][10454])","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:33.440747Z","iopub.status.busy":"2024-06-01T08:05:33.440416Z","iopub.status.idle":"2024-06-01T08:05:33.450570Z","shell.execute_reply":"2024-06-01T08:05:33.449603Z","shell.execute_reply.started":"2024-06-01T08:05:33.440723Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\ndef pad_truncate(df):\n    max_length = 200\n#     print(max_length)\n    bengali_tokenized = tokenizer(df['normalized_bengali'].tolist(), padding=\"max_length\", truncation=True)\n#     print(bengali_tokenized)\n#     max_length = find_max_length(df, 'text_transliterated')\n    banglish_tokenized = tokenizer(df['text_transliterated'].tolist(), padding=\"max_length\", truncation=True)\n\n    dataset = Dataset.from_dict({\n        \"input_ids\": banglish_tokenized[\"input_ids\"],\n        \"attention_mask\": banglish_tokenized[\"attention_mask\"],\n        \"labels\": bengali_tokenized[\"input_ids\"]  # Labels are target language tokens\n    })\n    \n    return dataset\n\ntrain_dataset = pad_truncate(df_train)\n# print(banglish, bengali)\n# pad_truncate(df_test)\n# pad_truncate(df_val)","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:33.451906Z","iopub.status.busy":"2024-06-01T08:05:33.451628Z","iopub.status.idle":"2024-06-01T08:05:59.035104Z","shell.execute_reply":"2024-06-01T08:05:59.034206Z","shell.execute_reply.started":"2024-06-01T08:05:33.451883Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# test_dataset['input_ids'][0]","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:59.036709Z","iopub.status.busy":"2024-06-01T08:05:59.036377Z","iopub.status.idle":"2024-06-01T08:05:59.040923Z","shell.execute_reply":"2024-06-01T08:05:59.040053Z","shell.execute_reply.started":"2024-06-01T08:05:59.036680Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# len(train_dataset['labels'][0])","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:59.043210Z","iopub.status.busy":"2024-06-01T08:05:59.042502Z","iopub.status.idle":"2024-06-01T08:06:11.531323Z","shell.execute_reply":"2024-06-01T08:06:11.530375Z","shell.execute_reply.started":"2024-06-01T08:05:59.043172Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"test_dataset = pad_truncate(df_test)\nval_dataset = pad_truncate(df_val)","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:11.533073Z","iopub.status.busy":"2024-06-01T08:06:11.532678Z","iopub.status.idle":"2024-06-01T08:06:13.904205Z","shell.execute_reply":"2024-06-01T08:06:13.903114Z","shell.execute_reply.started":"2024-06-01T08:06:11.533038Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Model training","metadata":{}},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n# training_args = TrainingArguments(\n#     output_dir=\"./mt5_banglish_bengali\",  # Output directory for checkpoints\n#     evaluation_strategy=\"steps\",\n#     overwrite_output_dir=True,  # Overwrite existing directory if it exists\n#     num_train_epochs=3,  # Adjust based on dataset size and desired accuracy\n#     per_device_train_batch_size=2,  # Adjust batch size based on GPU memory\n#     save_steps=50,  # Save model checkpoints every 10,000 steps\n#     save_total_limit=2,  # Keep only the most recent 2 checkpoints\n#     logging_steps=50,  # Log training progress every 500 steps\n#     fp16 = True,\n#     gradient_accumulation_steps = 6,\n#     load_best_model_at_end=True  # Load the best model based on validation metrics\n# )\n\nbatch_size = 4\nargs = Seq2SeqTrainingArguments(output_dir=\"weights\",\n                        evaluation_strategy=\"epoch\",\n                        save_strategy = \"epoch\",\n                        per_device_train_batch_size=batch_size,\n                        per_device_eval_batch_size=batch_size,\n                        learning_rate=2e-5,\n                        num_train_epochs=5,\n                        weight_decay=0.01,\n                        save_total_limit=3,\n                        predict_with_generate=True,\n                        fp16 = False,\n                        gradient_accumulation_steps = 6,\n                        save_steps = 50,\n                        logging_steps = 50,\n                        load_best_model_at_end=True,\n                        logging_dir=\"/logs\",\n                        report_to=\"wandb\")","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:13.905939Z","iopub.status.busy":"2024-06-01T08:06:13.905537Z","iopub.status.idle":"2024-06-01T08:06:13.942493Z","shell.execute_reply":"2024-06-01T08:06:13.941543Z","shell.execute_reply.started":"2024-06-01T08:06:13.905903Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","output_type":"stream","text":"c:\\Users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n\n  warnings.warn(\n"}]},{"cell_type":"code","source":"# df_train","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:13.943913Z","iopub.status.busy":"2024-06-01T08:06:13.943609Z","iopub.status.idle":"2024-06-01T08:06:13.947952Z","shell.execute_reply":"2024-06-01T08:06:13.946794Z","shell.execute_reply.started":"2024-06-01T08:06:13.943883Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# from datasets import Dataset\n\n# dataset = Dataset.from_dict({\n#     \"input_ids\": banglish_tokenized[\"input_ids\"],\n#     \"attention_mask\": banglish_tokenized[\"attention_mask\"],\n#     \"labels\": bengali_tokenized[\"input_ids\"]  # Labels are target language tokens\n# })\n\n# train_dataset = dataset.train_test_split(test_size=0.2)  # Split into train and validation sets\n","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:13.949912Z","iopub.status.busy":"2024-06-01T08:06:13.949571Z","iopub.status.idle":"2024-06-01T08:06:13.961157Z","shell.execute_reply":"2024-06-01T08:06:13.960356Z","shell.execute_reply.started":"2024-06-01T08:06:13.949881Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# df = pd.DataFrame(dataset)","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:13.962482Z","iopub.status.busy":"2024-06-01T08:06:13.962202Z","iopub.status.idle":"2024-06-01T08:06:13.971683Z","shell.execute_reply":"2024-06-01T08:06:13.970778Z","shell.execute_reply.started":"2024-06-01T08:06:13.962459Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# df.isna().sum(axis = 0)","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:13.972957Z","iopub.status.busy":"2024-06-01T08:06:13.972677Z","iopub.status.idle":"2024-06-01T08:06:13.986005Z","shell.execute_reply":"2024-06-01T08:06:13.985092Z","shell.execute_reply.started":"2024-06-01T08:06:13.972934Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"!pip install bert-score","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:13.987510Z","iopub.status.busy":"2024-06-01T08:06:13.987160Z","iopub.status.idle":"2024-06-01T08:06:26.413604Z","shell.execute_reply":"2024-06-01T08:06:26.412469Z","shell.execute_reply.started":"2024-06-01T08:06:13.987479Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: bert-score in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (0.3.13)\n\nRequirement already satisfied: torch>=1.0.0 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from bert-score) (2.2.0+cu121)\n\nRequirement already satisfied: pandas>=1.0.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from bert-score) (2.2.2)\n\nRequirement already satisfied: transformers>=3.0.0 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from bert-score) (4.41.0)\n\nRequirement already satisfied: numpy in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from bert-score) (1.26.4)\n\nRequirement already satisfied: requests in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from bert-score) (2.32.1)\n\nRequirement already satisfied: tqdm>=4.31.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from bert-score) (4.66.4)\n\nRequirement already satisfied: matplotlib in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from bert-score) (3.9.0)\n\nRequirement already satisfied: packaging>=20.9 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from bert-score) (24.0)\n\nRequirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n\nRequirement already satisfied: pytz>=2020.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n\nRequirement already satisfied: tzdata>=2022.7 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n\nRequirement already satisfied: filelock in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.14.0)\n\nRequirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from torch>=1.0.0->bert-score) (4.11.0)\n\nRequirement already satisfied: sympy in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from torch>=1.0.0->bert-score) (1.12)\n\nRequirement already satisfied: networkx in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.3)\n\nRequirement already satisfied: jinja2 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.1.4)\n\nRequirement already satisfied: fsspec in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from torch>=1.0.0->bert-score) (2024.3.1)\n\nRequirement already satisfied: colorama in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from tqdm>=4.31.1->bert-score) (0.4.6)\n\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.23.0)\n\nRequirement already satisfied: pyyaml>=5.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n\nRequirement already satisfied: regex!=2019.12.17 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers>=3.0.0->bert-score) (2024.5.15)\n\nRequirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.19.1)\n\nRequirement already satisfied: safetensors>=0.4.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.4.3)\n\nRequirement already satisfied: contourpy>=1.0.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->bert-score) (1.2.1)\n\nRequirement already satisfied: cycler>=0.10 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->bert-score) (0.12.1)\n\nRequirement already satisfied: fonttools>=4.22.0 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->bert-score) (4.51.0)\n\nRequirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->bert-score) (1.4.5)\n\nRequirement already satisfied: pillow>=8 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->bert-score) (10.3.0)\n\nRequirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->bert-score) (3.1.2)\n\nRequirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from requests->bert-score) (3.3.2)\n\nRequirement already satisfied: idna<4,>=2.5 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from requests->bert-score) (3.7)\n\nRequirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from requests->bert-score) (2.2.1)\n\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from requests->bert-score) (2024.2.2)\n\nRequirement already satisfied: six>=1.5 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n\nRequirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.5)\n\nRequirement already satisfied: mpmath>=0.19 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n"}]},{"cell_type":"code","source":"from datasets import load_metric\n\n# Load the BERTScore metric\nbert_metric = load_metric('bertscore')","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:26.415428Z","iopub.status.busy":"2024-06-01T08:06:26.415128Z","iopub.status.idle":"2024-06-01T08:06:26.830461Z","shell.execute_reply":"2024-06-01T08:06:26.829613Z","shell.execute_reply.started":"2024-06-01T08:06:26.415399Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","output_type":"stream","text":"C:\\Users\\ooga\\AppData\\Local\\Temp\\ipykernel_14588\\1619319013.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n\n  bert_metric = load_metric('bertscore')\n\nc:\\Users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for bertscore contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/bertscore/bertscore.py\n\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\n\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n\n  warnings.warn(\n"}]},{"cell_type":"code","source":"def compute_metrics(preds_and_labels):\n    preds, labels = preds_and_labels\n\n    # Decode the predictions and labels using the tokenizer, skipping special tokens\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    \n    # Replace -100 (masked tokens) in labels with the pad token ID\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    \n    # Decode the labels using the tokenizer, skipping special tokens\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    # Compute BERTScore using decoded predictions and labels\n    result = bert_metric.compute(predictions=decoded_preds, references=decoded_labels, lang='bn')\n    \n    # Return the BERTScore as a dictionary\n    return {\n      'BERT F1': np.mean(result['f1']),\n      'BERT Precision': np.mean(result['precision']),\n      'BERT Recall': np.mean(result['recall'])\n  }","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:26.831828Z","iopub.status.busy":"2024-06-01T08:06:26.831568Z","iopub.status.idle":"2024-06-01T08:06:26.838624Z","shell.execute_reply":"2024-06-01T08:06:26.837731Z","shell.execute_reply.started":"2024-06-01T08:06:26.831803Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\n# Instantiate a Seq2Seq model from the specified checkpoint\n\n# Define a data collator for Seq2Seq tasks\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:26.839944Z","iopub.status.busy":"2024-06-01T08:06:26.839668Z","iopub.status.idle":"2024-06-01T08:06:26.851718Z","shell.execute_reply":"2024-06-01T08:06:26.850892Z","shell.execute_reply.started":"2024-06-01T08:06:26.839921Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=args,\n    data_collator=data_collator,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,\n    compute_metrics = compute_metrics\n)","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:26.853239Z","iopub.status.busy":"2024-06-01T08:06:26.852921Z","iopub.status.idle":"2024-06-01T08:06:27.506813Z","shell.execute_reply":"2024-06-01T08:06:27.505900Z","shell.execute_reply.started":"2024-06-01T08:06:26.853209Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:27.508152Z","iopub.status.busy":"2024-06-01T08:06:27.507901Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\nFailed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmushahid\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":"c:\\Users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages\\transformers\\generation\\utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n\n  warnings.warn(\n\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [02:48<00:00,  2.22it/s]\n"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 1.0521430969238281,\n"," 'eval_BERT F1': 0.8490847468773524,\n"," 'eval_BERT Precision': 0.8660194059610367,\n"," 'eval_BERT Recall': 0.8342954052686691,\n"," 'eval_runtime': 169.0374,\n"," 'eval_samples_per_second': 8.874,\n"," 'eval_steps_per_second': 2.218,\n"," 'epoch': 4.998970769864141}"]},"metadata":{}}]},{"cell_type":"code","source":"def predict_output(input_sentence):\n    input_ids = tokenizer(normalize(input_sentence), return_tensors=\"pt\").input_ids.to(\"cuda\")\n    generated_tokens = model.generate(input_ids)\n    decoded_tokens = tokenizer.batch_decode(generated_tokens)[0]\n    decoded_tokens = normalize(decoded_tokens)\n\n    return decoded_tokens\n\nprint(\"start\")\ndf_val['predictions'] = df_val['text_transliterated'].apply(predict_output)\ndf_val.to_csv(\"mT5_val.csv\", index=False)\nprint(\"complete\")\n    \n# df_test.to_csv(\"banglaT5_small.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":"start\n"},{"name":"stderr","output_type":"stream","text":"c:\\Users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages\\transformers\\generation\\utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n\n  warnings.warn(\n"},{"name":"stdout","output_type":"stream","text":"complete\n"}]},{"cell_type":"code","source":"print(\"start\")\ndf_test['predictions'] = df_test['text_transliterated'].apply(predict_output)\ndf_test.to_csv(\"mT5_test.csv\", index=False)\nprint(\"complete\")","metadata":{},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":"start\n\ncomplete\n"}]},{"cell_type":"code","source":"import nltk\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction, closest_ref_length, brevity_penalty\nfrom nltk.tokenize import word_tokenize\nimport math\n\n# Ensure you have the punkt tokenizer models\nnltk.download('punkt')\n\ndef calculate_bleu(reference_sentence, candidate_sentence):\n\n  # Tokenize the sentences\n    reference = [word_tokenize(reference_sentence)]\n    candidate = word_tokenize(candidate_sentence)\n\n    # Define the smoothing function\n    smoothing_function = SmoothingFunction().method1\n\n  # Calculate BLEU-1\n    bleu1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0), smoothing_function=smoothing_function)\n  # Calculate BLEU-2\n    bleu2 = sentence_bleu(reference, candidate, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothing_function)\n  # Calculate BLEU-3\n    bleu3 = sentence_bleu(reference, candidate, weights=(0.33, 0.33, 0.33, 0), smoothing_function=smoothing_function)\n  # Calculate BLEU-4\n    bleu4 = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothing_function)\n\n    hyp_len = len(candidate)\n    ref_len = len(reference[0])\n    closest_ref_len =  closest_ref_length(reference, hyp_len)\n    bp = brevity_penalty(closest_ref_len, hyp_len)\n\n    ratio = hyp_len/ref_len\n\n    return bp*pow((bleu1*bleu2*bleu3*bleu4), 1/4), bp, ratio\n\n# Example reference and candidate sentences in Bangla\nreference_sentence = \"à¦†à¦ªà¦¨à¦¿à¦“ à¦¶à§à¦°à§ à¦à¦–à¦¨, à¦…à§à¦¯à¦¾à¦ª à¦¨à¦¾à¦® à¦¸à¦¾à¦‡à¦œ à¦•à¦‡à¥¤\"\ncandidate_sentence = \"à¦†à¦ªà¦¨à¦¿à¦“ à¦¶à§à¦°à§ à¦à¦–à¦¨, à¦…à§à¦¯à¦¾à¦ª à¦¨à¦¾à¦® à¦¸à¦¾à¦‡à¦œ à¦•à¦‡à¥¤ \"\ncalculate_bleu(reference_sentence, candidate_sentence)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nfrom nltk.translate.meteor_score import meteor_score\nfrom nltk.tokenize import word_tokenize\n\n# Example reference and candidate sentences in Bangla\nreference_sentence = \"à¦†à¦ªà¦¨à¦¿à¦“ à¦¶à§à¦°à§ à¦à¦–à¦¨, à¦…à§à¦¯à¦¾à¦ª à¦¨à¦¾à¦® à¦¸à¦¾à¦‡à¦œ à¦•à¦‡à¥¤\"\ncandidate_sentence = \"à¦†à¦ªà¦¨à¦¿à¦“ à¦¶à§à¦°à§ à¦à¦–à¦¨, à¦…à§à¦¯à¦¾à¦ª à¦¨à¦¾à¦® à¦¸à¦¾à¦‡à¦œ à¦•à¦‡à¥¤\"\n\nreference = [word_tokenize(reference_sentence)]\ncandidate = word_tokenize(candidate_sentence)\nprint(meteor_score(reference, candidate))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchmetrics.text.bert import BERTScore\n\nbertscore = BERTScore()\n\npreds = [\"à¦†à¦ªà¦¨à¦¿à¦“ à¦¶à§à¦°à§ à¦à¦–à¦¨, à¦…à§à¦¯à¦¾à¦ª à¦¨à¦¾à¦® à¦¸à¦¾à¦‡à¦œ à¦•à¦‡à¥¤\"]\ntarget = [\"à¦†à¦ªà¦¨à¦¿à¦“ à¦¶à§à¦°à§ à¦à¦–à¦¨, à¦…à§à¦¯à¦¾à¦ª à¦‡à¦‰à¦œà¦¾à¦° à¦¨à¦¾à¦® à¦¸à¦¾à¦‡à¦œ à¦•à¦‡à¥¤\"]\n\nprint(bertscore(preds, target))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.util import ngrams\n\n# Function to calculate ROUGE-1, ROUGE-2, and ROUGE-L scores for a pair of texts\ndef calculate_rouge_scores(reference_tokens, system_tokens):\n    def lcs(X, Y):\n        m, n = len(X), len(Y)\n        dp = [[0] * (n + 1) for _ in range(m + 1)]\n\n        for i in range(1, m + 1):\n            for j in range(1, n + 1):\n                if X[i - 1] == Y[j - 1]:\n                    dp[i][j] = dp[i - 1][j - 1] + 1\n                else:\n                    dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n\n        return dp[m][n]\n\n    # Calculate ROUGE-1 (unigram) scores\n    reference_unigrams = set(reference_tokens)\n    system_unigrams = set(system_tokens)\n    overlap_rouge1 = len(reference_unigrams.intersection(system_unigrams))\n    precision_rouge1 = overlap_rouge1 / len(system_unigrams)\n    recall_rouge1 = overlap_rouge1 / len(reference_unigrams)\n    r1_t = 1 if precision_rouge1 + recall_rouge1 == 0 else 0\n    f1_rouge1 = 2 * (precision_rouge1 * recall_rouge1) / (precision_rouge1 + recall_rouge1 + r1_t)\n\n    # Calculate ROUGE-2 (bigram) scores\n    reference_bigrams = set(ngrams(reference_tokens, 2))\n    system_bigrams = set(ngrams(system_tokens, 2))\n    overlap_rouge2 = len(reference_bigrams.intersection(system_bigrams))\n    precision_rouge2 = overlap_rouge2 / len(system_bigrams)\n    recall_rouge2 = overlap_rouge2 / len(reference_bigrams)\n    r2_t = 1 if precision_rouge2 + recall_rouge2 == 0 else 1\n    f1_rouge2 = 2 * (precision_rouge2 * recall_rouge2) / (precision_rouge2 + recall_rouge2 + r2_t)\n\n    # Calculate ROUGE-L scores\n    lcs_length = lcs(reference_tokens, system_tokens)\n    precision_rougeL = lcs_length / len(system_tokens)\n    recall_rougeL = lcs_length / len(reference_tokens)\n    rL_t = 1 if precision_rougeL + recall_rougeL == 0 else 0\n    f1_rougeL = 2 * (precision_rougeL * recall_rougeL) / (precision_rougeL + recall_rougeL + rL_t)\n\n    return {\n        'ROUGE-1 Precision': precision_rouge1,\n        'ROUGE-1 Recall': recall_rouge1,\n        'ROUGE-1 F1': f1_rouge1,\n        'ROUGE-2 Precision': precision_rouge2,\n        'ROUGE-2 Recall': recall_rouge2,\n        'ROUGE-2 F1': f1_rouge2,\n        'ROUGE-L Precision': precision_rougeL,\n        'ROUGE-L Recall': recall_rougeL,\n        'ROUGE-L F1': f1_rougeL,\n    }\n\n# Function to calculate the average of ROUGE scores for an array of text pairs\ndef calculate_average_rouge_scores(reference_texts, system_texts):\n    total_scores = {\n        'ROUGE-1 Precision': 0,\n        'ROUGE-1 Recall': 0,\n        'ROUGE-1 F1': 0,\n        'ROUGE-2 Precision': 0,\n        'ROUGE-2 Recall': 0,\n        'ROUGE-2 F1': 0,\n        'ROUGE-L Precision': 0,\n        'ROUGE-L Recall': 0,\n        'ROUGE-L F1': 0,\n    }\n\n    num_pairs = len(reference_texts)\n\n    for i in range(num_pairs):\n        reference_text = reference_texts[i]\n        system_text = system_texts[i]\n\n        reference_tokens = nltk.word_tokenize(reference_text)\n        system_tokens = nltk.word_tokenize(system_text)\n\n        scores = calculate_rouge_scores(reference_tokens, system_tokens)\n\n        for key, value in scores.items():\n            total_scores[key] += value\n\n    # Calculate the average scores\n    average_scores = {key: value / num_pairs for key, value in total_scores.items()}\n    \n    return average_scores\n\n# Example usage with an array of reference and system texts\n# reference_texts = test_d_ground\n# system_texts = [correct_grammar(test_d_sentence[i],num_return_sequences=2,input_len=test_d_len[i])[0] for i in range(len(test_d_sentence)) ]\n\nreference_texts = [\"à¦†à¦ªà¦¨à¦¿à¦“ à¦¶à§à¦°à§ à¦à¦–à¦¨, à¦…à§à¦¯à¦¾à¦ª à¦¨à¦¾à¦® à¦¸à¦¾à¦‡à¦œ à¦•à¦‡à¥¤\", \"à¦†à¦ªà¦¨à¦¿à¦“ à¦¶à§à¦°à§ à¦à¦–à¦¨, à¦…à§à¦¯à¦¾à¦ª à¦¨à¦¾à¦® à¦¸à¦¾à¦‡à¦œ à¦•à¦‡à¥¤\"]\nsystem_texts = [\"à¦†à¦ªà¦¨à¦¿à¦“ à¦¶à§à¦°à§ à¦à¦–à¦¨, à¦…à§à¦¯à¦¾à¦ª à¦‡à¦‰à¦œà¦¾à¦° à¦¨à¦¾à¦® à¦¸à¦¾à¦‡à¦œ à¦•à¦‡à¥¤\", \"à¦†à¦ªà¦¨à¦¿à¦“ à¦¶à§à¦°à§ à¦à¦–à¦¨, à¦…à§à¦¯à¦¾à¦ª à¦‡à¦‰à¦œà¦¾à¦° à¦¨à¦¾à¦® à¦¸à¦¾à¦‡à¦œ à¦•à¦‡à¥¤\"]\n\n\naverage_scores = calculate_average_rouge_scores(reference_texts, system_texts)\nprint(\"Average ROUGE Scores:\")\nfor key, value in average_scores.items():\n    print(key + \": {:.4f}\".format(value))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}