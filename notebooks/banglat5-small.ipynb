{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8450937,"sourceType":"datasetVersion","datasetId":5036289},{"sourceId":8556524,"sourceType":"datasetVersion","datasetId":5113293}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-01T08:04:22.069253Z","iopub.status.busy":"2024-06-01T08:04:22.068569Z","iopub.status.idle":"2024-06-01T08:04:22.953091Z","shell.execute_reply":"2024-06-01T08:04:22.952191Z","shell.execute_reply.started":"2024-06-01T08:04:22.069221Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:04:22.955756Z","iopub.status.busy":"2024-06-01T08:04:22.954958Z","iopub.status.idle":"2024-06-01T08:04:36.184255Z","shell.execute_reply":"2024-06-01T08:04:36.183282Z","shell.execute_reply.started":"2024-06-01T08:04:22.955719Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: transformers in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (4.41.0)\n\nRequirement already satisfied: filelock in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (3.14.0)\n\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (0.23.0)\n\nRequirement already satisfied: numpy>=1.17 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (1.26.4)\n\nRequirement already satisfied: packaging>=20.0 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (24.0)\n\nRequirement already satisfied: pyyaml>=5.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (6.0.1)\n\nRequirement already satisfied: regex!=2019.12.17 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (2024.5.15)\n\nRequirement already satisfied: requests in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (2.32.1)\n\nRequirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (0.19.1)\n\nRequirement already satisfied: safetensors>=0.4.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (0.4.3)\n\nRequirement already satisfied: tqdm>=4.27 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers) (4.66.4)\n\nRequirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\n\nRequirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n\nRequirement already satisfied: colorama in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n\nRequirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from requests->transformers) (3.3.2)\n\nRequirement already satisfied: idna<4,>=2.5 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from requests->transformers) (3.7)\n\nRequirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from requests->transformers) (2.2.1)\n\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from requests->transformers) (2024.2.2)\n"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom transformers import AutoTokenizer, MT5Model, TrainingArguments, Trainer, MT5ForConditionalGeneration, AutoModelForSeq2SeqLM\nimport torch\n\n# tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")\nmodel_name = \"csebuetnlp/banglat5_small\" #\"google/mt5-small\"  # \"csebuetnlp/banglat5_nmt_en_bn\"Adjust if using a pre-trained model\n\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\ntorch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# model = MT5ForConditionalGeneration.from_pretrained(model_name).to(torch_device)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(torch_device)","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:04:36.185953Z","iopub.status.busy":"2024-06-01T08:04:36.185643Z","iopub.status.idle":"2024-06-01T08:05:00.976410Z","shell.execute_reply":"2024-06-01T08:05:00.975593Z","shell.execute_reply.started":"2024-06-01T08:04:36.185918Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","output_type":"stream","text":"c:\\Users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n\n  from .autonotebook import tqdm as notebook_tqdm\n\nYou are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"}]},{"cell_type":"markdown","source":"### Dataset","metadata":{}},{"cell_type":"code","source":"! pip install git+https://github.com/csebuetnlp/normalizer\nfrom normalizer import normalize","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:00.979512Z","iopub.status.busy":"2024-06-01T08:05:00.978984Z","iopub.status.idle":"2024-06-01T08:05:25.284818Z","shell.execute_reply":"2024-06-01T08:05:25.283907Z","shell.execute_reply.started":"2024-06-01T08:05:00.979486Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","output_type":"stream","text":"Collecting git+https://github.com/csebuetnlp/normalizer\n\n  Cloning https://github.com/csebuetnlp/normalizer to c:\\users\\ooga\\appdata\\local\\temp\\pip-req-build-0lziefdy\n\n  Resolved https://github.com/csebuetnlp/normalizer to commit d405944dde5ceeacb7c2fd3245ae2a9dea5f35c9\n\n  Preparing metadata (setup.py): started\n\n  Preparing metadata (setup.py): finished with status 'done'\n\nRequirement already satisfied: regex in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from normalizer==0.0.1) (2024.5.15)\n\nRequirement already satisfied: emoji==1.4.2 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from normalizer==0.0.1) (1.4.2)\n\nRequirement already satisfied: ftfy==6.0.3 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from normalizer==0.0.1) (6.0.3)\n\nRequirement already satisfied: wcwidth in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from ftfy==6.0.3->normalizer==0.0.1) (0.2.13)\n"},{"name":"stderr","output_type":"stream","text":"  Running command git clone --filter=blob:none --quiet https://github.com/csebuetnlp/normalizer 'C:\\Users\\ooga\\AppData\\Local\\Temp\\pip-req-build-0lziefdy'\n"}]},{"cell_type":"code","source":"df_train = pd.read_csv(\"data/train.csv\")\ndf_test = pd.read_csv(\"data/test.csv\")\ndf_val =  pd.read_csv(\"data/val.csv\")","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:25.286386Z","iopub.status.busy":"2024-06-01T08:05:25.286080Z","iopub.status.idle":"2024-06-01T08:05:25.678216Z","shell.execute_reply":"2024-06-01T08:05:25.677407Z","shell.execute_reply.started":"2024-06-01T08:05:25.286356Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:25.679596Z","iopub.status.busy":"2024-06-01T08:05:25.679304Z","iopub.status.idle":"2024-06-01T08:05:25.702902Z","shell.execute_reply":"2024-06-01T08:05:25.701885Z","shell.execute_reply.started":"2024-06-01T08:05:25.679571Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>dataset</th>\n","      <th>text_transliterated</th>\n","      <th>text_bengali</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>e3839126-f351-4ff2-81b2-0d347a93b2db</td>\n","      <td>penta_trickbd_external</td>\n","      <td>Phone resulation 480p,vedio recording 1080p! How?</td>\n","      <td>ফোন রেজুলেশন ৪৮০পি, ভিডিও রেকর্ডিং ১০৮০পি! হাও?</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>b14214ab-a53d-47d4-9e58-298e1b3e6f42</td>\n","      <td>penta_trickbd_external</td>\n","      <td>Flash Tool Ki Letest Verson</td>\n","      <td>ফ্ল্যাশ টুল কি লেটেস্ট ভার্সন</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>20d6a478-daac-4459-b362-cfd076a5ee50</td>\n","      <td>penta_trickbd_external</td>\n","      <td>yes..Oem to Unlock kortey hobe ar root korar p...</td>\n","      <td>ইয়েস..ওএম তো আনলক করতে হবে আর রুট করার পর ও সে...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13f5078f-3f6c-4a81-be24-b3ef1cc8c984</td>\n","      <td>penta_trickbd_external</td>\n","      <td>lav nai oi eki joma dite jawai lagbe tokhn tak...</td>\n","      <td>লাভ নাই ওই একি জমা দিতে যাওয়াই লাগবে তখন টাকা ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>85b9e667-07a2-4861-bbfa-49b5b3107a79</td>\n","      <td>penta_trickbd_external</td>\n","      <td>Deliverer option nai amar.. ki korbo</td>\n","      <td>ডেলিভারার অপশন নেই আমার.. কি করব</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>38859</th>\n","      <td>bc6da3ec-7dc7-4b00-a31f-45e3e3082499</td>\n","      <td>springer_autobacktransliteration</td>\n","      <td>Eder ke mati chapa deya dorkar</td>\n","      <td>এদের কে মাটি চাপা দেয়া দরকার</td>\n","    </tr>\n","    <tr>\n","      <th>38860</th>\n","      <td>4c8ce30f-9119-4ebd-9ac0-7049dcb8a17d</td>\n","      <td>springer_autobacktransliteration</td>\n","      <td>Oder ekdin bichar hobe vai</td>\n","      <td>ওদের একদিন বিচার হবে ভাই</td>\n","    </tr>\n","    <tr>\n","      <th>38861</th>\n","      <td>c698d5b7-d06f-401b-9eac-c38081f49bb0</td>\n","      <td>springer_autobacktransliteration</td>\n","      <td>Opekkha koren</td>\n","      <td>অপেক্ষা করেন</td>\n","    </tr>\n","    <tr>\n","      <th>38862</th>\n","      <td>67d48ea7-85a6-450c-8367-c3c1aa4ecd45</td>\n","      <td>springer_autobacktransliteration</td>\n","      <td>Shomoy ashbe</td>\n","      <td>সময় আসবে</td>\n","    </tr>\n","    <tr>\n","      <th>38863</th>\n","      <td>1c2e996f-8249-4107-924a-798d65039cd9</td>\n","      <td>springer_autobacktransliteration</td>\n","      <td>Amadero somoy ashbe</td>\n","      <td>আমাদেরও সময় আসবে</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>38864 rows × 4 columns</p>\n","</div>"],"text/plain":["                                         id                           dataset  \\\n","0      e3839126-f351-4ff2-81b2-0d347a93b2db            penta_trickbd_external   \n","1      b14214ab-a53d-47d4-9e58-298e1b3e6f42            penta_trickbd_external   \n","2      20d6a478-daac-4459-b362-cfd076a5ee50            penta_trickbd_external   \n","3      13f5078f-3f6c-4a81-be24-b3ef1cc8c984            penta_trickbd_external   \n","4      85b9e667-07a2-4861-bbfa-49b5b3107a79            penta_trickbd_external   \n","...                                     ...                               ...   \n","38859  bc6da3ec-7dc7-4b00-a31f-45e3e3082499  springer_autobacktransliteration   \n","38860  4c8ce30f-9119-4ebd-9ac0-7049dcb8a17d  springer_autobacktransliteration   \n","38861  c698d5b7-d06f-401b-9eac-c38081f49bb0  springer_autobacktransliteration   \n","38862  67d48ea7-85a6-450c-8367-c3c1aa4ecd45  springer_autobacktransliteration   \n","38863  1c2e996f-8249-4107-924a-798d65039cd9  springer_autobacktransliteration   \n","\n","                                     text_transliterated  \\\n","0      Phone resulation 480p,vedio recording 1080p! How?   \n","1                            Flash Tool Ki Letest Verson   \n","2      yes..Oem to Unlock kortey hobe ar root korar p...   \n","3      lav nai oi eki joma dite jawai lagbe tokhn tak...   \n","4                   Deliverer option nai amar.. ki korbo   \n","...                                                  ...   \n","38859                     Eder ke mati chapa deya dorkar   \n","38860                         Oder ekdin bichar hobe vai   \n","38861                                      Opekkha koren   \n","38862                                       Shomoy ashbe   \n","38863                                Amadero somoy ashbe   \n","\n","                                            text_bengali  \n","0        ফোন রেজুলেশন ৪৮০পি, ভিডিও রেকর্ডিং ১০৮০পি! হাও?  \n","1                          ফ্ল্যাশ টুল কি লেটেস্ট ভার্সন  \n","2      ইয়েস..ওএম তো আনলক করতে হবে আর রুট করার পর ও সে...  \n","3      লাভ নাই ওই একি জমা দিতে যাওয়াই লাগবে তখন টাকা ...  \n","4                       ডেলিভারার অপশন নেই আমার.. কি করব  \n","...                                                  ...  \n","38859                       এদের কে মাটি চাপা দেয়া দরকার  \n","38860                           ওদের একদিন বিচার হবে ভাই  \n","38861                                       অপেক্ষা করেন  \n","38862                                           সময় আসবে  \n","38863                                   আমাদেরও সময় আসবে  \n","\n","[38864 rows x 4 columns]"]},"metadata":{}}]},{"cell_type":"code","source":"print(df_train.isna().sum())\nprint(df_test.isna().sum())\nprint(df_val.isna().sum())","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:25.704263Z","iopub.status.busy":"2024-06-01T08:05:25.703976Z","iopub.status.idle":"2024-06-01T08:05:25.730186Z","shell.execute_reply":"2024-06-01T08:05:25.729142Z","shell.execute_reply.started":"2024-06-01T08:05:25.704239Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","output_type":"stream","text":"id                     0\n\ndataset                0\n\ntext_transliterated    0\n\ntext_bengali           0\n\ndtype: int64\n\nid                     0\n\ndataset                0\n\ntext_transliterated    0\n\ntext_bengali           0\n\ndtype: int64\n\nid                     0\n\ndataset                0\n\ntext_transliterated    0\n\ntext_bengali           0\n\ndtype: int64\n"}]},{"cell_type":"markdown","source":"## Dataset Preprocessing\n### Normalize","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\n# Download necessary NLTK resources (may need internet connection)\nnltk.download('punkt')\nnltk.download('stopwords')\n\ndef clean_text(text, language='english'):\n    text = ''.join([char for char in text if char.isalnum() or char.isspace()])\n\n    # Convert to lowercase\n    text = text.lower()\n\n    # Remove stopwords (optional, adjust stopword list based on language)\n    stop_words = stopwords.words(language)\n    text = ' '.join([word for word in text.split() if word not in stop_words])\n\n    return text\n\n# Clean Banglish and Bengali text\n# df['Banglish_Clean'] = df['Banglish'].apply(clean_text)\n# df['Bengali_Clean'] = df['Bengali'].apply(clean_text, language='bengali')  # Specify Bengali for stopword removal\n\n# Normalization for Bengali text (replace with your desired normalization function)\ndef normalize_bengali(text):\n    normalized_text = normalize(text)\n    return normalized_text\n\ndf_train['normalized_bengali'] = df_train['text_bengali'].apply(normalize_bengali)\ndf_test['normalized_bengali'] = df_test['text_bengali'].apply(normalize_bengali)\ndf_val['normalized_bengali'] = df_val['text_bengali'].apply(normalize_bengali)\n","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:25.731654Z","iopub.status.busy":"2024-06-01T08:05:25.731390Z","iopub.status.idle":"2024-06-01T08:05:33.429144Z","shell.execute_reply":"2024-06-01T08:05:33.428372Z","shell.execute_reply.started":"2024-06-01T08:05:25.731629Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","output_type":"stream","text":"[nltk_data] Downloading package punkt to\n\n[nltk_data]     C:\\Users\\ooga\\AppData\\Roaming\\nltk_data...\n\n[nltk_data]   Package punkt is already up-to-date!\n\n[nltk_data] Downloading package stopwords to\n\n[nltk_data]     C:\\Users\\ooga\\AppData\\Roaming\\nltk_data...\n\n[nltk_data]   Package stopwords is already up-to-date!\n"}]},{"cell_type":"code","source":"df_train[\"normalized_bengali\"][0]","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:33.430542Z","iopub.status.busy":"2024-06-01T08:05:33.430242Z","iopub.status.idle":"2024-06-01T08:05:33.436711Z","shell.execute_reply":"2024-06-01T08:05:33.435785Z","shell.execute_reply.started":"2024-06-01T08:05:33.430517Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":["'ফোন রেজুলেশন ৪৮০পি, ভিডিও রেকর্ডিং ১০৮০পি! হাও?'"]},"metadata":{}}]},{"cell_type":"markdown","source":"### pad and truncate all the dfs","metadata":{}},{"cell_type":"code","source":"def find_max_length(df, column_name):\n    # Find the index of the text with the maximum length\n    max_length_index = df[column_name].str.len().idxmax()\n\n    # Get the text with the maximum length\n    max_length_text = df.loc[max_length_index, column_name]\n\n    # Print the maximum length and the corresponding text\n#     print(f\"Index of the text with maximum length: {max_length_index}\")\n#     print(f\"Maximum length: {len(max_length_text)}\")\n#     print(f\"Text with maximum length:\\n{max_length_text}\")\n    return len(max_length_text)\n\n# find_max_length(df_train, 'text_bengali')\n# print(df_train['text_bengali'][10454])","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:33.440747Z","iopub.status.busy":"2024-06-01T08:05:33.440416Z","iopub.status.idle":"2024-06-01T08:05:33.450570Z","shell.execute_reply":"2024-06-01T08:05:33.449603Z","shell.execute_reply.started":"2024-06-01T08:05:33.440723Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\ndef pad_truncate(df):\n    max_length = 200\n#     print(max_length)\n    bengali_tokenized = tokenizer(df['normalized_bengali'].tolist(), padding=\"max_length\", truncation=True)\n#     print(bengali_tokenized)\n#     max_length = find_max_length(df, 'text_transliterated')\n    banglish_tokenized = tokenizer(df['text_transliterated'].tolist(), padding=\"max_length\", truncation=True)\n\n    dataset = Dataset.from_dict({\n        \"input_ids\": banglish_tokenized[\"input_ids\"],\n        \"attention_mask\": banglish_tokenized[\"attention_mask\"],\n        \"labels\": bengali_tokenized[\"input_ids\"]  # Labels are target language tokens\n    })\n    \n    return dataset\n\ntrain_dataset = pad_truncate(df_train)\n# print(banglish, bengali)\n# pad_truncate(df_test)\n# pad_truncate(df_val)","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:33.451906Z","iopub.status.busy":"2024-06-01T08:05:33.451628Z","iopub.status.idle":"2024-06-01T08:05:59.035104Z","shell.execute_reply":"2024-06-01T08:05:59.034206Z","shell.execute_reply.started":"2024-06-01T08:05:33.451883Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# test_dataset['input_ids'][0]","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:59.036709Z","iopub.status.busy":"2024-06-01T08:05:59.036377Z","iopub.status.idle":"2024-06-01T08:05:59.040923Z","shell.execute_reply":"2024-06-01T08:05:59.040053Z","shell.execute_reply.started":"2024-06-01T08:05:59.036680Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# len(train_dataset['labels'][0])","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:05:59.043210Z","iopub.status.busy":"2024-06-01T08:05:59.042502Z","iopub.status.idle":"2024-06-01T08:06:11.531323Z","shell.execute_reply":"2024-06-01T08:06:11.530375Z","shell.execute_reply.started":"2024-06-01T08:05:59.043172Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"test_dataset = pad_truncate(df_test)\nval_dataset = pad_truncate(df_val)","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:11.533073Z","iopub.status.busy":"2024-06-01T08:06:11.532678Z","iopub.status.idle":"2024-06-01T08:06:13.904205Z","shell.execute_reply":"2024-06-01T08:06:13.903114Z","shell.execute_reply.started":"2024-06-01T08:06:11.533038Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Model training","metadata":{}},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n# training_args = TrainingArguments(\n#     output_dir=\"./mt5_banglish_bengali\",  # Output directory for checkpoints\n#     evaluation_strategy=\"steps\",\n#     overwrite_output_dir=True,  # Overwrite existing directory if it exists\n#     num_train_epochs=3,  # Adjust based on dataset size and desired accuracy\n#     per_device_train_batch_size=2,  # Adjust batch size based on GPU memory\n#     save_steps=50,  # Save model checkpoints every 10,000 steps\n#     save_total_limit=2,  # Keep only the most recent 2 checkpoints\n#     logging_steps=50,  # Log training progress every 500 steps\n#     fp16 = True,\n#     gradient_accumulation_steps = 6,\n#     load_best_model_at_end=True  # Load the best model based on validation metrics\n# )\n\nbatch_size = 4\nargs = Seq2SeqTrainingArguments(output_dir=\"weights\",\n                        evaluation_strategy=\"epoch\",\n                        save_strategy = \"epoch\",\n                        per_device_train_batch_size=batch_size,\n                        per_device_eval_batch_size=batch_size,\n                        learning_rate=2e-5,\n                        num_train_epochs=5,\n                        weight_decay=0.01,\n                        save_total_limit=3,\n                        predict_with_generate=True,\n                        fp16 = False,\n                        gradient_accumulation_steps = 6,\n                        save_steps = 50,\n                        logging_steps = 50,\n                        load_best_model_at_end=True,\n                        logging_dir=\"/logs\",\n                        report_to=\"wandb\")","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:13.905939Z","iopub.status.busy":"2024-06-01T08:06:13.905537Z","iopub.status.idle":"2024-06-01T08:06:13.942493Z","shell.execute_reply":"2024-06-01T08:06:13.941543Z","shell.execute_reply.started":"2024-06-01T08:06:13.905903Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","output_type":"stream","text":"c:\\Users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n\n  warnings.warn(\n"}]},{"cell_type":"code","source":"# df_train","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:13.943913Z","iopub.status.busy":"2024-06-01T08:06:13.943609Z","iopub.status.idle":"2024-06-01T08:06:13.947952Z","shell.execute_reply":"2024-06-01T08:06:13.946794Z","shell.execute_reply.started":"2024-06-01T08:06:13.943883Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# from datasets import Dataset\n\n# dataset = Dataset.from_dict({\n#     \"input_ids\": banglish_tokenized[\"input_ids\"],\n#     \"attention_mask\": banglish_tokenized[\"attention_mask\"],\n#     \"labels\": bengali_tokenized[\"input_ids\"]  # Labels are target language tokens\n# })\n\n# train_dataset = dataset.train_test_split(test_size=0.2)  # Split into train and validation sets\n","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:13.949912Z","iopub.status.busy":"2024-06-01T08:06:13.949571Z","iopub.status.idle":"2024-06-01T08:06:13.961157Z","shell.execute_reply":"2024-06-01T08:06:13.960356Z","shell.execute_reply.started":"2024-06-01T08:06:13.949881Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# df = pd.DataFrame(dataset)","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:13.962482Z","iopub.status.busy":"2024-06-01T08:06:13.962202Z","iopub.status.idle":"2024-06-01T08:06:13.971683Z","shell.execute_reply":"2024-06-01T08:06:13.970778Z","shell.execute_reply.started":"2024-06-01T08:06:13.962459Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# df.isna().sum(axis = 0)","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:13.972957Z","iopub.status.busy":"2024-06-01T08:06:13.972677Z","iopub.status.idle":"2024-06-01T08:06:13.986005Z","shell.execute_reply":"2024-06-01T08:06:13.985092Z","shell.execute_reply.started":"2024-06-01T08:06:13.972934Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"!pip install bert-score","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:13.987510Z","iopub.status.busy":"2024-06-01T08:06:13.987160Z","iopub.status.idle":"2024-06-01T08:06:26.413604Z","shell.execute_reply":"2024-06-01T08:06:26.412469Z","shell.execute_reply.started":"2024-06-01T08:06:13.987479Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: bert-score in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (0.3.13)\n\nRequirement already satisfied: torch>=1.0.0 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from bert-score) (2.2.0+cu121)\n\nRequirement already satisfied: pandas>=1.0.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from bert-score) (2.2.2)\n\nRequirement already satisfied: transformers>=3.0.0 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from bert-score) (4.41.0)\n\nRequirement already satisfied: numpy in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from bert-score) (1.26.4)\n\nRequirement already satisfied: requests in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from bert-score) (2.32.1)\n\nRequirement already satisfied: tqdm>=4.31.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from bert-score) (4.66.4)\n\nRequirement already satisfied: matplotlib in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from bert-score) (3.9.0)\n\nRequirement already satisfied: packaging>=20.9 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from bert-score) (24.0)\n\nRequirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n\nRequirement already satisfied: pytz>=2020.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n\nRequirement already satisfied: tzdata>=2022.7 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n\nRequirement already satisfied: filelock in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.14.0)\n\nRequirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from torch>=1.0.0->bert-score) (4.11.0)\n\nRequirement already satisfied: sympy in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from torch>=1.0.0->bert-score) (1.12)\n\nRequirement already satisfied: networkx in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.3)\n\nRequirement already satisfied: jinja2 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.1.4)\n\nRequirement already satisfied: fsspec in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from torch>=1.0.0->bert-score) (2024.3.1)\n\nRequirement already satisfied: colorama in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from tqdm>=4.31.1->bert-score) (0.4.6)\n\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.23.0)\n\nRequirement already satisfied: pyyaml>=5.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n\nRequirement already satisfied: regex!=2019.12.17 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers>=3.0.0->bert-score) (2024.5.15)\n\nRequirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.19.1)\n\nRequirement already satisfied: safetensors>=0.4.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.4.3)\n\nRequirement already satisfied: contourpy>=1.0.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->bert-score) (1.2.1)\n\nRequirement already satisfied: cycler>=0.10 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->bert-score) (0.12.1)\n\nRequirement already satisfied: fonttools>=4.22.0 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->bert-score) (4.51.0)\n\nRequirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->bert-score) (1.4.5)\n\nRequirement already satisfied: pillow>=8 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->bert-score) (10.3.0)\n\nRequirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->bert-score) (3.1.2)\n\nRequirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from requests->bert-score) (3.3.2)\n\nRequirement already satisfied: idna<4,>=2.5 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from requests->bert-score) (3.7)\n\nRequirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from requests->bert-score) (2.2.1)\n\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from requests->bert-score) (2024.2.2)\n\nRequirement already satisfied: six>=1.5 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n\nRequirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.5)\n\nRequirement already satisfied: mpmath>=0.19 in c:\\users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n"}]},{"cell_type":"code","source":"from datasets import load_metric\n\n# Load the BERTScore metric\nbert_metric = load_metric('bertscore')","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:26.415428Z","iopub.status.busy":"2024-06-01T08:06:26.415128Z","iopub.status.idle":"2024-06-01T08:06:26.830461Z","shell.execute_reply":"2024-06-01T08:06:26.829613Z","shell.execute_reply.started":"2024-06-01T08:06:26.415399Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","output_type":"stream","text":"C:\\Users\\ooga\\AppData\\Local\\Temp\\ipykernel_10268\\1619319013.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n\n  bert_metric = load_metric('bertscore')\n\nc:\\Users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for bertscore contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/bertscore/bertscore.py\n\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\n\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n\n  warnings.warn(\n"}]},{"cell_type":"code","source":"def compute_metrics(preds_and_labels):\n    preds, labels = preds_and_labels\n\n    # Decode the predictions and labels using the tokenizer, skipping special tokens\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    \n    # Replace -100 (masked tokens) in labels with the pad token ID\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    \n    # Decode the labels using the tokenizer, skipping special tokens\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    # Compute BERTScore using decoded predictions and labels\n    result = bert_metric.compute(predictions=decoded_preds, references=decoded_labels, lang='bn')\n    \n    # Return the BERTScore as a dictionary\n    return {\n      'BERT F1': np.mean(result['f1']),\n      'BERT Precision': np.mean(result['precision']),\n      'BERT Recall': np.mean(result['recall'])\n  }","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:26.831828Z","iopub.status.busy":"2024-06-01T08:06:26.831568Z","iopub.status.idle":"2024-06-01T08:06:26.838624Z","shell.execute_reply":"2024-06-01T08:06:26.837731Z","shell.execute_reply.started":"2024-06-01T08:06:26.831803Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\n# Instantiate a Seq2Seq model from the specified checkpoint\n\n# Define a data collator for Seq2Seq tasks\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:26.839944Z","iopub.status.busy":"2024-06-01T08:06:26.839668Z","iopub.status.idle":"2024-06-01T08:06:26.851718Z","shell.execute_reply":"2024-06-01T08:06:26.850892Z","shell.execute_reply.started":"2024-06-01T08:06:26.839921Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=args,\n    data_collator=data_collator,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,\n    compute_metrics = compute_metrics\n)","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:26.853239Z","iopub.status.busy":"2024-06-01T08:06:26.852921Z","iopub.status.idle":"2024-06-01T08:06:27.506813Z","shell.execute_reply":"2024-06-01T08:06:27.505900Z","shell.execute_reply.started":"2024-06-01T08:06:26.853209Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.execute_input":"2024-06-01T08:06:27.508152Z","iopub.status.busy":"2024-06-01T08:06:27.507901Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\nFailed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmushahid\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"},{"output_type":"display_data","data":{"text/html":["Tracking run with wandb version 0.17.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Run data is saved locally in <code>c:\\Users\\ooga\\Downloads\\fabiha\\wandb\\run-20240603_013042-kng7zneq</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/mushahid/huggingface/runs/kng7zneq' target=\"_blank\">weights</a></strong> to <a href='https://wandb.ai/mushahid/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":[" View project at <a href='https://wandb.ai/mushahid/huggingface' target=\"_blank\">https://wandb.ai/mushahid/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":[" View run at <a href='https://wandb.ai/mushahid/huggingface/runs/kng7zneq' target=\"_blank\">https://wandb.ai/mushahid/huggingface/runs/kng7zneq</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"name":"stderr","output_type":"stream","text":"  1%|          | 50/8095 [01:13<3:12:15,  1.43s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 53.6613, 'grad_norm': 81.79608917236328, 'learning_rate': 1.9876466954910442e-05, 'epoch': 0.03}\n"},{"name":"stderr","output_type":"stream","text":"  1%|          | 100/8095 [02:27<3:21:56,  1.52s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 52.5918, 'grad_norm': 82.74657440185547, 'learning_rate': 1.975293390982088e-05, 'epoch': 0.06}\n"},{"name":"stderr","output_type":"stream","text":"  2%|▏         | 150/8095 [03:42<3:23:16,  1.54s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 51.3417, 'grad_norm': 83.04741668701172, 'learning_rate': 1.962940086473132e-05, 'epoch': 0.09}\n"},{"name":"stderr","output_type":"stream","text":"  2%|▏         | 200/8095 [04:58<3:18:26,  1.51s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 49.8359, 'grad_norm': 84.33369445800781, 'learning_rate': 1.9505867819641754e-05, 'epoch': 0.12}\n"},{"name":"stderr","output_type":"stream","text":"  3%|▎         | 250/8095 [06:14<3:19:59,  1.53s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 48.0134, 'grad_norm': 85.47264862060547, 'learning_rate': 1.9382334774552194e-05, 'epoch': 0.15}\n"},{"name":"stderr","output_type":"stream","text":"  4%|▎         | 300/8095 [07:30<3:17:56,  1.52s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 46.1266, 'grad_norm': 86.10546875, 'learning_rate': 1.925880172946263e-05, 'epoch': 0.19}\n"},{"name":"stderr","output_type":"stream","text":"  4%|▍         | 350/8095 [08:46<3:14:41,  1.51s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 43.7884, 'grad_norm': 86.26187896728516, 'learning_rate': 1.9135268684373072e-05, 'epoch': 0.22}\n"},{"name":"stderr","output_type":"stream","text":"  5%|▍         | 400/8095 [10:01<3:13:29,  1.51s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 40.7405, 'grad_norm': 87.07811737060547, 'learning_rate': 1.901173563928351e-05, 'epoch': 0.25}\n"},{"name":"stderr","output_type":"stream","text":"  6%|▌         | 450/8095 [11:16<3:12:06,  1.51s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 36.2473, 'grad_norm': 87.97532653808594, 'learning_rate': 1.888820259419395e-05, 'epoch': 0.28}\n"},{"name":"stderr","output_type":"stream","text":"  6%|▌         | 500/8095 [12:32<3:11:01,  1.51s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 27.5908, 'grad_norm': 89.63648223876953, 'learning_rate': 1.8764669549104387e-05, 'epoch': 0.31}\n"},{"name":"stderr","output_type":"stream","text":"  7%|▋         | 550/8095 [13:47<3:09:36,  1.51s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 8.4244, 'grad_norm': 33.86652374267578, 'learning_rate': 1.8641136504014824e-05, 'epoch': 0.34}\n"},{"name":"stderr","output_type":"stream","text":"  7%|▋         | 600/8095 [15:03<3:08:27,  1.51s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 2.5279, 'grad_norm': 20.411436080932617, 'learning_rate': 1.8517603458925265e-05, 'epoch': 0.37}\n"},{"name":"stderr","output_type":"stream","text":"  8%|▊         | 650/8095 [16:18<3:07:18,  1.51s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.8655, 'grad_norm': 2.7826550006866455, 'learning_rate': 1.8394070413835702e-05, 'epoch': 0.4}\n"},{"name":"stderr","output_type":"stream","text":"  9%|▊         | 700/8095 [17:33<3:05:47,  1.51s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.4131, 'grad_norm': 0.5552659630775452, 'learning_rate': 1.8270537368746143e-05, 'epoch': 0.43}\n"},{"name":"stderr","output_type":"stream","text":"  9%|▉         | 750/8095 [18:49<3:08:54,  1.54s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.3125, 'grad_norm': 0.25206491351127625, 'learning_rate': 1.814700432365658e-05, 'epoch': 0.46}\n"},{"name":"stderr","output_type":"stream","text":" 10%|▉         | 800/8095 [20:06<3:07:39,  1.54s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2893, 'grad_norm': 0.21552634239196777, 'learning_rate': 1.8023471278567017e-05, 'epoch': 0.49}\n"},{"name":"stderr","output_type":"stream","text":" 11%|█         | 850/8095 [21:23<3:05:34,  1.54s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2858, 'grad_norm': 0.18658460676670074, 'learning_rate': 1.7899938233477458e-05, 'epoch': 0.52}\n"},{"name":"stderr","output_type":"stream","text":" 11%|█         | 900/8095 [22:40<3:04:11,  1.54s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2762, 'grad_norm': 0.2684408128261566, 'learning_rate': 1.7776405188387895e-05, 'epoch': 0.56}\n"},{"name":"stderr","output_type":"stream","text":" 12%|█▏        | 950/8095 [23:57<3:01:59,  1.53s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2833, 'grad_norm': 0.15369701385498047, 'learning_rate': 1.7652872143298335e-05, 'epoch': 0.59}\n"},{"name":"stderr","output_type":"stream","text":" 12%|█▏        | 1000/8095 [25:13<3:00:57,  1.53s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2728, 'grad_norm': 0.34758931398391724, 'learning_rate': 1.7529339098208773e-05, 'epoch': 0.62}\n"},{"name":"stderr","output_type":"stream","text":" 13%|█▎        | 1050/8095 [26:30<2:59:50,  1.53s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2531, 'grad_norm': 0.19065682590007782, 'learning_rate': 1.7405806053119213e-05, 'epoch': 0.65}\n"},{"name":"stderr","output_type":"stream","text":" 14%|█▎        | 1100/8095 [27:46<2:58:09,  1.53s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2415, 'grad_norm': 0.17833882570266724, 'learning_rate': 1.7282273008029647e-05, 'epoch': 0.68}\n"},{"name":"stderr","output_type":"stream","text":" 14%|█▍        | 1150/8095 [29:03<2:56:52,  1.53s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2399, 'grad_norm': 0.4581044912338257, 'learning_rate': 1.7158739962940088e-05, 'epoch': 0.71}\n"},{"name":"stderr","output_type":"stream","text":" 15%|█▍        | 1200/8095 [30:19<2:55:48,  1.53s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2305, 'grad_norm': 0.18249601125717163, 'learning_rate': 1.7035206917850525e-05, 'epoch': 0.74}\n"},{"name":"stderr","output_type":"stream","text":" 15%|█▌        | 1250/8095 [31:36<2:54:43,  1.53s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2221, 'grad_norm': 0.5299639701843262, 'learning_rate': 1.6911673872760965e-05, 'epoch': 0.77}\n"},{"name":"stderr","output_type":"stream","text":" 16%|█▌        | 1300/8095 [32:53<2:53:25,  1.53s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2255, 'grad_norm': 0.4439012110233307, 'learning_rate': 1.6788140827671403e-05, 'epoch': 0.8}\n"},{"name":"stderr","output_type":"stream","text":" 17%|█▋        | 1350/8095 [34:09<2:52:07,  1.53s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2208, 'grad_norm': 0.14112460613250732, 'learning_rate': 1.6664607782581843e-05, 'epoch': 0.83}\n"},{"name":"stderr","output_type":"stream","text":" 17%|█▋        | 1400/8095 [35:26<2:50:42,  1.53s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2165, 'grad_norm': 0.24603265523910522, 'learning_rate': 1.654107473749228e-05, 'epoch': 0.86}\n"},{"name":"stderr","output_type":"stream","text":" 18%|█▊        | 1450/8095 [36:42<2:49:29,  1.53s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2256, 'grad_norm': 0.28274664282798767, 'learning_rate': 1.6417541692402718e-05, 'epoch': 0.9}\n"},{"name":"stderr","output_type":"stream","text":" 19%|█▊        | 1500/8095 [37:59<2:48:29,  1.53s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2225, 'grad_norm': 0.2309223860502243, 'learning_rate': 1.6294008647313158e-05, 'epoch': 0.93}\n"},{"name":"stderr","output_type":"stream","text":" 19%|█▉        | 1550/8095 [39:15<2:46:58,  1.53s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2121, 'grad_norm': 0.328275203704834, 'learning_rate': 1.6170475602223595e-05, 'epoch': 0.96}\n"},{"name":"stderr","output_type":"stream","text":" 20%|█▉        | 1600/8095 [40:32<2:45:51,  1.53s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2021, 'grad_norm': 0.39594221115112305, 'learning_rate': 1.6046942557134036e-05, 'epoch': 0.99}\n"},{"name":"stderr","output_type":"stream","text":" 20%|██        | 1619/8095 [41:01<2:45:12,  1.53s/it]c:\\Users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages\\transformers\\generation\\utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n\n  warnings.warn(\n\nc:\\Users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n\n  attn_output = torch.nn.functional.scaled_dot_product_attention(\n\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n\n                                                     \n\n 20%|██        | 1619/8095 [43:04<2:45:12,  1.53s/it]"},{"name":"stdout","output_type":"stream","text":"{'eval_loss': 0.1679154485464096, 'eval_BERT F1': 0.6090190058350563, 'eval_BERT Precision': 0.6452960810859998, 'eval_BERT Recall': 0.5783439970612526, 'eval_runtime': 122.9027, 'eval_samples_per_second': 12.205, 'eval_steps_per_second': 3.051, 'epoch': 1.0}\n"},{"name":"stderr","output_type":"stream","text":" 20%|██        | 1650/8095 [43:52<2:43:47,  1.52s/it] "},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2014, 'grad_norm': 0.15485996007919312, 'learning_rate': 1.5923409512044473e-05, 'epoch': 1.02}\n"},{"name":"stderr","output_type":"stream","text":" 21%|██        | 1700/8095 [45:07<2:39:02,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2137, 'grad_norm': 0.1439303159713745, 'learning_rate': 1.579987646695491e-05, 'epoch': 1.05}\n"},{"name":"stderr","output_type":"stream","text":" 22%|██▏       | 1750/8095 [46:22<2:37:53,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2044, 'grad_norm': 0.12395039200782776, 'learning_rate': 1.567634342186535e-05, 'epoch': 1.08}\n"},{"name":"stderr","output_type":"stream","text":" 22%|██▏       | 1800/8095 [47:37<2:36:26,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1902, 'grad_norm': 0.14427010715007782, 'learning_rate': 1.5552810376775788e-05, 'epoch': 1.11}\n"},{"name":"stderr","output_type":"stream","text":" 23%|██▎       | 1850/8095 [48:51<2:35:23,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1946, 'grad_norm': 0.29059138894081116, 'learning_rate': 1.542927733168623e-05, 'epoch': 1.14}\n"},{"name":"stderr","output_type":"stream","text":" 23%|██▎       | 1900/8095 [50:06<2:34:09,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1878, 'grad_norm': 0.32550904154777527, 'learning_rate': 1.5305744286596666e-05, 'epoch': 1.17}\n"},{"name":"stderr","output_type":"stream","text":" 24%|██▍       | 1950/8095 [51:21<2:32:48,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1995, 'grad_norm': 0.14976394176483154, 'learning_rate': 1.5182211241507105e-05, 'epoch': 1.2}\n"},{"name":"stderr","output_type":"stream","text":" 25%|██▍       | 2000/8095 [52:36<2:31:48,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.187, 'grad_norm': 0.2662014663219452, 'learning_rate': 1.5058678196417542e-05, 'epoch': 1.24}\n"},{"name":"stderr","output_type":"stream","text":" 25%|██▌       | 2050/8095 [53:50<2:30:36,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1906, 'grad_norm': 0.16033095121383667, 'learning_rate': 1.493514515132798e-05, 'epoch': 1.27}\n"},{"name":"stderr","output_type":"stream","text":" 26%|██▌       | 2100/8095 [55:05<2:29:18,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.2064, 'grad_norm': 0.17834801971912384, 'learning_rate': 1.481161210623842e-05, 'epoch': 1.3}\n"},{"name":"stderr","output_type":"stream","text":" 27%|██▋       | 2150/8095 [56:20<2:28:00,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1775, 'grad_norm': 0.1643441766500473, 'learning_rate': 1.4688079061148859e-05, 'epoch': 1.33}\n"},{"name":"stderr","output_type":"stream","text":" 27%|██▋       | 2200/8095 [57:34<2:26:49,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1852, 'grad_norm': 0.19210952520370483, 'learning_rate': 1.4564546016059298e-05, 'epoch': 1.36}\n"},{"name":"stderr","output_type":"stream","text":" 28%|██▊       | 2250/8095 [58:49<2:25:32,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.19, 'grad_norm': 0.1249229833483696, 'learning_rate': 1.4441012970969736e-05, 'epoch': 1.39}\n"},{"name":"stderr","output_type":"stream","text":" 28%|██▊       | 2300/8095 [1:00:04<2:24:14,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1878, 'grad_norm': 0.2210606187582016, 'learning_rate': 1.4317479925880174e-05, 'epoch': 1.42}\n"},{"name":"stderr","output_type":"stream","text":" 29%|██▉       | 2350/8095 [1:01:18<2:22:45,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1732, 'grad_norm': 0.11187636107206345, 'learning_rate': 1.4193946880790612e-05, 'epoch': 1.45}\n"},{"name":"stderr","output_type":"stream","text":" 30%|██▉       | 2400/8095 [1:02:33<2:21:50,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1789, 'grad_norm': 0.2191801816225052, 'learning_rate': 1.4070413835701051e-05, 'epoch': 1.48}\n"},{"name":"stderr","output_type":"stream","text":" 30%|███       | 2450/8095 [1:03:48<2:20:37,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1756, 'grad_norm': 1.8976801633834839, 'learning_rate': 1.394688079061149e-05, 'epoch': 1.51}\n"},{"name":"stderr","output_type":"stream","text":" 31%|███       | 2500/8095 [1:05:03<2:19:08,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1753, 'grad_norm': 0.11434680223464966, 'learning_rate': 1.3823347745521929e-05, 'epoch': 1.54}\n"},{"name":"stderr","output_type":"stream","text":" 32%|███▏      | 2550/8095 [1:06:17<2:18:02,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1676, 'grad_norm': 0.13224519789218903, 'learning_rate': 1.3699814700432368e-05, 'epoch': 1.57}\n"},{"name":"stderr","output_type":"stream","text":" 32%|███▏      | 2600/8095 [1:07:32<2:16:52,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1733, 'grad_norm': 0.29856449365615845, 'learning_rate': 1.3576281655342805e-05, 'epoch': 1.61}\n"},{"name":"stderr","output_type":"stream","text":" 33%|███▎      | 2650/8095 [1:08:47<2:15:32,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1652, 'grad_norm': 0.12079424411058426, 'learning_rate': 1.3452748610253244e-05, 'epoch': 1.64}\n"},{"name":"stderr","output_type":"stream","text":" 33%|███▎      | 2700/8095 [1:10:01<2:14:16,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1597, 'grad_norm': 0.4730075001716614, 'learning_rate': 1.3329215565163683e-05, 'epoch': 1.67}\n"},{"name":"stderr","output_type":"stream","text":" 34%|███▍      | 2750/8095 [1:11:16<2:12:54,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1572, 'grad_norm': 0.36057713627815247, 'learning_rate': 1.3205682520074122e-05, 'epoch': 1.7}\n"},{"name":"stderr","output_type":"stream","text":" 35%|███▍      | 2800/8095 [1:12:31<2:11:44,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1489, 'grad_norm': 0.14014950394630432, 'learning_rate': 1.308214947498456e-05, 'epoch': 1.73}\n"},{"name":"stderr","output_type":"stream","text":" 35%|███▌      | 2850/8095 [1:13:45<2:10:34,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1511, 'grad_norm': 0.5397221446037292, 'learning_rate': 1.2958616429895e-05, 'epoch': 1.76}\n"},{"name":"stderr","output_type":"stream","text":" 36%|███▌      | 2900/8095 [1:15:00<2:09:11,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1469, 'grad_norm': 0.3215118944644928, 'learning_rate': 1.2835083384805435e-05, 'epoch': 1.79}\n"},{"name":"stderr","output_type":"stream","text":" 36%|███▋      | 2950/8095 [1:16:15<2:08:12,  1.50s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1457, 'grad_norm': 0.14980530738830566, 'learning_rate': 1.2711550339715874e-05, 'epoch': 1.82}\n"},{"name":"stderr","output_type":"stream","text":" 37%|███▋      | 3000/8095 [1:17:29<2:07:04,  1.50s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1469, 'grad_norm': 0.18089142441749573, 'learning_rate': 1.2588017294626313e-05, 'epoch': 1.85}\n"},{"name":"stderr","output_type":"stream","text":" 38%|███▊      | 3050/8095 [1:18:44<2:05:34,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1481, 'grad_norm': 0.27816954255104065, 'learning_rate': 1.2464484249536752e-05, 'epoch': 1.88}\n"},{"name":"stderr","output_type":"stream","text":" 38%|███▊      | 3100/8095 [1:19:59<2:04:34,  1.50s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1452, 'grad_norm': 0.3803395628929138, 'learning_rate': 1.234095120444719e-05, 'epoch': 1.91}\n"},{"name":"stderr","output_type":"stream","text":" 39%|███▉      | 3150/8095 [1:21:14<2:03:17,  1.50s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1409, 'grad_norm': 0.26112720370292664, 'learning_rate': 1.221741815935763e-05, 'epoch': 1.95}\n"},{"name":"stderr","output_type":"stream","text":" 40%|███▉      | 3200/8095 [1:22:28<2:01:52,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1418, 'grad_norm': 0.36478281021118164, 'learning_rate': 1.2093885114268067e-05, 'epoch': 1.98}\n"},{"name":"stderr","output_type":"stream","text":" 40%|████      | 3238/8095 [1:23:25<2:00:50,  1.49s/it]c:\\Users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages\\transformers\\generation\\utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n\n  warnings.warn(\n\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n\n                                                       \n\n 40%|████      | 3238/8095 [1:25:28<2:00:50,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'eval_loss': 0.1031671017408371, 'eval_BERT F1': 0.7187390927473704, 'eval_BERT Precision': 0.7370246242880821, 'eval_BERT Recall': 0.7026457252899806, 'eval_runtime': 122.003, 'eval_samples_per_second': 12.295, 'eval_steps_per_second': 3.074, 'epoch': 2.0}\n"},{"name":"stderr","output_type":"stream","text":" 40%|████      | 3250/8095 [1:25:46<2:58:27,  2.21s/it] "},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1358, 'grad_norm': 0.1326763778924942, 'learning_rate': 1.1970352069178506e-05, 'epoch': 2.01}\n"},{"name":"stderr","output_type":"stream","text":" 41%|████      | 3300/8095 [1:27:00<1:59:14,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1323, 'grad_norm': 4.625297546386719, 'learning_rate': 1.1846819024088945e-05, 'epoch': 2.04}\n"},{"name":"stderr","output_type":"stream","text":" 41%|████▏     | 3350/8095 [1:28:15<1:58:22,  1.50s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1385, 'grad_norm': 0.19247987866401672, 'learning_rate': 1.1723285978999383e-05, 'epoch': 2.07}\n"},{"name":"stderr","output_type":"stream","text":" 42%|████▏     | 3400/8095 [1:29:30<1:56:57,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1343, 'grad_norm': 0.10900379717350006, 'learning_rate': 1.1599752933909822e-05, 'epoch': 2.1}\n"},{"name":"stderr","output_type":"stream","text":" 43%|████▎     | 3450/8095 [1:30:44<1:55:47,  1.50s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1376, 'grad_norm': 0.16117191314697266, 'learning_rate': 1.1476219888820261e-05, 'epoch': 2.13}\n"},{"name":"stderr","output_type":"stream","text":" 43%|████▎     | 3500/8095 [1:31:59<1:54:20,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1393, 'grad_norm': 2.4108643531799316, 'learning_rate': 1.1352686843730698e-05, 'epoch': 2.16}\n"},{"name":"stderr","output_type":"stream","text":" 44%|████▍     | 3550/8095 [1:33:14<1:53:05,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1344, 'grad_norm': 0.2575700283050537, 'learning_rate': 1.1229153798641137e-05, 'epoch': 2.19}\n"},{"name":"stderr","output_type":"stream","text":" 44%|████▍     | 3600/8095 [1:34:28<1:51:54,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1317, 'grad_norm': 0.691845715045929, 'learning_rate': 1.1105620753551576e-05, 'epoch': 2.22}\n"},{"name":"stderr","output_type":"stream","text":" 45%|████▌     | 3650/8095 [1:35:43<1:50:30,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1443, 'grad_norm': 0.3180152475833893, 'learning_rate': 1.0982087708462015e-05, 'epoch': 2.25}\n"},{"name":"stderr","output_type":"stream","text":" 46%|████▌     | 3700/8095 [1:36:58<1:49:31,  1.50s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.141, 'grad_norm': 0.12371301651000977, 'learning_rate': 1.0858554663372454e-05, 'epoch': 2.28}\n"},{"name":"stderr","output_type":"stream","text":" 46%|████▋     | 3750/8095 [1:38:12<1:48:13,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1285, 'grad_norm': 0.12316489219665527, 'learning_rate': 1.0735021618282893e-05, 'epoch': 2.32}\n"},{"name":"stderr","output_type":"stream","text":" 47%|████▋     | 3800/8095 [1:39:27<1:46:51,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1283, 'grad_norm': 1.0484391450881958, 'learning_rate': 1.061148857319333e-05, 'epoch': 2.35}\n"},{"name":"stderr","output_type":"stream","text":" 48%|████▊     | 3850/8095 [1:40:42<1:45:43,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1302, 'grad_norm': 4.500853061676025, 'learning_rate': 1.0487955528103769e-05, 'epoch': 2.38}\n"},{"name":"stderr","output_type":"stream","text":" 48%|████▊     | 3900/8095 [1:41:57<1:44:33,  1.50s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1236, 'grad_norm': 0.7719602584838867, 'learning_rate': 1.0364422483014208e-05, 'epoch': 2.41}\n"},{"name":"stderr","output_type":"stream","text":" 49%|████▉     | 3950/8095 [1:43:11<1:43:15,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1247, 'grad_norm': 0.19313286244869232, 'learning_rate': 1.0240889437924647e-05, 'epoch': 2.44}\n"},{"name":"stderr","output_type":"stream","text":" 49%|████▉     | 4000/8095 [1:44:26<1:42:01,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1279, 'grad_norm': 0.21669307351112366, 'learning_rate': 1.0117356392835086e-05, 'epoch': 2.47}\n"},{"name":"stderr","output_type":"stream","text":" 50%|█████     | 4050/8095 [1:45:41<1:40:32,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1182, 'grad_norm': 0.12396176159381866, 'learning_rate': 9.993823347745523e-06, 'epoch': 2.5}\n"},{"name":"stderr","output_type":"stream","text":" 51%|█████     | 4100/8095 [1:46:55<1:39:31,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1225, 'grad_norm': 0.6288121938705444, 'learning_rate': 9.870290302655962e-06, 'epoch': 2.53}\n"},{"name":"stderr","output_type":"stream","text":" 51%|█████▏    | 4150/8095 [1:48:10<1:38:10,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1258, 'grad_norm': 0.12335371226072311, 'learning_rate': 9.746757257566399e-06, 'epoch': 2.56}\n"},{"name":"stderr","output_type":"stream","text":" 52%|█████▏    | 4200/8095 [1:49:25<1:37:09,  1.50s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1319, 'grad_norm': 0.23399463295936584, 'learning_rate': 9.623224212476838e-06, 'epoch': 2.59}\n"},{"name":"stderr","output_type":"stream","text":" 53%|█████▎    | 4250/8095 [1:50:40<1:35:52,  1.50s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1146, 'grad_norm': 0.116556815803051, 'learning_rate': 9.499691167387277e-06, 'epoch': 2.62}\n"},{"name":"stderr","output_type":"stream","text":" 53%|█████▎    | 4300/8095 [1:51:54<1:34:44,  1.50s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.116, 'grad_norm': 0.12950606644153595, 'learning_rate': 9.376158122297716e-06, 'epoch': 2.66}\n"},{"name":"stderr","output_type":"stream","text":" 54%|█████▎    | 4350/8095 [1:53:09<1:33:18,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1208, 'grad_norm': 0.198343425989151, 'learning_rate': 9.252625077208154e-06, 'epoch': 2.69}\n"},{"name":"stderr","output_type":"stream","text":" 54%|█████▍    | 4400/8095 [1:54:24<1:31:54,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.118, 'grad_norm': 0.14149385690689087, 'learning_rate': 9.129092032118593e-06, 'epoch': 2.72}\n"},{"name":"stderr","output_type":"stream","text":" 55%|█████▍    | 4450/8095 [1:55:39<1:30:42,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1244, 'grad_norm': 0.1498393565416336, 'learning_rate': 9.00555898702903e-06, 'epoch': 2.75}\n"},{"name":"stderr","output_type":"stream","text":" 56%|█████▌    | 4500/8095 [1:56:53<1:29:31,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1202, 'grad_norm': 0.12047850340604782, 'learning_rate': 8.88202594193947e-06, 'epoch': 2.78}\n"},{"name":"stderr","output_type":"stream","text":" 56%|█████▌    | 4550/8095 [1:58:08<1:28:17,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1156, 'grad_norm': 0.12583975493907928, 'learning_rate': 8.758492896849908e-06, 'epoch': 2.81}\n"},{"name":"stderr","output_type":"stream","text":" 57%|█████▋    | 4600/8095 [1:59:22<1:25:11,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1198, 'grad_norm': 0.1897178292274475, 'learning_rate': 8.634959851760346e-06, 'epoch': 2.84}\n"},{"name":"stderr","output_type":"stream","text":" 57%|█████▋    | 4650/8095 [2:00:35<1:23:43,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1282, 'grad_norm': 0.16470767557621002, 'learning_rate': 8.511426806670784e-06, 'epoch': 2.87}\n"},{"name":"stderr","output_type":"stream","text":" 58%|█████▊    | 4700/8095 [2:01:48<1:22:42,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1123, 'grad_norm': 0.22098097205162048, 'learning_rate': 8.387893761581223e-06, 'epoch': 2.9}\n"},{"name":"stderr","output_type":"stream","text":" 59%|█████▊    | 4750/8095 [2:03:01<1:21:26,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1165, 'grad_norm': 0.1532311737537384, 'learning_rate': 8.264360716491662e-06, 'epoch': 2.93}\n"},{"name":"stderr","output_type":"stream","text":" 59%|█████▉    | 4800/8095 [2:04:14<1:20:08,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.117, 'grad_norm': 0.17141184210777283, 'learning_rate': 8.140827671402101e-06, 'epoch': 2.96}\n"},{"name":"stderr","output_type":"stream","text":" 60%|█████▉    | 4850/8095 [2:05:27<1:18:59,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1217, 'grad_norm': 0.21488790214061737, 'learning_rate': 8.01729462631254e-06, 'epoch': 3.0}\n"},{"name":"stderr","output_type":"stream","text":" 60%|██████    | 4858/8095 [2:05:39<1:18:46,  1.46s/it]c:\\Users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages\\transformers\\generation\\utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n\n  warnings.warn(\n\n                                                       \n\n 60%|██████    | 4858/8095 [2:07:37<1:18:46,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'eval_loss': 0.08465564250946045, 'eval_BERT F1': 0.7780958740313848, 'eval_BERT Precision': 0.7898316922585169, 'eval_BERT Recall': 0.767652642428875, 'eval_runtime': 118.1639, 'eval_samples_per_second': 12.694, 'eval_steps_per_second': 3.174, 'epoch': 3.0}\n"},{"name":"stderr","output_type":"stream","text":" 61%|██████    | 4900/8095 [2:08:39<1:17:43,  1.46s/it] "},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1147, 'grad_norm': 0.10522744059562683, 'learning_rate': 7.893761581222977e-06, 'epoch': 3.03}\n"},{"name":"stderr","output_type":"stream","text":" 61%|██████    | 4950/8095 [2:09:52<1:16:31,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1113, 'grad_norm': 0.1745244711637497, 'learning_rate': 7.770228536133416e-06, 'epoch': 3.06}\n"},{"name":"stderr","output_type":"stream","text":" 62%|██████▏   | 5000/8095 [2:11:05<1:15:17,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1182, 'grad_norm': 0.13296769559383392, 'learning_rate': 7.646695491043855e-06, 'epoch': 3.09}\n"},{"name":"stderr","output_type":"stream","text":" 62%|██████▏   | 5050/8095 [2:12:18<1:14:04,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1162, 'grad_norm': 0.23349027335643768, 'learning_rate': 7.523162445954293e-06, 'epoch': 3.12}\n"},{"name":"stderr","output_type":"stream","text":" 63%|██████▎   | 5100/8095 [2:13:31<1:12:52,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.112, 'grad_norm': 0.38954952359199524, 'learning_rate': 7.399629400864732e-06, 'epoch': 3.15}\n"},{"name":"stderr","output_type":"stream","text":" 64%|██████▎   | 5150/8095 [2:14:44<1:11:38,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1146, 'grad_norm': 0.1193532645702362, 'learning_rate': 7.276096355775171e-06, 'epoch': 3.18}\n"},{"name":"stderr","output_type":"stream","text":" 64%|██████▍   | 5200/8095 [2:15:57<1:10:22,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1123, 'grad_norm': 0.20016713440418243, 'learning_rate': 7.152563310685609e-06, 'epoch': 3.21}\n"},{"name":"stderr","output_type":"stream","text":" 65%|██████▍   | 5250/8095 [2:17:10<1:09:15,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1124, 'grad_norm': 0.20372292399406433, 'learning_rate': 7.029030265596048e-06, 'epoch': 3.24}\n"},{"name":"stderr","output_type":"stream","text":" 65%|██████▌   | 5300/8095 [2:18:23<1:08:03,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1152, 'grad_norm': 0.10407738387584686, 'learning_rate': 6.905497220506487e-06, 'epoch': 3.27}\n"},{"name":"stderr","output_type":"stream","text":" 66%|██████▌   | 5350/8095 [2:19:36<1:06:50,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.116, 'grad_norm': 0.13394181430339813, 'learning_rate': 6.781964175416924e-06, 'epoch': 3.3}\n"},{"name":"stderr","output_type":"stream","text":" 67%|██████▋   | 5400/8095 [2:20:49<1:05:40,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.116, 'grad_norm': 0.7985479831695557, 'learning_rate': 6.658431130327363e-06, 'epoch': 3.33}\n"},{"name":"stderr","output_type":"stream","text":" 67%|██████▋   | 5450/8095 [2:22:02<1:04:26,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1209, 'grad_norm': 0.1363767832517624, 'learning_rate': 6.5348980852378016e-06, 'epoch': 3.37}\n"},{"name":"stderr","output_type":"stream","text":" 68%|██████▊   | 5500/8095 [2:23:15<1:03:12,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1109, 'grad_norm': 0.16218201816082, 'learning_rate': 6.41136504014824e-06, 'epoch': 3.4}\n"},{"name":"stderr","output_type":"stream","text":" 69%|██████▊   | 5550/8095 [2:24:28<1:01:58,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1069, 'grad_norm': 0.10935169458389282, 'learning_rate': 6.2878319950586785e-06, 'epoch': 3.43}\n"},{"name":"stderr","output_type":"stream","text":" 69%|██████▉   | 5600/8095 [2:25:41<1:00:50,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1149, 'grad_norm': 0.18918026983737946, 'learning_rate': 6.164298949969117e-06, 'epoch': 3.46}\n"},{"name":"stderr","output_type":"stream","text":" 70%|██████▉   | 5650/8095 [2:26:54<59:42,  1.47s/it]  "},{"name":"stdout","output_type":"stream","text":"{'loss': 0.112, 'grad_norm': 0.19901716709136963, 'learning_rate': 6.0407659048795554e-06, 'epoch': 3.49}\n"},{"name":"stderr","output_type":"stream","text":" 70%|███████   | 5700/8095 [2:28:07<58:17,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1179, 'grad_norm': 0.15269377827644348, 'learning_rate': 5.917232859789994e-06, 'epoch': 3.52}\n"},{"name":"stderr","output_type":"stream","text":" 71%|███████   | 5750/8095 [2:29:21<57:02,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1115, 'grad_norm': 0.18741010129451752, 'learning_rate': 5.793699814700433e-06, 'epoch': 3.55}\n"},{"name":"stderr","output_type":"stream","text":" 72%|███████▏  | 5800/8095 [2:30:34<55:49,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1081, 'grad_norm': 4.746659755706787, 'learning_rate': 5.670166769610871e-06, 'epoch': 3.58}\n"},{"name":"stderr","output_type":"stream","text":" 72%|███████▏  | 5850/8095 [2:31:46<54:36,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1179, 'grad_norm': 0.1543150395154953, 'learning_rate': 5.54663372452131e-06, 'epoch': 3.61}\n"},{"name":"stderr","output_type":"stream","text":" 73%|███████▎  | 5900/8095 [2:32:59<53:24,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1143, 'grad_norm': 0.11349888145923615, 'learning_rate': 5.423100679431749e-06, 'epoch': 3.64}\n"},{"name":"stderr","output_type":"stream","text":" 74%|███████▎  | 5950/8095 [2:34:12<52:10,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1153, 'grad_norm': 0.18231654167175293, 'learning_rate': 5.299567634342186e-06, 'epoch': 3.67}\n"},{"name":"stderr","output_type":"stream","text":" 74%|███████▍  | 6000/8095 [2:35:25<50:57,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1129, 'grad_norm': 0.12259335070848465, 'learning_rate': 5.176034589252625e-06, 'epoch': 3.71}\n"},{"name":"stderr","output_type":"stream","text":" 75%|███████▍  | 6050/8095 [2:36:38<49:44,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1038, 'grad_norm': 0.15827065706253052, 'learning_rate': 5.052501544163064e-06, 'epoch': 3.74}\n"},{"name":"stderr","output_type":"stream","text":" 75%|███████▌  | 6100/8095 [2:37:51<48:29,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1055, 'grad_norm': 0.17163588106632233, 'learning_rate': 4.928968499073503e-06, 'epoch': 3.77}\n"},{"name":"stderr","output_type":"stream","text":" 76%|███████▌  | 6150/8095 [2:39:04<47:25,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1106, 'grad_norm': 0.18436329066753387, 'learning_rate': 4.805435453983941e-06, 'epoch': 3.8}\n"},{"name":"stderr","output_type":"stream","text":" 77%|███████▋  | 6200/8095 [2:40:17<46:05,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1071, 'grad_norm': 0.1771116554737091, 'learning_rate': 4.68190240889438e-06, 'epoch': 3.83}\n"},{"name":"stderr","output_type":"stream","text":" 77%|███████▋  | 6250/8095 [2:41:30<44:52,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1147, 'grad_norm': 0.17316603660583496, 'learning_rate': 4.558369363804818e-06, 'epoch': 3.86}\n"},{"name":"stderr","output_type":"stream","text":" 78%|███████▊  | 6300/8095 [2:42:43<43:39,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1108, 'grad_norm': 0.09789225459098816, 'learning_rate': 4.434836318715257e-06, 'epoch': 3.89}\n"},{"name":"stderr","output_type":"stream","text":" 78%|███████▊  | 6350/8095 [2:43:56<42:26,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1071, 'grad_norm': 0.20186811685562134, 'learning_rate': 4.311303273625696e-06, 'epoch': 3.92}\n"},{"name":"stderr","output_type":"stream","text":" 79%|███████▉  | 6400/8095 [2:45:09<41:13,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1144, 'grad_norm': 0.19655592739582062, 'learning_rate': 4.187770228536134e-06, 'epoch': 3.95}\n"},{"name":"stderr","output_type":"stream","text":" 80%|███████▉  | 6450/8095 [2:46:22<40:00,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1075, 'grad_norm': 0.13798141479492188, 'learning_rate': 4.064237183446572e-06, 'epoch': 3.98}\n"},{"name":"stderr","output_type":"stream","text":" 80%|████████  | 6477/8095 [2:47:02<39:20,  1.46s/it]c:\\Users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages\\transformers\\generation\\utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n\n  warnings.warn(\n\n                                                     \n\n 80%|████████  | 6477/8095 [2:49:00<39:20,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'eval_loss': 0.07919792830944061, 'eval_BERT F1': 0.794685318171978, 'eval_BERT Precision': 0.8054739863276482, 'eval_BERT Recall': 0.7851421701113382, 'eval_runtime': 117.8331, 'eval_samples_per_second': 12.73, 'eval_steps_per_second': 3.182, 'epoch': 4.0}\n"},{"name":"stderr","output_type":"stream","text":" 80%|████████  | 6500/8095 [2:49:35<38:51,  1.46s/it]   "},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1064, 'grad_norm': 0.11235510557889938, 'learning_rate': 3.940704138357011e-06, 'epoch': 4.01}\n"},{"name":"stderr","output_type":"stream","text":" 81%|████████  | 6550/8095 [2:50:48<37:34,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1157, 'grad_norm': 0.09129971265792847, 'learning_rate': 3.8171710932674495e-06, 'epoch': 4.04}\n"},{"name":"stderr","output_type":"stream","text":" 82%|████████▏ | 6600/8095 [2:52:01<36:22,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1031, 'grad_norm': 0.10104438662528992, 'learning_rate': 3.6936380481778876e-06, 'epoch': 4.08}\n"},{"name":"stderr","output_type":"stream","text":" 82%|████████▏ | 6650/8095 [2:53:14<35:08,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1098, 'grad_norm': 0.15377679467201233, 'learning_rate': 3.5701050030883264e-06, 'epoch': 4.11}\n"},{"name":"stderr","output_type":"stream","text":" 83%|████████▎ | 6700/8095 [2:54:27<33:55,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1079, 'grad_norm': 0.09556194394826889, 'learning_rate': 3.446571957998765e-06, 'epoch': 4.14}\n"},{"name":"stderr","output_type":"stream","text":" 83%|████████▎ | 6750/8095 [2:55:40<32:43,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1083, 'grad_norm': 0.26823925971984863, 'learning_rate': 3.3230389129092034e-06, 'epoch': 4.17}\n"},{"name":"stderr","output_type":"stream","text":" 84%|████████▍ | 6800/8095 [2:56:52<31:30,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1101, 'grad_norm': 1.7461183071136475, 'learning_rate': 3.1995058678196423e-06, 'epoch': 4.2}\n"},{"name":"stderr","output_type":"stream","text":" 85%|████████▍ | 6850/8095 [2:58:05<30:17,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.106, 'grad_norm': 0.12715458869934082, 'learning_rate': 3.0759728227300807e-06, 'epoch': 4.23}\n"},{"name":"stderr","output_type":"stream","text":" 85%|████████▌ | 6900/8095 [2:59:18<29:04,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1105, 'grad_norm': 0.1269860416650772, 'learning_rate': 2.9524397776405188e-06, 'epoch': 4.26}\n"},{"name":"stderr","output_type":"stream","text":" 86%|████████▌ | 6950/8095 [3:00:31<27:51,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1087, 'grad_norm': 0.2538457214832306, 'learning_rate': 2.8289067325509577e-06, 'epoch': 4.29}\n"},{"name":"stderr","output_type":"stream","text":" 86%|████████▋ | 7000/8095 [3:01:44<26:38,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1103, 'grad_norm': 0.1747337430715561, 'learning_rate': 2.705373687461396e-06, 'epoch': 4.32}\n"},{"name":"stderr","output_type":"stream","text":" 87%|████████▋ | 7050/8095 [3:02:57<25:25,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1068, 'grad_norm': 0.17303451895713806, 'learning_rate': 2.5818406423718346e-06, 'epoch': 4.35}\n"},{"name":"stderr","output_type":"stream","text":" 88%|████████▊ | 7100/8095 [3:04:10<24:11,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1063, 'grad_norm': 4.561871528625488, 'learning_rate': 2.458307597282273e-06, 'epoch': 4.38}\n"},{"name":"stderr","output_type":"stream","text":" 88%|████████▊ | 7150/8095 [3:05:23<22:58,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1077, 'grad_norm': 0.10595976561307907, 'learning_rate': 2.334774552192712e-06, 'epoch': 4.42}\n"},{"name":"stderr","output_type":"stream","text":" 89%|████████▉ | 7200/8095 [3:06:36<21:45,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1093, 'grad_norm': 0.12316923588514328, 'learning_rate': 2.2112415071031504e-06, 'epoch': 4.45}\n"},{"name":"stderr","output_type":"stream","text":" 90%|████████▉ | 7250/8095 [3:07:49<20:32,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1049, 'grad_norm': 0.14862652122974396, 'learning_rate': 2.087708462013589e-06, 'epoch': 4.48}\n"},{"name":"stderr","output_type":"stream","text":" 90%|█████████ | 7300/8095 [3:09:02<19:20,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.107, 'grad_norm': 0.1792069524526596, 'learning_rate': 1.9641754169240273e-06, 'epoch': 4.51}\n"},{"name":"stderr","output_type":"stream","text":" 91%|█████████ | 7350/8095 [3:10:15<18:06,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1079, 'grad_norm': 0.25917840003967285, 'learning_rate': 1.840642371834466e-06, 'epoch': 4.54}\n"},{"name":"stderr","output_type":"stream","text":" 91%|█████████▏| 7400/8095 [3:11:28<16:55,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1067, 'grad_norm': 0.15505079925060272, 'learning_rate': 1.7171093267449043e-06, 'epoch': 4.57}\n"},{"name":"stderr","output_type":"stream","text":" 92%|█████████▏| 7450/8095 [3:12:41<15:41,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.107, 'grad_norm': 1.0656014680862427, 'learning_rate': 1.593576281655343e-06, 'epoch': 4.6}\n"},{"name":"stderr","output_type":"stream","text":" 93%|█████████▎| 7500/8095 [3:13:54<14:28,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1116, 'grad_norm': 0.1262347549200058, 'learning_rate': 1.4700432365657816e-06, 'epoch': 4.63}\n"},{"name":"stderr","output_type":"stream","text":" 93%|█████████▎| 7550/8095 [3:15:07<13:15,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1026, 'grad_norm': 0.09297077357769012, 'learning_rate': 1.3465101914762199e-06, 'epoch': 4.66}\n"},{"name":"stderr","output_type":"stream","text":" 94%|█████████▍| 7600/8095 [3:16:20<12:02,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1023, 'grad_norm': 0.10990168154239655, 'learning_rate': 1.2229771463866586e-06, 'epoch': 4.69}\n"},{"name":"stderr","output_type":"stream","text":" 95%|█████████▍| 7650/8095 [3:17:33<10:49,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1164, 'grad_norm': 0.12699803709983826, 'learning_rate': 1.099444101297097e-06, 'epoch': 4.72}\n"},{"name":"stderr","output_type":"stream","text":" 95%|█████████▌| 7700/8095 [3:18:46<09:36,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1075, 'grad_norm': 0.09956404566764832, 'learning_rate': 9.759110562075357e-07, 'epoch': 4.76}\n"},{"name":"stderr","output_type":"stream","text":" 96%|█████████▌| 7750/8095 [3:19:59<08:23,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1029, 'grad_norm': 1.4161510467529297, 'learning_rate': 8.523780111179742e-07, 'epoch': 4.79}\n"},{"name":"stderr","output_type":"stream","text":" 96%|█████████▋| 7800/8095 [3:21:12<07:10,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1154, 'grad_norm': 0.13452711701393127, 'learning_rate': 7.288449660284126e-07, 'epoch': 4.82}\n"},{"name":"stderr","output_type":"stream","text":" 97%|█████████▋| 7850/8095 [3:22:25<05:57,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1093, 'grad_norm': 0.9480608105659485, 'learning_rate': 6.053119209388512e-07, 'epoch': 4.85}\n"},{"name":"stderr","output_type":"stream","text":" 98%|█████████▊| 7900/8095 [3:23:38<04:44,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.105, 'grad_norm': 0.2776511609554291, 'learning_rate': 4.817788758492898e-07, 'epoch': 4.88}\n"},{"name":"stderr","output_type":"stream","text":" 98%|█████████▊| 7950/8095 [3:24:51<03:31,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1094, 'grad_norm': 0.2459544837474823, 'learning_rate': 3.582458307597283e-07, 'epoch': 4.91}\n"},{"name":"stderr","output_type":"stream","text":" 99%|█████████▉| 8000/8095 [3:26:04<02:18,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1045, 'grad_norm': 0.13424701988697052, 'learning_rate': 2.347127856701668e-07, 'epoch': 4.94}\n"},{"name":"stderr","output_type":"stream","text":" 99%|█████████▉| 8050/8095 [3:27:17<01:05,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'loss': 0.1066, 'grad_norm': 0.7676380276679993, 'learning_rate': 1.1117974058060533e-07, 'epoch': 4.97}\n"},{"name":"stderr","output_type":"stream","text":"100%|██████████| 8095/8095 [3:28:23<00:00,  1.46s/it]c:\\Users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages\\transformers\\generation\\utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n\n  warnings.warn(\n\n                                                     \n\n100%|██████████| 8095/8095 [3:30:21<00:00,  1.46s/it]"},{"name":"stdout","output_type":"stream","text":"{'eval_loss': 0.0776943638920784, 'eval_BERT F1': 0.798313144048055, 'eval_BERT Precision': 0.8085368829568227, 'eval_BERT Recall': 0.7892783262729645, 'eval_runtime': 118.1218, 'eval_samples_per_second': 12.699, 'eval_steps_per_second': 3.175, 'epoch': 5.0}\n"},{"name":"stderr","output_type":"stream","text":"There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n\n100%|██████████| 8095/8095 [3:30:22<00:00,  1.56s/it]"},{"name":"stdout","output_type":"stream","text":"{'train_runtime': 12627.6868, 'train_samples_per_second': 15.388, 'train_steps_per_second': 0.641, 'train_loss': 2.9863612572008478, 'epoch': 5.0}\n"},{"name":"stderr","output_type":"stream","text":"\n"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=8095, training_loss=2.9863612572008478, metrics={'train_runtime': 12627.6868, 'train_samples_per_second': 15.388, 'train_steps_per_second': 0.641, 'total_flos': 2.629420518998016e+16, 'train_loss': 2.9863612572008478, 'epoch': 4.998970769864141})"]},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","output_type":"stream","text":"c:\\Users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages\\transformers\\generation\\utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n\n  warnings.warn(\n\n100%|██████████| 375/375 [01:57<00:00,  3.19it/s]\n"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.0776943638920784,\n"," 'eval_BERT F1': 0.798313144048055,\n"," 'eval_BERT Precision': 0.8085368829568227,\n"," 'eval_BERT Recall': 0.7892783262729645,\n"," 'eval_runtime': 117.6855,\n"," 'eval_samples_per_second': 12.746,\n"," 'eval_steps_per_second': 3.186,\n"," 'epoch': 4.998970769864141}"]},"metadata":{}}]},{"cell_type":"code","source":"def predict_output(input_sentence):\n    input_ids = tokenizer((input_sentence), return_tensors=\"pt\").input_ids.to(\"cuda\")\n    generated_tokens = model.generate(input_ids)\n    decoded_tokens = tokenizer.batch_decode(generated_tokens)[0]\n    decoded_tokens = normalize(decoded_tokens)\n\n    return decoded_tokens\n    \ndf_test['predictions'] = df_test['text_transliterated'].apply(predict_output)\ndf_test.to_csv(\"banglaT5_small_test.csv\", index = False)\n\ndf_val['predictions'] = df_val['text_transliterated'].apply(predict_output)\ndf_val.to_csv(\"banglaT5_small_val.csv\", index = False)","metadata":{"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","output_type":"stream","text":"c:\\Users\\ooga\\miniconda3\\envs\\ml_env\\lib\\site-packages\\transformers\\generation\\utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n\n  warnings.warn(\n"}]},{"cell_type":"code","source":"import nltk\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction, closest_ref_length, brevity_penalty\nfrom nltk.tokenize import word_tokenize\nimport math\n\n# Ensure you have the punkt tokenizer models\nnltk.download('punkt')\n\ndef calculate_bleu(reference_sentence, candidate_sentence):\n\n  # Tokenize the sentences\n    reference = [word_tokenize(reference_sentence)]\n    candidate = word_tokenize(candidate_sentence)\n\n    # Define the smoothing function\n    smoothing_function = SmoothingFunction().method1\n\n  # Calculate BLEU-1\n    bleu1 = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0), smoothing_function=smoothing_function)\n  # Calculate BLEU-2\n    bleu2 = sentence_bleu(reference, candidate, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothing_function)\n  # Calculate BLEU-3\n    bleu3 = sentence_bleu(reference, candidate, weights=(0.33, 0.33, 0.33, 0), smoothing_function=smoothing_function)\n  # Calculate BLEU-4\n    bleu4 = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothing_function)\n\n    hyp_len = len(candidate)\n    ref_len = len(reference[0])\n    closest_ref_len =  closest_ref_length(reference, hyp_len)\n    bp = brevity_penalty(closest_ref_len, hyp_len)\n\n    ratio = hyp_len/ref_len\n\n    return bp*pow((bleu1*bleu2*bleu3*bleu4), 1/4), bp, ratio\n\n# Example reference and candidate sentences in Bangla\nreference_sentence = \"আপনিও শুরু এখন, অ্যাপ নাম সাইজ কই।\"\ncandidate_sentence = \"আপনিও শুরু এখন, অ্যাপ নাম সাইজ কই। \"\ncalculate_bleu(reference_sentence, candidate_sentence)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nfrom nltk.translate.meteor_score import meteor_score\nfrom nltk.tokenize import word_tokenize\n\n# Example reference and candidate sentences in Bangla\nreference_sentence = \"আপনিও শুরু এখন, অ্যাপ নাম সাইজ কই।\"\ncandidate_sentence = \"আপনিও শুরু এখন, অ্যাপ নাম সাইজ কই।\"\n\nreference = [word_tokenize(reference_sentence)]\ncandidate = word_tokenize(candidate_sentence)\nprint(meteor_score(reference, candidate))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchmetrics.text.bert import BERTScore\n\nbertscore = BERTScore()\n\npreds = [\"আপনিও শুরু এখন, অ্যাপ নাম সাইজ কই।\"]\ntarget = [\"আপনিও শুরু এখন, অ্যাপ ইউজার নাম সাইজ কই।\"]\n\nprint(bertscore(preds, target))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.util import ngrams\n\n# Function to calculate ROUGE-1, ROUGE-2, and ROUGE-L scores for a pair of texts\ndef calculate_rouge_scores(reference_tokens, system_tokens):\n    def lcs(X, Y):\n        m, n = len(X), len(Y)\n        dp = [[0] * (n + 1) for _ in range(m + 1)]\n\n        for i in range(1, m + 1):\n            for j in range(1, n + 1):\n                if X[i - 1] == Y[j - 1]:\n                    dp[i][j] = dp[i - 1][j - 1] + 1\n                else:\n                    dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n\n        return dp[m][n]\n\n    # Calculate ROUGE-1 (unigram) scores\n    reference_unigrams = set(reference_tokens)\n    system_unigrams = set(system_tokens)\n    overlap_rouge1 = len(reference_unigrams.intersection(system_unigrams))\n    precision_rouge1 = overlap_rouge1 / len(system_unigrams)\n    recall_rouge1 = overlap_rouge1 / len(reference_unigrams)\n    r1_t = 1 if precision_rouge1 + recall_rouge1 == 0 else 0\n    f1_rouge1 = 2 * (precision_rouge1 * recall_rouge1) / (precision_rouge1 + recall_rouge1 + r1_t)\n\n    # Calculate ROUGE-2 (bigram) scores\n    reference_bigrams = set(ngrams(reference_tokens, 2))\n    system_bigrams = set(ngrams(system_tokens, 2))\n    overlap_rouge2 = len(reference_bigrams.intersection(system_bigrams))\n    precision_rouge2 = overlap_rouge2 / len(system_bigrams)\n    recall_rouge2 = overlap_rouge2 / len(reference_bigrams)\n    r2_t = 1 if precision_rouge2 + recall_rouge2 == 0 else 1\n    f1_rouge2 = 2 * (precision_rouge2 * recall_rouge2) / (precision_rouge2 + recall_rouge2 + r2_t)\n\n    # Calculate ROUGE-L scores\n    lcs_length = lcs(reference_tokens, system_tokens)\n    precision_rougeL = lcs_length / len(system_tokens)\n    recall_rougeL = lcs_length / len(reference_tokens)\n    rL_t = 1 if precision_rougeL + recall_rougeL == 0 else 0\n    f1_rougeL = 2 * (precision_rougeL * recall_rougeL) / (precision_rougeL + recall_rougeL + rL_t)\n\n    return {\n        'ROUGE-1 Precision': precision_rouge1,\n        'ROUGE-1 Recall': recall_rouge1,\n        'ROUGE-1 F1': f1_rouge1,\n        'ROUGE-2 Precision': precision_rouge2,\n        'ROUGE-2 Recall': recall_rouge2,\n        'ROUGE-2 F1': f1_rouge2,\n        'ROUGE-L Precision': precision_rougeL,\n        'ROUGE-L Recall': recall_rougeL,\n        'ROUGE-L F1': f1_rougeL,\n    }\n\n# Function to calculate the average of ROUGE scores for an array of text pairs\ndef calculate_average_rouge_scores(reference_texts, system_texts):\n    total_scores = {\n        'ROUGE-1 Precision': 0,\n        'ROUGE-1 Recall': 0,\n        'ROUGE-1 F1': 0,\n        'ROUGE-2 Precision': 0,\n        'ROUGE-2 Recall': 0,\n        'ROUGE-2 F1': 0,\n        'ROUGE-L Precision': 0,\n        'ROUGE-L Recall': 0,\n        'ROUGE-L F1': 0,\n    }\n\n    num_pairs = len(reference_texts)\n\n    for i in range(num_pairs):\n        reference_text = reference_texts[i]\n        system_text = system_texts[i]\n\n        reference_tokens = nltk.word_tokenize(reference_text)\n        system_tokens = nltk.word_tokenize(system_text)\n\n        scores = calculate_rouge_scores(reference_tokens, system_tokens)\n\n        for key, value in scores.items():\n            total_scores[key] += value\n\n    # Calculate the average scores\n    average_scores = {key: value / num_pairs for key, value in total_scores.items()}\n    \n    return average_scores\n\n# Example usage with an array of reference and system texts\n# reference_texts = test_d_ground\n# system_texts = [correct_grammar(test_d_sentence[i],num_return_sequences=2,input_len=test_d_len[i])[0] for i in range(len(test_d_sentence)) ]\n\nreference_texts = [\"আপনিও শুরু এখন, অ্যাপ নাম সাইজ কই।\", \"আপনিও শুরু এখন, অ্যাপ নাম সাইজ কই।\"]\nsystem_texts = [\"আপনিও শুরু এখন, অ্যাপ ইউজার নাম সাইজ কই।\", \"আপনিও শুরু এখন, অ্যাপ ইউজার নাম সাইজ কই।\"]\n\n\naverage_scores = calculate_average_rouge_scores(reference_texts, system_texts)\nprint(\"Average ROUGE Scores:\")\nfor key, value in average_scores.items():\n    print(key + \": {:.4f}\".format(value))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}