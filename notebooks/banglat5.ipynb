{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8593204,"sourceType":"datasetVersion","datasetId":5140374},{"sourceId":8638125,"sourceType":"datasetVersion","datasetId":5167159}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-08T09:04:31.283116Z","iopub.execute_input":"2024-06-08T09:04:31.283934Z","iopub.status.idle":"2024-06-08T09:04:32.269596Z","shell.execute_reply.started":"2024-06-08T09:04:31.283903Z","shell.execute_reply":"2024-06-08T09:04:32.268592Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/banglat5-output/checkpoint-9716/config.json\n/kaggle/input/banglat5-output/checkpoint-9716/trainer_state.json\n/kaggle/input/banglat5-output/checkpoint-9716/spiece.model\n/kaggle/input/banglat5-output/checkpoint-9716/training_args.bin\n/kaggle/input/banglat5-output/checkpoint-9716/tokenizer_config.json\n/kaggle/input/banglat5-output/checkpoint-9716/scheduler.pt\n/kaggle/input/banglat5-output/checkpoint-9716/model.safetensors\n/kaggle/input/banglat5-output/checkpoint-9716/special_tokens_map.json\n/kaggle/input/banglat5-output/checkpoint-9716/optimizer.pt\n/kaggle/input/banglat5-output/checkpoint-9716/rng_state.pth\n/kaggle/input/banglat5-output/checkpoint-9716/added_tokens.json\n/kaggle/input/banglat5-output/checkpoint-9716/generation_config.json\n/kaggle/input/pentabd-transliterated-dataset/val.csv\n/kaggle/input/pentabd-transliterated-dataset/train.csv\n/kaggle/input/pentabd-transliterated-dataset/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install wandb -qqq\nimport wandb","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:04:32.271431Z","iopub.execute_input":"2024-06-08T09:04:32.272299Z","iopub.status.idle":"2024-06-08T09:04:46.913781Z","shell.execute_reply.started":"2024-06-08T09:04:32.272260Z","shell.execute_reply":"2024-06-08T09:04:46.912792Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb_api_key\")","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:04:46.915039Z","iopub.execute_input":"2024-06-08T09:04:46.915369Z","iopub.status.idle":"2024-06-08T09:04:47.164634Z","shell.execute_reply.started":"2024-06-08T09:04:46.915337Z","shell.execute_reply":"2024-06-08T09:04:47.163758Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"! wandb login $secret_value_0","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:04:47.166631Z","iopub.execute_input":"2024-06-08T09:04:47.166945Z","iopub.status.idle":"2024-06-08T09:04:50.393841Z","shell.execute_reply.started":"2024-06-08T09:04:47.166917Z","shell.execute_reply":"2024-06-08T09:04:50.392692Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:04:50.395467Z","iopub.execute_input":"2024-06-08T09:04:50.395842Z","iopub.status.idle":"2024-06-08T09:05:03.084338Z","shell.execute_reply.started":"2024-06-08T09:04:50.395801Z","shell.execute_reply":"2024-06-08T09:05:03.083006Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom transformers import AutoTokenizer, MT5Model, TrainingArguments, Trainer, MT5ForConditionalGeneration, AutoModelForSeq2SeqLM\nimport torch\n\n# tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")\nmodel_name = \"/kaggle/input/banglat5-output/checkpoint-9716\" #\"google/mt5-small\"  # \"csebuetnlp/banglat5_nmt_en_bn\"Adjust if using a pre-trained model\n\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\ntorch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# model = MT5ForConditionalGeneration.from_pretrained(model_name).to(torch_device)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(torch_device)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:05:07.246350Z","iopub.execute_input":"2024-06-08T09:05:07.246772Z","iopub.status.idle":"2024-06-08T09:05:33.797141Z","shell.execute_reply.started":"2024-06-08T09:05:07.246737Z","shell.execute_reply":"2024-06-08T09:05:33.796009Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"2024-06-08 09:05:14.918033: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-08 09:05:14.918157: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-08 09:05:15.044919: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install git+https://github.com/csebuetnlp/normalizer\nfrom normalizer import normalize","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:05:33.799445Z","iopub.execute_input":"2024-06-08T09:05:33.800290Z","iopub.status.idle":"2024-06-08T09:05:55.041579Z","shell.execute_reply.started":"2024-06-08T09:05:33.800250Z","shell.execute_reply":"2024-06-08T09:05:55.040749Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting git+https://github.com/csebuetnlp/normalizer\n  Cloning https://github.com/csebuetnlp/normalizer to /tmp/pip-req-build-b48f0umu\n  Running command git clone --filter=blob:none --quiet https://github.com/csebuetnlp/normalizer /tmp/pip-req-build-b48f0umu\n  Resolved https://github.com/csebuetnlp/normalizer to commit d405944dde5ceeacb7c2fd3245ae2a9dea5f35c9\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from normalizer==0.0.1) (2023.12.25)\nCollecting emoji==1.4.2 (from normalizer==0.0.1)\n  Downloading emoji-1.4.2.tar.gz (184 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/185.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting ftfy==6.0.3 (from normalizer==0.0.1)\n  Downloading ftfy-6.0.3.tar.gz (64 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy==6.0.3->normalizer==0.0.1) (0.2.13)\nBuilding wheels for collected packages: normalizer, emoji, ftfy\n  Building wheel for normalizer (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for normalizer: filename=normalizer-0.0.1-py3-none-any.whl size=6859 sha256=fe34424ce24ed123d17c747a824ac9a080ff538503064e31db0dcd6df8e446b2\n  Stored in directory: /tmp/pip-ephem-wheel-cache-wouj6l8e/wheels/2e/79/9c/cd96d490298305d51d2da11484bb2c25fd1f759a6906708282\n  Building wheel for emoji (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186460 sha256=fadce948e3874962db986ca1628a960846922cbea4f2a44318f22f95315a0d7f\n  Stored in directory: /root/.cache/pip/wheels/10/f0/fd/4813b1177405693e8da9cdea839f0fb64fde161380e058c827\n  Building wheel for ftfy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41929 sha256=caee656cdac17054e3fdb163d6b77dd1e602821a184a6d20f9ae985d8485d7ef\n  Stored in directory: /root/.cache/pip/wheels/92/8e/16/c1e4d4d65685d71085e4e27b44d6ed880b0559474c9ee4ff66\nSuccessfully built normalizer emoji ftfy\nInstalling collected packages: emoji, ftfy, normalizer\n  Attempting uninstall: emoji\n    Found existing installation: emoji 2.12.1\n    Uninstalling emoji-2.12.1:\n      Successfully uninstalled emoji-2.12.1\nSuccessfully installed emoji-1.4.2 ftfy-6.0.3 normalizer-0.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/pentabd-transliterated-dataset/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/pentabd-transliterated-dataset/test.csv\")\ndf_val =  pd.read_csv(\"/kaggle/input/pentabd-transliterated-dataset/val.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:05:55.043047Z","iopub.execute_input":"2024-06-08T09:05:55.043352Z","iopub.status.idle":"2024-06-08T09:05:55.439882Z","shell.execute_reply.started":"2024-06-08T09:05:55.043325Z","shell.execute_reply":"2024-06-08T09:05:55.438781Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:05:55.442356Z","iopub.execute_input":"2024-06-08T09:05:55.442689Z","iopub.status.idle":"2024-06-08T09:05:55.467451Z","shell.execute_reply.started":"2024-06-08T09:05:55.442661Z","shell.execute_reply":"2024-06-08T09:05:55.466567Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                         id                           dataset  \\\n0      e3839126-f351-4ff2-81b2-0d347a93b2db            penta_trickbd_external   \n1      b14214ab-a53d-47d4-9e58-298e1b3e6f42            penta_trickbd_external   \n2      20d6a478-daac-4459-b362-cfd076a5ee50            penta_trickbd_external   \n3      13f5078f-3f6c-4a81-be24-b3ef1cc8c984            penta_trickbd_external   \n4      85b9e667-07a2-4861-bbfa-49b5b3107a79            penta_trickbd_external   \n...                                     ...                               ...   \n38859  bc6da3ec-7dc7-4b00-a31f-45e3e3082499  springer_autobacktransliteration   \n38860  4c8ce30f-9119-4ebd-9ac0-7049dcb8a17d  springer_autobacktransliteration   \n38861  c698d5b7-d06f-401b-9eac-c38081f49bb0  springer_autobacktransliteration   \n38862  67d48ea7-85a6-450c-8367-c3c1aa4ecd45  springer_autobacktransliteration   \n38863  1c2e996f-8249-4107-924a-798d65039cd9  springer_autobacktransliteration   \n\n                                     text_transliterated  \\\n0      Phone resulation 480p,vedio recording 1080p! How?   \n1                            Flash Tool Ki Letest Verson   \n2      yes..Oem to Unlock kortey hobe ar root korar p...   \n3      lav nai oi eki joma dite jawai lagbe tokhn tak...   \n4                   Deliverer option nai amar.. ki korbo   \n...                                                  ...   \n38859                     Eder ke mati chapa deya dorkar   \n38860                         Oder ekdin bichar hobe vai   \n38861                                      Opekkha koren   \n38862                                       Shomoy ashbe   \n38863                                Amadero somoy ashbe   \n\n                                            text_bengali  \n0        ফোন রেজুলেশন ৪৮০পি, ভিডিও রেকর্ডিং ১০৮০পি! হাও?  \n1                          ফ্ল্যাশ টুল কি লেটেস্ট ভার্সন  \n2      ইয়েস..ওএম তো আনলক করতে হবে আর রুট করার পর ও সে...  \n3      লাভ নাই ওই একি জমা দিতে যাওয়াই লাগবে তখন টাকা ...  \n4                       ডেলিভারার অপশন নেই আমার.. কি করব  \n...                                                  ...  \n38859                       এদের কে মাটি চাপা দেয়া দরকার  \n38860                           ওদের একদিন বিচার হবে ভাই  \n38861                                       অপেক্ষা করেন  \n38862                                           সময় আসবে  \n38863                                   আমাদেরও সময় আসবে  \n\n[38864 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dataset</th>\n      <th>text_transliterated</th>\n      <th>text_bengali</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e3839126-f351-4ff2-81b2-0d347a93b2db</td>\n      <td>penta_trickbd_external</td>\n      <td>Phone resulation 480p,vedio recording 1080p! How?</td>\n      <td>ফোন রেজুলেশন ৪৮০পি, ভিডিও রেকর্ডিং ১০৮০পি! হাও?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b14214ab-a53d-47d4-9e58-298e1b3e6f42</td>\n      <td>penta_trickbd_external</td>\n      <td>Flash Tool Ki Letest Verson</td>\n      <td>ফ্ল্যাশ টুল কি লেটেস্ট ভার্সন</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20d6a478-daac-4459-b362-cfd076a5ee50</td>\n      <td>penta_trickbd_external</td>\n      <td>yes..Oem to Unlock kortey hobe ar root korar p...</td>\n      <td>ইয়েস..ওএম তো আনলক করতে হবে আর রুট করার পর ও সে...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13f5078f-3f6c-4a81-be24-b3ef1cc8c984</td>\n      <td>penta_trickbd_external</td>\n      <td>lav nai oi eki joma dite jawai lagbe tokhn tak...</td>\n      <td>লাভ নাই ওই একি জমা দিতে যাওয়াই লাগবে তখন টাকা ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>85b9e667-07a2-4861-bbfa-49b5b3107a79</td>\n      <td>penta_trickbd_external</td>\n      <td>Deliverer option nai amar.. ki korbo</td>\n      <td>ডেলিভারার অপশন নেই আমার.. কি করব</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>38859</th>\n      <td>bc6da3ec-7dc7-4b00-a31f-45e3e3082499</td>\n      <td>springer_autobacktransliteration</td>\n      <td>Eder ke mati chapa deya dorkar</td>\n      <td>এদের কে মাটি চাপা দেয়া দরকার</td>\n    </tr>\n    <tr>\n      <th>38860</th>\n      <td>4c8ce30f-9119-4ebd-9ac0-7049dcb8a17d</td>\n      <td>springer_autobacktransliteration</td>\n      <td>Oder ekdin bichar hobe vai</td>\n      <td>ওদের একদিন বিচার হবে ভাই</td>\n    </tr>\n    <tr>\n      <th>38861</th>\n      <td>c698d5b7-d06f-401b-9eac-c38081f49bb0</td>\n      <td>springer_autobacktransliteration</td>\n      <td>Opekkha koren</td>\n      <td>অপেক্ষা করেন</td>\n    </tr>\n    <tr>\n      <th>38862</th>\n      <td>67d48ea7-85a6-450c-8367-c3c1aa4ecd45</td>\n      <td>springer_autobacktransliteration</td>\n      <td>Shomoy ashbe</td>\n      <td>সময় আসবে</td>\n    </tr>\n    <tr>\n      <th>38863</th>\n      <td>1c2e996f-8249-4107-924a-798d65039cd9</td>\n      <td>springer_autobacktransliteration</td>\n      <td>Amadero somoy ashbe</td>\n      <td>আমাদেরও সময় আসবে</td>\n    </tr>\n  </tbody>\n</table>\n<p>38864 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# df_train = df_train[:300]\n# df_test = df_test[:40]\n# df_val = df_val[:40]\n","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:05:55.468618Z","iopub.execute_input":"2024-06-08T09:05:55.469269Z","iopub.status.idle":"2024-06-08T09:05:55.473136Z","shell.execute_reply.started":"2024-06-08T09:05:55.469237Z","shell.execute_reply":"2024-06-08T09:05:55.472227Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(df_train.isna().sum())\nprint(df_test.isna().sum())\nprint(df_val.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:05:55.474315Z","iopub.execute_input":"2024-06-08T09:05:55.474652Z","iopub.status.idle":"2024-06-08T09:05:55.504733Z","shell.execute_reply.started":"2024-06-08T09:05:55.474620Z","shell.execute_reply":"2024-06-08T09:05:55.503650Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"id                     0\ndataset                0\ntext_transliterated    0\ntext_bengali           0\ndtype: int64\nid                     0\ndataset                0\ntext_transliterated    0\ntext_bengali           0\ndtype: int64\nid                     0\ndataset                0\ntext_transliterated    0\ntext_bengali           0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\n# Download necessary NLTK resources (may need internet connection)\nnltk.download('punkt')\nnltk.download('stopwords')\n\ndef clean_text(text, language='english'):\n    text = ''.join([char for char in text if char.isalnum() or char.isspace()])\n\n    # Convert to lowercase\n    text = text.lower()\n\n    # Remove stopwords (optional, adjust stopword list based on language)\n    stop_words = stopwords.words(language)\n    text = ' '.join([word for word in text.split() if word not in stop_words])\n\n    return text\n\n# Clean Banglish and Bengali text\n# df['Banglish_Clean'] = df['Banglish'].apply(clean_text)\n# df['Bengali_Clean'] = df['Bengali'].apply(clean_text, language='bengali')  # Specify Bengali for stopword removal\n\n# Normalization for Bengali text (replace with your desired normalization function)\ndef normalize_bengali(text):\n    normalized_text = normalize(text)\n    return normalized_text\n\ndf_train['normalized_bengali'] = df_train['text_bengali'].apply(normalize_bengali)\ndf_test['normalized_bengali'] = df_test['text_bengali'].apply(normalize_bengali)\ndf_val['normalized_bengali'] = df_val['text_bengali'].apply(normalize_bengali)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:05:55.506072Z","iopub.execute_input":"2024-06-08T09:05:55.506425Z","iopub.status.idle":"2024-06-08T09:06:03.529515Z","shell.execute_reply.started":"2024-06-08T09:05:55.506394Z","shell.execute_reply":"2024-06-08T09:06:03.528510Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train[\"normalized_bengali\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:06:03.531074Z","iopub.execute_input":"2024-06-08T09:06:03.531552Z","iopub.status.idle":"2024-06-08T09:06:03.538216Z","shell.execute_reply.started":"2024-06-08T09:06:03.531507Z","shell.execute_reply":"2024-06-08T09:06:03.537233Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'ফোন রেজুলেশন ৪৮০পি, ভিডিও রেকর্ডিং ১০৮০পি! হাও?'"},"metadata":{}}]},{"cell_type":"code","source":"def find_max_length(df, column_name):\n    # Find the index of the text with the maximum length\n    max_length_index = df[column_name].str.len().idxmax()\n\n    # Get the text with the maximum length\n    max_length_text = df.loc[max_length_index, column_name]\n\n    # Print the maximum length and the corresponding text\n#     print(f\"Index of the text with maximum length: {max_length_index}\")\n#     print(f\"Maximum length: {len(max_length_text)}\")\n#     print(f\"Text with maximum length:\\n{max_length_text}\")\n    return len(max_length_text)\n\n# find_max_length(df_train, 'text_bengali')\n# print(df_train['text_bengali'][10454])","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:06:03.539479Z","iopub.execute_input":"2024-06-08T09:06:03.540157Z","iopub.status.idle":"2024-06-08T09:06:03.547776Z","shell.execute_reply.started":"2024-06-08T09:06:03.540132Z","shell.execute_reply":"2024-06-08T09:06:03.547003Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\ndef pad_truncate(df):\n    max_length = 200\n#     print(max_length)\n    bengali_tokenized = tokenizer(df['normalized_bengali'].tolist(), padding=\"max_length\", truncation=True)\n#     print(bengali_tokenized)\n#     max_length = find_max_length(df, 'text_transliterated')\n    banglish_tokenized = tokenizer(df['text_transliterated'].tolist(), padding=\"max_length\", truncation=True)\n\n    dataset = Dataset.from_dict({\n        \"input_ids\": banglish_tokenized[\"input_ids\"],\n        \"attention_mask\": banglish_tokenized[\"attention_mask\"],\n        \"labels\": bengali_tokenized[\"input_ids\"]  # Labels are target language tokens\n    })\n    \n    return dataset\n\ntrain_dataset = pad_truncate(df_train)\n# print(banglish, bengali)\n# pad_truncate(df_test)\n# pad_truncate(df_val)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:06:03.551280Z","iopub.execute_input":"2024-06-08T09:06:03.551555Z","iopub.status.idle":"2024-06-08T09:06:29.913794Z","shell.execute_reply.started":"2024-06-08T09:06:03.551525Z","shell.execute_reply":"2024-06-08T09:06:29.912766Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"test_dataset = pad_truncate(df_test)\nval_dataset = pad_truncate(df_val)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:06:29.915257Z","iopub.execute_input":"2024-06-08T09:06:29.915607Z","iopub.status.idle":"2024-06-08T09:06:32.679035Z","shell.execute_reply.started":"2024-06-08T09:06:29.915562Z","shell.execute_reply":"2024-06-08T09:06:32.677963Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n# training_args = TrainingArguments(\n#     output_dir=\"./mt5_banglish_bengali\",  # Output directory for checkpoints\n#     evaluation_strategy=\"steps\",\n#     overwrite_output_dir=True,  # Overwrite existing directory if it exists\n#     num_train_epochs=3,  # Adjust based on dataset size and desired accuracy\n#     per_device_train_batch_size=2,  # Adjust batch size based on GPU memory\n#     save_steps=50,  # Save model checkpoints every 10,000 steps\n#     save_total_limit=2,  # Keep only the most recent 2 checkpoints\n#     logging_steps=50,  # Log training progress every 500 steps\n#     fp16 = True,\n#     gradient_accumulation_steps = 6,\n#     load_best_model_at_end=True  # Load the best model based on validation metrics\n# )\n\nbatch_size = 4\nargs = Seq2SeqTrainingArguments(output_dir=\"weights\",\n                        evaluation_strategy=\"epoch\",\n                        save_strategy = \"epoch\",\n                        per_device_train_batch_size=batch_size,\n                        per_device_eval_batch_size=batch_size,\n                        learning_rate=5e-5,\n                        num_train_epochs=7,\n                        weight_decay=0.01,\n                        save_total_limit=3,\n                        predict_with_generate=True,\n                        fp16 = False,\n                        gradient_accumulation_steps = 6,\n                        save_steps = 50,\n                        logging_steps = 50,\n                        load_best_model_at_end=True,\n                        logging_dir=\"/logs\",\n                        report_to=\"wandb\")","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:59:23.647005Z","iopub.execute_input":"2024-06-07T08:59:23.647775Z","iopub.status.idle":"2024-06-07T08:59:23.688300Z","shell.execute_reply.started":"2024-06-07T08:59:23.647738Z","shell.execute_reply":"2024-06-07T08:59:23.687399Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install bert-score","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:59:23.689497Z","iopub.execute_input":"2024-06-07T08:59:23.689772Z","iopub.status.idle":"2024-06-07T08:59:36.675984Z","shell.execute_reply.started":"2024-06-07T08:59:23.689749Z","shell.execute_reply":"2024-06-07T08:59:36.674834Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.1.2)\nRequirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.2.1)\nRequirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert-score) (4.41.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert-score) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.32.3)\nRequirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (4.66.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert-score) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert-score) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2023.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2024.3.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.23.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.4.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (9.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (2024.2.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: bert-score\nSuccessfully installed bert-score-0.3.13\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_metric\n\n# Load the BERTScore metric\nbert_metric = load_metric('bertscore')","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:59:36.677573Z","iopub.execute_input":"2024-06-07T08:59:36.677956Z","iopub.status.idle":"2024-06-07T08:59:37.807938Z","shell.execute_reply.started":"2024-06-07T08:59:36.677919Z","shell.execute_reply":"2024-06-07T08:59:37.807007Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1619319013.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n  bert_metric = load_metric('bertscore')\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for bertscore contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.2/metrics/bertscore/bertscore.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78c070e4ad2149128e5f87ca09e8e971"}},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(preds_and_labels):\n    preds, labels = preds_and_labels\n\n    # Decode the predictions and labels using the tokenizer, skipping special tokens\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    \n    # Replace -100 (masked tokens) in labels with the pad token ID\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    \n    # Decode the labels using the tokenizer, skipping special tokens\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    # Compute BERTScore using decoded predictions and labels\n    result = bert_metric.compute(predictions=decoded_preds, references=decoded_labels, lang='bn')\n    \n    # Return the BERTScore as a dictionary\n    return {\n      'BERT F1': np.mean(result['f1']),\n      'BERT Precision': np.mean(result['precision']),\n      'BERT Recall': np.mean(result['recall'])\n  }","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:59:37.809175Z","iopub.execute_input":"2024-06-07T08:59:37.809465Z","iopub.status.idle":"2024-06-07T08:59:37.816258Z","shell.execute_reply.started":"2024-06-07T08:59:37.809441Z","shell.execute_reply":"2024-06-07T08:59:37.815241Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\n# Instantiate a Seq2Seq model from the specified checkpoint\n\n# Define a data collator for Seq2Seq tasks\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:59:37.817265Z","iopub.execute_input":"2024-06-07T08:59:37.817506Z","iopub.status.idle":"2024-06-07T08:59:37.828757Z","shell.execute_reply.started":"2024-06-07T08:59:37.817485Z","shell.execute_reply":"2024-06-07T08:59:37.827910Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=args,\n    data_collator=data_collator,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,\n    compute_metrics = compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:59:37.829925Z","iopub.execute_input":"2024-06-07T08:59:37.830693Z","iopub.status.idle":"2024-06-07T08:59:37.869542Z","shell.execute_reply.started":"2024-06-07T08:59:37.830661Z","shell.execute_reply":"2024-06-07T08:59:37.868759Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:59:37.870622Z","iopub.execute_input":"2024-06-07T08:59:37.870938Z","iopub.status.idle":"2024-06-07T09:03:35.183875Z","shell.execute_reply.started":"2024-06-07T08:59:37.870913Z","shell.execute_reply":"2024-06-07T09:03:35.182423Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfabihahaider4\u001b[0m (\u001b[33mpenta_global\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240607_085940-5f060v7l</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/penta_global/huggingface/runs/5f060v7l' target=\"_blank\">weights</a></strong> to <a href='https://wandb.ai/penta_global/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/penta_global/huggingface' target=\"_blank\">https://wandb.ai/penta_global/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/penta_global/huggingface/runs/5f060v7l' target=\"_blank\">https://wandb.ai/penta_global/huggingface/runs/5f060v7l</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='54' max='11333' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   54/11333 03:29 < 12:37:14, 0.25 it/s, Epoch 0.03/7]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2216\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2216\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2219\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2222\u001b[0m ):\n\u001b[1;32m   2223\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2224\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3250\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3248\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3250\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:2125\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2124\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2125\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-06-07T09:03:35.185235Z","iopub.status.idle":"2024-06-07T09:03:35.185724Z","shell.execute_reply.started":"2024-06-07T09:03:35.185472Z","shell.execute_reply":"2024-06-07T09:03:35.185492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_output(input_sentence):\n    input_ids = tokenizer((input_sentence), return_tensors=\"pt\").input_ids.to(\"cuda\")\n    generated_tokens = model.generate(input_ids)\n    decoded_tokens = tokenizer.batch_decode(generated_tokens)[0]\n    decoded_tokens = normalize(decoded_tokens)\n\n    return decoded_tokens\n    \ndf_test['predictions'] = df_test['text_transliterated'].apply(predict_output)\ndf_test.to_csv(\"banglaT5_test.csv\", index = False)\n\ndf_val['predictions'] = df_val['text_transliterated'].apply(predict_output)\ndf_val.to_csv(\"banglaT5_val.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:06:32.680323Z","iopub.execute_input":"2024-06-08T09:06:32.680628Z","iopub.status.idle":"2024-06-08T09:21:54.198588Z","shell.execute_reply.started":"2024-06-08T09:06:32.680603Z","shell.execute_reply":"2024-06-08T09:21:54.197582Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"df_test","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:21:54.199715Z","iopub.execute_input":"2024-06-08T09:21:54.199981Z","iopub.status.idle":"2024-06-08T09:21:54.217237Z","shell.execute_reply.started":"2024-06-08T09:21:54.199956Z","shell.execute_reply":"2024-06-08T09:21:54.216090Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                        id                 dataset  \\\n0     f5afeacc-e452-497d-80d4-daf5c3238368  penta_trickbd_external   \n1     14a899f1-e09d-4fc2-ad2d-f92075d5992a  penta_trickbd_external   \n2     379c0d55-c07f-4832-8f88-686640233377  penta_trickbd_external   \n3     5988a6d1-0bbc-453e-a93f-9e34294f6c09  penta_trickbd_external   \n4     9f505ba3-ec5f-442c-8e9e-f98d0062c27d  penta_trickbd_external   \n...                                    ...                     ...   \n2495  71df756f-279b-4454-b9c0-63a88afd941f  penta_trickbd_external   \n2496  aea2444d-7a1a-41a6-9206-84be015c3ebe  penta_trickbd_external   \n2497  6abf65f5-d78f-41f4-884b-59086c241e03  penta_trickbd_external   \n2498  b484d9ea-c523-4f6e-b328-245d5de7ee52  penta_trickbd_external   \n2499  12d4dd55-c539-47d8-a97c-953aecf6d24c  penta_trickbd_external   \n\n                                    text_transliterated  \\\n0     oi mia watermark a click korle subscribe hobe ...   \n1                            Eta niyeo post korte hoy??   \n2                     flat style bar indicator.apk diye   \n3     ekhane gia ager adress copy kore abar kaj korr...   \n4     background pic select kore save korle protol n...   \n...                                                 ...   \n2495  ipl er jonno youtube e jotesto… but Ufa or lal...   \n2496  tnx…bro,,,Happy new year ta sort kate likeswn ...   \n2497    Oo taile thik ache ami onno kichu vabchilam.. 🙂   \n2498  vai ata sobai jane. tai jkew show hidden file ...   \n2499         Vai amar tao i20, kintu root korbo kivabe?   \n\n                                           text_bengali  \\\n0     ঐ মিয়া ওয়াটারমার্ক এ ক্লিক করলে সাবস্ক্রাইব হব...   \n1                           ফ্লাট নিয়েও পোস্ট করতে হয়??   \n2                       ফ্লাট স্টাইল indicator.apk দিয়ে   \n3     এখানে গিয়ে আগের অ্যাডরেস কপি করে আবার কাজ করতে...   \n4     ব্যাকগ্রাউণ্ড পিক সিলেক্ট করে সেভ করলে প্রটোল ...   \n...                                                 ...   \n2495  আইপিএল এর জন্য ইউটিউবে যথেষ্ট… কিন্তু ইউএফএ বা...   \n2496  ধন্যবাদ ভাই,,,হ্যাপি নিউ ইয়ার টা শর্টকাটে লেখস...   \n2497         ও তাইলে ঠিক আছে আমি অন্য কিছু ভাবছিলাম.. 🙂   \n2498  ভাই এটা সবাই জানে। তাই কেউ show hidden file on...   \n2499           ভাই আমার ও আই২০, কিন্তু রুট করবো কিভাবে?   \n\n                                     normalized_bengali  \\\n0     ঐ মিয়া ওয়াটারমার্ক এ ক্লিক করলে সাবস্ক্রাইব ...   \n1                         ফ্লাট নিয়েও পোস্ট করতে হয়??   \n2                      ফ্লাট স্টাইল indicator.apk দিয়ে   \n3     এখানে গিয়ে আগের অ্যাডরেস কপি করে আবার কাজ করত...   \n4     ব্যাকগ্রাউণ্ড পিক সিলেক্ট করে সেভ করলে প্রটোল ...   \n...                                                 ...   \n2495  আইপিএল এর জন্য ইউটিউবে যথেষ্ট... কিন্তু ইউএফএ ...   \n2496  ধন্যবাদ ভাই,,,হ্যাপি নিউ ইয়ার টা শর্টকাটে লেখ...   \n2497         ও তাইলে ঠিক আছে আমি অন্য কিছু ভাবছিলাম.. 🙂   \n2498  ভাই এটা সবাই জানে। তাই কেউ show hidden file on...   \n2499           ভাই আমার ও আই২০, কিন্তু রুট করবো কিভাবে?   \n\n                                            predictions  \n0     <pad> ওই মিয়া ওয়াটারমার্ক এ ক্লিক করলে সাবস্...  \n1                 <pad> এটা নিয়েও পোস্ট করতে হয়??</s>  \n2     <pad> ফ্ল্যাট স্টাইল বার ইনডিকেটর।এপিকে দিয়ে</s>  \n3     <pad>এখানে গিয়া আগের এডপ্রেস কপি করে আবার কাজ...  \n4     <pad> ব্যাকগ্রাউন্ড পিক সিলেক্ট করে সেভ করলে প...  \n...                                                 ...  \n2495  <pad>আইপ এর জন্য ইউটিউব এ যথেষ্ট... বাট ইউফা অ...  \n2496  <pad>থ্যাংকস...ব্রো,,,হ্যাপি নিউ ইয়ার টা সর্ট...  \n2497  <pad> ওও তাইলে ঠিক আছে আমি অন্য কিছু ভাবছিলাম....  \n2498  <pad>ভাই এটা সবাই জানে। তাই কেউ শো হিডেন ফাইল ...  \n2499  <pad> ভাই আমার টাও আই২০, কিন্তু রুট করবো কিভাব...  \n\n[2500 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dataset</th>\n      <th>text_transliterated</th>\n      <th>text_bengali</th>\n      <th>normalized_bengali</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f5afeacc-e452-497d-80d4-daf5c3238368</td>\n      <td>penta_trickbd_external</td>\n      <td>oi mia watermark a click korle subscribe hobe ...</td>\n      <td>ঐ মিয়া ওয়াটারমার্ক এ ক্লিক করলে সাবস্ক্রাইব হব...</td>\n      <td>ঐ মিয়া ওয়াটারমার্ক এ ক্লিক করলে সাবস্ক্রাইব ...</td>\n      <td>&lt;pad&gt; ওই মিয়া ওয়াটারমার্ক এ ক্লিক করলে সাবস্...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14a899f1-e09d-4fc2-ad2d-f92075d5992a</td>\n      <td>penta_trickbd_external</td>\n      <td>Eta niyeo post korte hoy??</td>\n      <td>ফ্লাট নিয়েও পোস্ট করতে হয়??</td>\n      <td>ফ্লাট নিয়েও পোস্ট করতে হয়??</td>\n      <td>&lt;pad&gt; এটা নিয়েও পোস্ট করতে হয়??&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>379c0d55-c07f-4832-8f88-686640233377</td>\n      <td>penta_trickbd_external</td>\n      <td>flat style bar indicator.apk diye</td>\n      <td>ফ্লাট স্টাইল indicator.apk দিয়ে</td>\n      <td>ফ্লাট স্টাইল indicator.apk দিয়ে</td>\n      <td>&lt;pad&gt; ফ্ল্যাট স্টাইল বার ইনডিকেটর।এপিকে দিয়ে&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5988a6d1-0bbc-453e-a93f-9e34294f6c09</td>\n      <td>penta_trickbd_external</td>\n      <td>ekhane gia ager adress copy kore abar kaj korr...</td>\n      <td>এখানে গিয়ে আগের অ্যাডরেস কপি করে আবার কাজ করতে...</td>\n      <td>এখানে গিয়ে আগের অ্যাডরেস কপি করে আবার কাজ করত...</td>\n      <td>&lt;pad&gt;এখানে গিয়া আগের এডপ্রেস কপি করে আবার কাজ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9f505ba3-ec5f-442c-8e9e-f98d0062c27d</td>\n      <td>penta_trickbd_external</td>\n      <td>background pic select kore save korle protol n...</td>\n      <td>ব্যাকগ্রাউণ্ড পিক সিলেক্ট করে সেভ করলে প্রটোল ...</td>\n      <td>ব্যাকগ্রাউণ্ড পিক সিলেক্ট করে সেভ করলে প্রটোল ...</td>\n      <td>&lt;pad&gt; ব্যাকগ্রাউন্ড পিক সিলেক্ট করে সেভ করলে প...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2495</th>\n      <td>71df756f-279b-4454-b9c0-63a88afd941f</td>\n      <td>penta_trickbd_external</td>\n      <td>ipl er jonno youtube e jotesto… but Ufa or lal...</td>\n      <td>আইপিএল এর জন্য ইউটিউবে যথেষ্ট… কিন্তু ইউএফএ বা...</td>\n      <td>আইপিএল এর জন্য ইউটিউবে যথেষ্ট... কিন্তু ইউএফএ ...</td>\n      <td>&lt;pad&gt;আইপ এর জন্য ইউটিউব এ যথেষ্ট... বাট ইউফা অ...</td>\n    </tr>\n    <tr>\n      <th>2496</th>\n      <td>aea2444d-7a1a-41a6-9206-84be015c3ebe</td>\n      <td>penta_trickbd_external</td>\n      <td>tnx…bro,,,Happy new year ta sort kate likeswn ...</td>\n      <td>ধন্যবাদ ভাই,,,হ্যাপি নিউ ইয়ার টা শর্টকাটে লেখস...</td>\n      <td>ধন্যবাদ ভাই,,,হ্যাপি নিউ ইয়ার টা শর্টকাটে লেখ...</td>\n      <td>&lt;pad&gt;থ্যাংকস...ব্রো,,,হ্যাপি নিউ ইয়ার টা সর্ট...</td>\n    </tr>\n    <tr>\n      <th>2497</th>\n      <td>6abf65f5-d78f-41f4-884b-59086c241e03</td>\n      <td>penta_trickbd_external</td>\n      <td>Oo taile thik ache ami onno kichu vabchilam.. 🙂</td>\n      <td>ও তাইলে ঠিক আছে আমি অন্য কিছু ভাবছিলাম.. 🙂</td>\n      <td>ও তাইলে ঠিক আছে আমি অন্য কিছু ভাবছিলাম.. 🙂</td>\n      <td>&lt;pad&gt; ওও তাইলে ঠিক আছে আমি অন্য কিছু ভাবছিলাম....</td>\n    </tr>\n    <tr>\n      <th>2498</th>\n      <td>b484d9ea-c523-4f6e-b328-245d5de7ee52</td>\n      <td>penta_trickbd_external</td>\n      <td>vai ata sobai jane. tai jkew show hidden file ...</td>\n      <td>ভাই এটা সবাই জানে। তাই কেউ show hidden file on...</td>\n      <td>ভাই এটা সবাই জানে। তাই কেউ show hidden file on...</td>\n      <td>&lt;pad&gt;ভাই এটা সবাই জানে। তাই কেউ শো হিডেন ফাইল ...</td>\n    </tr>\n    <tr>\n      <th>2499</th>\n      <td>12d4dd55-c539-47d8-a97c-953aecf6d24c</td>\n      <td>penta_trickbd_external</td>\n      <td>Vai amar tao i20, kintu root korbo kivabe?</td>\n      <td>ভাই আমার ও আই২০, কিন্তু রুট করবো কিভাবে?</td>\n      <td>ভাই আমার ও আই২০, কিন্তু রুট করবো কিভাবে?</td>\n      <td>&lt;pad&gt; ভাই আমার টাও আই২০, কিন্তু রুট করবো কিভাব...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2500 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_val","metadata":{"execution":{"iopub.status.busy":"2024-06-08T09:21:54.218566Z","iopub.execute_input":"2024-06-08T09:21:54.218910Z","iopub.status.idle":"2024-06-08T09:21:54.239252Z","shell.execute_reply.started":"2024-06-08T09:21:54.218880Z","shell.execute_reply":"2024-06-08T09:21:54.238209Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"                                        id                 dataset  \\\n0     4e670101-f164-4220-bb23-7a5f9a30b2c6  penta_trickbd_external   \n1     0bcd5128-96d1-4d8f-8ceb-ab64c5eb82d4  penta_trickbd_external   \n2     9e32b31c-5683-4778-90b3-95785b905d2d  penta_trickbd_external   \n3     bf484d13-0f1a-43ac-9703-25687f3806a2  penta_trickbd_external   \n4     95f170d8-24cf-4819-ac7b-cdaf090b57c1  penta_trickbd_external   \n...                                    ...                     ...   \n1495  fae94029-a03c-4970-9e26-1a9205f85609  penta_trickbd_external   \n1496  88378e71-ba7f-4245-8e65-faa6f4df72be  penta_trickbd_external   \n1497  2ed0a273-2ae5-4e93-a2b6-b48e556a1051  penta_trickbd_external   \n1498  aae28ebc-016d-4375-a60b-0486e86521f3  penta_trickbd_external   \n1499  0f38cb07-4742-4d5d-ae49-3b32763f866c  penta_trickbd_external   \n\n                                    text_transliterated  \\\n0                        oi mb diye Browse kora zabena?   \n1                                    Bolod marka post….   \n2        1$=1000captha puron korte hoibe…tahole hobe 1$   \n3                                   ei game khln nai..?   \n4                                   a ta age theke jani   \n...                                                 ...   \n1495              Bondho kore dise……network busy dekhay   \n1496  Vai, Apni Jodi ttf file gulo picsart-fonts a m...   \n1497  vai 10 second a kom holeo 10 taka katbe, ami e...   \n1498                               Kaj korche.Thank you   \n1499  নতুন reg kore 1150 Tau paysilam..kintu..ektu.....   \n\n                                           text_bengali  \\\n0                     ঐ মোবাইল দিয়ে ব্রাউজ করা যাবে না?   \n1                                    বলদ মার্কা পোস্ট….   \n2             1৳=১০০০ক্যাপচা পূরণ করতে হবে…তাহলে হবে 1৳   \n3                                      এই গেম খেলিনি..?   \n4                                     এটা আগে থেকে জানি   \n...                                                 ...   \n1495             বন্ধ করে দিছে…… নেটওয়ার্ক বিজি দেখায়   \n1496  ভাই, আপনি যদি টিটিএফ ফাইল গুলো পিক্সআর্ট-ফন্টস...   \n1497  ভাই ১০ সেকেন্ড এ কম হলেও ১০ টাকা কাটবে, আমি এর...   \n1498                                কাজ করছে। থ্যাংক ইউ   \n1499  নতুন রেজিস্ট্রেশন করে ১১৫০ টাউ পেয়েছিলাম.. কি...   \n\n                                     normalized_bengali  \\\n0                    ঐ মোবাইল দিয়ে ব্রাউজ করা যাবে না?   \n1                                  বলদ মার্কা পোস্ট....   \n2           1৳=১০০০ক্যাপচা পূরণ করতে হবে...তাহলে হবে 1৳   \n3                                      এই গেম খেলিনি..?   \n4                                     এটা আগে থেকে জানি   \n...                                                 ...   \n1495         বন্ধ করে দিছে...... নেটওয়ার্ক বিজি দেখায়   \n1496  ভাই, আপনি যদি টিটিএফ ফাইল গুলো পিক্সআর্ট-ফন্টস...   \n1497  ভাই ১০ সেকেন্ড এ কম হলেও ১০ টাকা কাটবে, আমি এর...   \n1498                                কাজ করছে। থ্যাংক ইউ   \n1499  নতুন রেজিস্ট্রেশন করে ১১৫০ টাউ পেয়েছিলাম.. কি...   \n\n                                            predictions  \n0            <pad> ওই এমবি দিয়ে ব্রাউজ করা যাবেনা?</s>  \n1                       <pad> ভালো মার্কা পোস্ট....</s>  \n2     <pad> ১$=১০০০০টাকা পূরণ করতে হবে...তাহলে হবে ১...  \n3                         <pad> এই গেম খেলেন নাই..?</s>  \n4                           <pad> এটা আগে থেকে জানি</s>  \n...                                                 ...  \n1495  <pad> বন্ধ করে দিসে......নেটওয়ার্ক বিজি দেখায...  \n1496  <pad>ভাই, আপনি যদি টিটিএফ ফাইল গুলো পিকস্ট-ফন্...  \n1497  <pad> ভাই ১০ সেকেন্ড এ কম হলেও ১০ টাকা কাটবে, ...  \n1498                       <pad> কাজ করছে।থ্যাংক ইউ</s>  \n1499  <pad>নতুন রেজ করে ১১৫০ তাও পাইসিলাম..কিন্তু..এ...  \n\n[1500 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dataset</th>\n      <th>text_transliterated</th>\n      <th>text_bengali</th>\n      <th>normalized_bengali</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4e670101-f164-4220-bb23-7a5f9a30b2c6</td>\n      <td>penta_trickbd_external</td>\n      <td>oi mb diye Browse kora zabena?</td>\n      <td>ঐ মোবাইল দিয়ে ব্রাউজ করা যাবে না?</td>\n      <td>ঐ মোবাইল দিয়ে ব্রাউজ করা যাবে না?</td>\n      <td>&lt;pad&gt; ওই এমবি দিয়ে ব্রাউজ করা যাবেনা?&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0bcd5128-96d1-4d8f-8ceb-ab64c5eb82d4</td>\n      <td>penta_trickbd_external</td>\n      <td>Bolod marka post….</td>\n      <td>বলদ মার্কা পোস্ট….</td>\n      <td>বলদ মার্কা পোস্ট....</td>\n      <td>&lt;pad&gt; ভালো মার্কা পোস্ট....&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9e32b31c-5683-4778-90b3-95785b905d2d</td>\n      <td>penta_trickbd_external</td>\n      <td>1$=1000captha puron korte hoibe…tahole hobe 1$</td>\n      <td>1৳=১০০০ক্যাপচা পূরণ করতে হবে…তাহলে হবে 1৳</td>\n      <td>1৳=১০০০ক্যাপচা পূরণ করতে হবে...তাহলে হবে 1৳</td>\n      <td>&lt;pad&gt; ১$=১০০০০টাকা পূরণ করতে হবে...তাহলে হবে ১...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bf484d13-0f1a-43ac-9703-25687f3806a2</td>\n      <td>penta_trickbd_external</td>\n      <td>ei game khln nai..?</td>\n      <td>এই গেম খেলিনি..?</td>\n      <td>এই গেম খেলিনি..?</td>\n      <td>&lt;pad&gt; এই গেম খেলেন নাই..?&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>95f170d8-24cf-4819-ac7b-cdaf090b57c1</td>\n      <td>penta_trickbd_external</td>\n      <td>a ta age theke jani</td>\n      <td>এটা আগে থেকে জানি</td>\n      <td>এটা আগে থেকে জানি</td>\n      <td>&lt;pad&gt; এটা আগে থেকে জানি&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1495</th>\n      <td>fae94029-a03c-4970-9e26-1a9205f85609</td>\n      <td>penta_trickbd_external</td>\n      <td>Bondho kore dise……network busy dekhay</td>\n      <td>বন্ধ করে দিছে…… নেটওয়ার্ক বিজি দেখায়</td>\n      <td>বন্ধ করে দিছে...... নেটওয়ার্ক বিজি দেখায়</td>\n      <td>&lt;pad&gt; বন্ধ করে দিসে......নেটওয়ার্ক বিজি দেখায...</td>\n    </tr>\n    <tr>\n      <th>1496</th>\n      <td>88378e71-ba7f-4245-8e65-faa6f4df72be</td>\n      <td>penta_trickbd_external</td>\n      <td>Vai, Apni Jodi ttf file gulo picsart-fonts a m...</td>\n      <td>ভাই, আপনি যদি টিটিএফ ফাইল গুলো পিক্সআর্ট-ফন্টস...</td>\n      <td>ভাই, আপনি যদি টিটিএফ ফাইল গুলো পিক্সআর্ট-ফন্টস...</td>\n      <td>&lt;pad&gt;ভাই, আপনি যদি টিটিএফ ফাইল গুলো পিকস্ট-ফন্...</td>\n    </tr>\n    <tr>\n      <th>1497</th>\n      <td>2ed0a273-2ae5-4e93-a2b6-b48e556a1051</td>\n      <td>penta_trickbd_external</td>\n      <td>vai 10 second a kom holeo 10 taka katbe, ami e...</td>\n      <td>ভাই ১০ সেকেন্ড এ কম হলেও ১০ টাকা কাটবে, আমি এর...</td>\n      <td>ভাই ১০ সেকেন্ড এ কম হলেও ১০ টাকা কাটবে, আমি এর...</td>\n      <td>&lt;pad&gt; ভাই ১০ সেকেন্ড এ কম হলেও ১০ টাকা কাটবে, ...</td>\n    </tr>\n    <tr>\n      <th>1498</th>\n      <td>aae28ebc-016d-4375-a60b-0486e86521f3</td>\n      <td>penta_trickbd_external</td>\n      <td>Kaj korche.Thank you</td>\n      <td>কাজ করছে। থ্যাংক ইউ</td>\n      <td>কাজ করছে। থ্যাংক ইউ</td>\n      <td>&lt;pad&gt; কাজ করছে।থ্যাংক ইউ&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>1499</th>\n      <td>0f38cb07-4742-4d5d-ae49-3b32763f866c</td>\n      <td>penta_trickbd_external</td>\n      <td>নতুন reg kore 1150 Tau paysilam..kintu..ektu.....</td>\n      <td>নতুন রেজিস্ট্রেশন করে ১১৫০ টাউ পেয়েছিলাম.. কি...</td>\n      <td>নতুন রেজিস্ট্রেশন করে ১১৫০ টাউ পেয়েছিলাম.. কি...</td>\n      <td>&lt;pad&gt;নতুন রেজ করে ১১৫০ তাও পাইসিলাম..কিন্তু..এ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1500 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}